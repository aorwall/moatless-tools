{
  "instance_id": "matplotlib__matplotlib-24013",
  "model_patch": "diff --git a/lib/matplotlib/tri/__init__.py b/lib/matplotlib/tri/__init__.py\nindex 4185452c01..588234e272 100644\n--- a/lib/matplotlib/tri/__init__.py\n+++ b/lib/matplotlib/tri/__init__.py\n@@ -7,7 +7,7 @@ from .tricontour import TriContourSet, tricontour, tricontourf\n from .trifinder import TriFinder, TrapezoidMapTriFinder\n from .triinterpolate import (TriInterpolator, LinearTriInterpolator,\n                              CubicTriInterpolator)\n-from .tripcolor import tripcolor\n+from ._tripcolor import tripcolor\n from .triplot import triplot\n from .trirefine import TriRefiner, UniformTriRefiner\n from .tritools import TriAnalyzer\ndiff --git a/lib/matplotlib/tri/tripcolor.py b/lib/matplotlib/tri/_tripcolor.py\nsimilarity index 100%\nrename from lib/matplotlib/tri/tripcolor.py\nrename to lib/matplotlib/tri/_tripcolor.py\n",
  "model_name_or_path": "Devin",
  "pass_or_fail": "fail",
  "model_patch_files": [
    "lib/matplotlib/tri/__init__.py"
  ],
  "repo": "matplotlib/matplotlib",
  "base_commit": "394748d584d1cd5c361a6a4c7b70d7b8a8cd3ef0",
  "patch": "diff --git a/lib/matplotlib/tri/__init__.py b/lib/matplotlib/tri/__init__.py\n--- a/lib/matplotlib/tri/__init__.py\n+++ b/lib/matplotlib/tri/__init__.py\n@@ -2,15 +2,15 @@\n Unstructured triangular grid functions.\n \"\"\"\n \n-from .triangulation import Triangulation\n-from .tricontour import TriContourSet, tricontour, tricontourf\n-from .trifinder import TriFinder, TrapezoidMapTriFinder\n-from .triinterpolate import (TriInterpolator, LinearTriInterpolator,\n-                             CubicTriInterpolator)\n-from .tripcolor import tripcolor\n-from .triplot import triplot\n-from .trirefine import TriRefiner, UniformTriRefiner\n-from .tritools import TriAnalyzer\n+from ._triangulation import Triangulation\n+from ._tricontour import TriContourSet, tricontour, tricontourf\n+from ._trifinder import TriFinder, TrapezoidMapTriFinder\n+from ._triinterpolate import (TriInterpolator, LinearTriInterpolator,\n+                              CubicTriInterpolator)\n+from ._tripcolor import tripcolor\n+from ._triplot import triplot\n+from ._trirefine import TriRefiner, UniformTriRefiner\n+from ._tritools import TriAnalyzer\n \n \n __all__ = [\"Triangulation\",\ndiff --git a/lib/matplotlib/tri/_triangulation.py b/lib/matplotlib/tri/_triangulation.py\nnew file mode 100644\n--- /dev/null\n+++ b/lib/matplotlib/tri/_triangulation.py\n@@ -0,0 +1,240 @@\n+import numpy as np\n+\n+from matplotlib import _api\n+\n+\n+class Triangulation:\n+    \"\"\"\n+    An unstructured triangular grid consisting of npoints points and\n+    ntri triangles.  The triangles can either be specified by the user\n+    or automatically generated using a Delaunay triangulation.\n+\n+    Parameters\n+    ----------\n+    x, y : (npoints,) array-like\n+        Coordinates of grid points.\n+    triangles : (ntri, 3) array-like of int, optional\n+        For each triangle, the indices of the three points that make\n+        up the triangle, ordered in an anticlockwise manner.  If not\n+        specified, the Delaunay triangulation is calculated.\n+    mask : (ntri,) array-like of bool, optional\n+        Which triangles are masked out.\n+\n+    Attributes\n+    ----------\n+    triangles : (ntri, 3) array of int\n+        For each triangle, the indices of the three points that make\n+        up the triangle, ordered in an anticlockwise manner. If you want to\n+        take the *mask* into account, use `get_masked_triangles` instead.\n+    mask : (ntri, 3) array of bool\n+        Masked out triangles.\n+    is_delaunay : bool\n+        Whether the Triangulation is a calculated Delaunay\n+        triangulation (where *triangles* was not specified) or not.\n+\n+    Notes\n+    -----\n+    For a Triangulation to be valid it must not have duplicate points,\n+    triangles formed from colinear points, or overlapping triangles.\n+    \"\"\"\n+    def __init__(self, x, y, triangles=None, mask=None):\n+        from matplotlib import _qhull\n+\n+        self.x = np.asarray(x, dtype=np.float64)\n+        self.y = np.asarray(y, dtype=np.float64)\n+        if self.x.shape != self.y.shape or self.x.ndim != 1:\n+            raise ValueError(\"x and y must be equal-length 1D arrays, but \"\n+                             f\"found shapes {self.x.shape!r} and \"\n+                             f\"{self.y.shape!r}\")\n+\n+        self.mask = None\n+        self._edges = None\n+        self._neighbors = None\n+        self.is_delaunay = False\n+\n+        if triangles is None:\n+            # No triangulation specified, so use matplotlib._qhull to obtain\n+            # Delaunay triangulation.\n+            self.triangles, self._neighbors = _qhull.delaunay(x, y)\n+            self.is_delaunay = True\n+        else:\n+            # Triangulation specified. Copy, since we may correct triangle\n+            # orientation.\n+            try:\n+                self.triangles = np.array(triangles, dtype=np.int32, order='C')\n+            except ValueError as e:\n+                raise ValueError('triangles must be a (N, 3) int array, not '\n+                                 f'{triangles!r}') from e\n+            if self.triangles.ndim != 2 or self.triangles.shape[1] != 3:\n+                raise ValueError(\n+                    'triangles must be a (N, 3) int array, but found shape '\n+                    f'{self.triangles.shape!r}')\n+            if self.triangles.max() >= len(self.x):\n+                raise ValueError(\n+                    'triangles are indices into the points and must be in the '\n+                    f'range 0 <= i < {len(self.x)} but found value '\n+                    f'{self.triangles.max()}')\n+            if self.triangles.min() < 0:\n+                raise ValueError(\n+                    'triangles are indices into the points and must be in the '\n+                    f'range 0 <= i < {len(self.x)} but found value '\n+                    f'{self.triangles.min()}')\n+\n+        # Underlying C++ object is not created until first needed.\n+        self._cpp_triangulation = None\n+\n+        # Default TriFinder not created until needed.\n+        self._trifinder = None\n+\n+        self.set_mask(mask)\n+\n+    def calculate_plane_coefficients(self, z):\n+        \"\"\"\n+        Calculate plane equation coefficients for all unmasked triangles from\n+        the point (x, y) coordinates and specified z-array of shape (npoints).\n+        The returned array has shape (npoints, 3) and allows z-value at (x, y)\n+        position in triangle tri to be calculated using\n+        ``z = array[tri, 0] * x  + array[tri, 1] * y + array[tri, 2]``.\n+        \"\"\"\n+        return self.get_cpp_triangulation().calculate_plane_coefficients(z)\n+\n+    @property\n+    def edges(self):\n+        \"\"\"\n+        Return integer array of shape (nedges, 2) containing all edges of\n+        non-masked triangles.\n+\n+        Each row defines an edge by its start point index and end point\n+        index.  Each edge appears only once, i.e. for an edge between points\n+        *i*  and *j*, there will only be either *(i, j)* or *(j, i)*.\n+        \"\"\"\n+        if self._edges is None:\n+            self._edges = self.get_cpp_triangulation().get_edges()\n+        return self._edges\n+\n+    def get_cpp_triangulation(self):\n+        \"\"\"\n+        Return the underlying C++ Triangulation object, creating it\n+        if necessary.\n+        \"\"\"\n+        from matplotlib import _tri\n+        if self._cpp_triangulation is None:\n+            self._cpp_triangulation = _tri.Triangulation(\n+                self.x, self.y, self.triangles, self.mask, self._edges,\n+                self._neighbors, not self.is_delaunay)\n+        return self._cpp_triangulation\n+\n+    def get_masked_triangles(self):\n+        \"\"\"\n+        Return an array of triangles taking the mask into account.\n+        \"\"\"\n+        if self.mask is not None:\n+            return self.triangles[~self.mask]\n+        else:\n+            return self.triangles\n+\n+    @staticmethod\n+    def get_from_args_and_kwargs(*args, **kwargs):\n+        \"\"\"\n+        Return a Triangulation object from the args and kwargs, and\n+        the remaining args and kwargs with the consumed values removed.\n+\n+        There are two alternatives: either the first argument is a\n+        Triangulation object, in which case it is returned, or the args\n+        and kwargs are sufficient to create a new Triangulation to\n+        return.  In the latter case, see Triangulation.__init__ for\n+        the possible args and kwargs.\n+        \"\"\"\n+        if isinstance(args[0], Triangulation):\n+            triangulation, *args = args\n+            if 'triangles' in kwargs:\n+                _api.warn_external(\n+                    \"Passing the keyword 'triangles' has no effect when also \"\n+                    \"passing a Triangulation\")\n+            if 'mask' in kwargs:\n+                _api.warn_external(\n+                    \"Passing the keyword 'mask' has no effect when also \"\n+                    \"passing a Triangulation\")\n+        else:\n+            x, y, triangles, mask, args, kwargs = \\\n+                Triangulation._extract_triangulation_params(args, kwargs)\n+            triangulation = Triangulation(x, y, triangles, mask)\n+        return triangulation, args, kwargs\n+\n+    @staticmethod\n+    def _extract_triangulation_params(args, kwargs):\n+        x, y, *args = args\n+        # Check triangles in kwargs then args.\n+        triangles = kwargs.pop('triangles', None)\n+        from_args = False\n+        if triangles is None and args:\n+            triangles = args[0]\n+            from_args = True\n+        if triangles is not None:\n+            try:\n+                triangles = np.asarray(triangles, dtype=np.int32)\n+            except ValueError:\n+                triangles = None\n+        if triangles is not None and (triangles.ndim != 2 or\n+                                      triangles.shape[1] != 3):\n+            triangles = None\n+        if triangles is not None and from_args:\n+            args = args[1:]  # Consumed first item in args.\n+        # Check for mask in kwargs.\n+        mask = kwargs.pop('mask', None)\n+        return x, y, triangles, mask, args, kwargs\n+\n+    def get_trifinder(self):\n+        \"\"\"\n+        Return the default `matplotlib.tri.TriFinder` of this\n+        triangulation, creating it if necessary.  This allows the same\n+        TriFinder object to be easily shared.\n+        \"\"\"\n+        if self._trifinder is None:\n+            # Default TriFinder class.\n+            from matplotlib.tri._trifinder import TrapezoidMapTriFinder\n+            self._trifinder = TrapezoidMapTriFinder(self)\n+        return self._trifinder\n+\n+    @property\n+    def neighbors(self):\n+        \"\"\"\n+        Return integer array of shape (ntri, 3) containing neighbor triangles.\n+\n+        For each triangle, the indices of the three triangles that\n+        share the same edges, or -1 if there is no such neighboring\n+        triangle.  ``neighbors[i, j]`` is the triangle that is the neighbor\n+        to the edge from point index ``triangles[i, j]`` to point index\n+        ``triangles[i, (j+1)%3]``.\n+        \"\"\"\n+        if self._neighbors is None:\n+            self._neighbors = self.get_cpp_triangulation().get_neighbors()\n+        return self._neighbors\n+\n+    def set_mask(self, mask):\n+        \"\"\"\n+        Set or clear the mask array.\n+\n+        Parameters\n+        ----------\n+        mask : None or bool array of length ntri\n+        \"\"\"\n+        if mask is None:\n+            self.mask = None\n+        else:\n+            self.mask = np.asarray(mask, dtype=bool)\n+            if self.mask.shape != (self.triangles.shape[0],):\n+                raise ValueError('mask array must have same length as '\n+                                 'triangles array')\n+\n+        # Set mask in C++ Triangulation.\n+        if self._cpp_triangulation is not None:\n+            self._cpp_triangulation.set_mask(self.mask)\n+\n+        # Clear derived fields so they are recalculated when needed.\n+        self._edges = None\n+        self._neighbors = None\n+\n+        # Recalculate TriFinder if it exists.\n+        if self._trifinder is not None:\n+            self._trifinder._initialize()\ndiff --git a/lib/matplotlib/tri/_tricontour.py b/lib/matplotlib/tri/_tricontour.py\nnew file mode 100644\n--- /dev/null\n+++ b/lib/matplotlib/tri/_tricontour.py\n@@ -0,0 +1,271 @@\n+import numpy as np\n+\n+from matplotlib import _docstring\n+from matplotlib.contour import ContourSet\n+from matplotlib.tri._triangulation import Triangulation\n+\n+\n+@_docstring.dedent_interpd\n+class TriContourSet(ContourSet):\n+    \"\"\"\n+    Create and store a set of contour lines or filled regions for\n+    a triangular grid.\n+\n+    This class is typically not instantiated directly by the user but by\n+    `~.Axes.tricontour` and `~.Axes.tricontourf`.\n+\n+    %(contour_set_attributes)s\n+    \"\"\"\n+    def __init__(self, ax, *args, **kwargs):\n+        \"\"\"\n+        Draw triangular grid contour lines or filled regions,\n+        depending on whether keyword arg *filled* is False\n+        (default) or True.\n+\n+        The first argument of the initializer must be an `~.axes.Axes`\n+        object.  The remaining arguments and keyword arguments\n+        are described in the docstring of `~.Axes.tricontour`.\n+        \"\"\"\n+        super().__init__(ax, *args, **kwargs)\n+\n+    def _process_args(self, *args, **kwargs):\n+        \"\"\"\n+        Process args and kwargs.\n+        \"\"\"\n+        if isinstance(args[0], TriContourSet):\n+            C = args[0]._contour_generator\n+            if self.levels is None:\n+                self.levels = args[0].levels\n+            self.zmin = args[0].zmin\n+            self.zmax = args[0].zmax\n+            self._mins = args[0]._mins\n+            self._maxs = args[0]._maxs\n+        else:\n+            from matplotlib import _tri\n+            tri, z = self._contour_args(args, kwargs)\n+            C = _tri.TriContourGenerator(tri.get_cpp_triangulation(), z)\n+            self._mins = [tri.x.min(), tri.y.min()]\n+            self._maxs = [tri.x.max(), tri.y.max()]\n+\n+        self._contour_generator = C\n+        return kwargs\n+\n+    def _contour_args(self, args, kwargs):\n+        tri, args, kwargs = Triangulation.get_from_args_and_kwargs(*args,\n+                                                                   **kwargs)\n+        z = np.ma.asarray(args[0])\n+        if z.shape != tri.x.shape:\n+            raise ValueError('z array must have same length as triangulation x'\n+                             ' and y arrays')\n+\n+        # z values must be finite, only need to check points that are included\n+        # in the triangulation.\n+        z_check = z[np.unique(tri.get_masked_triangles())]\n+        if np.ma.is_masked(z_check):\n+            raise ValueError('z must not contain masked points within the '\n+                             'triangulation')\n+        if not np.isfinite(z_check).all():\n+            raise ValueError('z array must not contain non-finite values '\n+                             'within the triangulation')\n+\n+        z = np.ma.masked_invalid(z, copy=False)\n+        self.zmax = float(z_check.max())\n+        self.zmin = float(z_check.min())\n+        if self.logscale and self.zmin <= 0:\n+            func = 'contourf' if self.filled else 'contour'\n+            raise ValueError(f'Cannot {func} log of negative values.')\n+        self._process_contour_level_args(args[1:])\n+        return (tri, z)\n+\n+\n+_docstring.interpd.update(_tricontour_doc=\"\"\"\n+Draw contour %%(type)s on an unstructured triangular grid.\n+\n+Call signatures::\n+\n+    %%(func)s(triangulation, z, [levels], ...)\n+    %%(func)s(x, y, z, [levels], *, [triangles=triangles], [mask=mask], ...)\n+\n+The triangular grid can be specified either by passing a `.Triangulation`\n+object as the first parameter, or by passing the points *x*, *y* and\n+optionally the *triangles* and a *mask*. See `.Triangulation` for an\n+explanation of these parameters. If neither of *triangulation* or\n+*triangles* are given, the triangulation is calculated on the fly.\n+\n+It is possible to pass *triangles* positionally, i.e.\n+``%%(func)s(x, y, triangles, z, ...)``. However, this is discouraged. For more\n+clarity, pass *triangles* via keyword argument.\n+\n+Parameters\n+----------\n+triangulation : `.Triangulation`, optional\n+    An already created triangular grid.\n+\n+x, y, triangles, mask\n+    Parameters defining the triangular grid. See `.Triangulation`.\n+    This is mutually exclusive with specifying *triangulation*.\n+\n+z : array-like\n+    The height values over which the contour is drawn.  Color-mapping is\n+    controlled by *cmap*, *norm*, *vmin*, and *vmax*.\n+\n+    .. note::\n+        All values in *z* must be finite. Hence, nan and inf values must\n+        either be removed or `~.Triangulation.set_mask` be used.\n+\n+levels : int or array-like, optional\n+    Determines the number and positions of the contour lines / regions.\n+\n+    If an int *n*, use `~matplotlib.ticker.MaxNLocator`, which tries to\n+    automatically choose no more than *n+1* \"nice\" contour levels between\n+    between minimum and maximum numeric values of *Z*.\n+\n+    If array-like, draw contour lines at the specified levels.  The values must\n+    be in increasing order.\n+\n+Returns\n+-------\n+`~matplotlib.tri.TriContourSet`\n+\n+Other Parameters\n+----------------\n+colors : color string or sequence of colors, optional\n+    The colors of the levels, i.e., the contour %%(type)s.\n+\n+    The sequence is cycled for the levels in ascending order. If the sequence\n+    is shorter than the number of levels, it is repeated.\n+\n+    As a shortcut, single color strings may be used in place of one-element\n+    lists, i.e. ``'red'`` instead of ``['red']`` to color all levels with the\n+    same color. This shortcut does only work for color strings, not for other\n+    ways of specifying colors.\n+\n+    By default (value *None*), the colormap specified by *cmap* will be used.\n+\n+alpha : float, default: 1\n+    The alpha blending value, between 0 (transparent) and 1 (opaque).\n+\n+%(cmap_doc)s\n+\n+    This parameter is ignored if *colors* is set.\n+\n+%(norm_doc)s\n+\n+    This parameter is ignored if *colors* is set.\n+\n+%(vmin_vmax_doc)s\n+\n+    If *vmin* or *vmax* are not given, the default color scaling is based on\n+    *levels*.\n+\n+    This parameter is ignored if *colors* is set.\n+\n+origin : {*None*, 'upper', 'lower', 'image'}, default: None\n+    Determines the orientation and exact position of *z* by specifying the\n+    position of ``z[0, 0]``.  This is only relevant, if *X*, *Y* are not given.\n+\n+    - *None*: ``z[0, 0]`` is at X=0, Y=0 in the lower left corner.\n+    - 'lower': ``z[0, 0]`` is at X=0.5, Y=0.5 in the lower left corner.\n+    - 'upper': ``z[0, 0]`` is at X=N+0.5, Y=0.5 in the upper left corner.\n+    - 'image': Use the value from :rc:`image.origin`.\n+\n+extent : (x0, x1, y0, y1), optional\n+    If *origin* is not *None*, then *extent* is interpreted as in `.imshow`: it\n+    gives the outer pixel boundaries. In this case, the position of z[0, 0] is\n+    the center of the pixel, not a corner. If *origin* is *None*, then\n+    (*x0*, *y0*) is the position of z[0, 0], and (*x1*, *y1*) is the position\n+    of z[-1, -1].\n+\n+    This argument is ignored if *X* and *Y* are specified in the call to\n+    contour.\n+\n+locator : ticker.Locator subclass, optional\n+    The locator is used to determine the contour levels if they are not given\n+    explicitly via *levels*.\n+    Defaults to `~.ticker.MaxNLocator`.\n+\n+extend : {'neither', 'both', 'min', 'max'}, default: 'neither'\n+    Determines the ``%%(func)s``-coloring of values that are outside the\n+    *levels* range.\n+\n+    If 'neither', values outside the *levels* range are not colored.  If 'min',\n+    'max' or 'both', color the values below, above or below and above the\n+    *levels* range.\n+\n+    Values below ``min(levels)`` and above ``max(levels)`` are mapped to the\n+    under/over values of the `.Colormap`. Note that most colormaps do not have\n+    dedicated colors for these by default, so that the over and under values\n+    are the edge values of the colormap.  You may want to set these values\n+    explicitly using `.Colormap.set_under` and `.Colormap.set_over`.\n+\n+    .. note::\n+\n+        An existing `.TriContourSet` does not get notified if properties of its\n+        colormap are changed. Therefore, an explicit call to\n+        `.ContourSet.changed()` is needed after modifying the colormap. The\n+        explicit call can be left out, if a colorbar is assigned to the\n+        `.TriContourSet` because it internally calls `.ContourSet.changed()`.\n+\n+xunits, yunits : registered units, optional\n+    Override axis units by specifying an instance of a\n+    :class:`matplotlib.units.ConversionInterface`.\n+\n+antialiased : bool, optional\n+    Enable antialiasing, overriding the defaults.  For\n+    filled contours, the default is *True*.  For line contours,\n+    it is taken from :rc:`lines.antialiased`.\"\"\" % _docstring.interpd.params)\n+\n+\n+@_docstring.Substitution(func='tricontour', type='lines')\n+@_docstring.dedent_interpd\n+def tricontour(ax, *args, **kwargs):\n+    \"\"\"\n+    %(_tricontour_doc)s\n+\n+    linewidths : float or array-like, default: :rc:`contour.linewidth`\n+        The line width of the contour lines.\n+\n+        If a number, all levels will be plotted with this linewidth.\n+\n+        If a sequence, the levels in ascending order will be plotted with\n+        the linewidths in the order specified.\n+\n+        If None, this falls back to :rc:`lines.linewidth`.\n+\n+    linestyles : {*None*, 'solid', 'dashed', 'dashdot', 'dotted'}, optional\n+        If *linestyles* is *None*, the default is 'solid' unless the lines are\n+        monochrome.  In that case, negative contours will take their linestyle\n+        from :rc:`contour.negative_linestyle` setting.\n+\n+        *linestyles* can also be an iterable of the above strings specifying a\n+        set of linestyles to be used. If this iterable is shorter than the\n+        number of contour levels it will be repeated as necessary.\n+    \"\"\"\n+    kwargs['filled'] = False\n+    return TriContourSet(ax, *args, **kwargs)\n+\n+\n+@_docstring.Substitution(func='tricontourf', type='regions')\n+@_docstring.dedent_interpd\n+def tricontourf(ax, *args, **kwargs):\n+    \"\"\"\n+    %(_tricontour_doc)s\n+\n+    hatches : list[str], optional\n+        A list of cross hatch patterns to use on the filled areas.\n+        If None, no hatching will be added to the contour.\n+        Hatching is supported in the PostScript, PDF, SVG and Agg\n+        backends only.\n+\n+    Notes\n+    -----\n+    `.tricontourf` fills intervals that are closed at the top; that is, for\n+    boundaries *z1* and *z2*, the filled region is::\n+\n+        z1 < Z <= z2\n+\n+    except for the lowest interval, which is closed on both sides (i.e. it\n+    includes the lowest value).\n+    \"\"\"\n+    kwargs['filled'] = True\n+    return TriContourSet(ax, *args, **kwargs)\ndiff --git a/lib/matplotlib/tri/_trifinder.py b/lib/matplotlib/tri/_trifinder.py\nnew file mode 100644\n--- /dev/null\n+++ b/lib/matplotlib/tri/_trifinder.py\n@@ -0,0 +1,93 @@\n+import numpy as np\n+\n+from matplotlib import _api\n+from matplotlib.tri import Triangulation\n+\n+\n+class TriFinder:\n+    \"\"\"\n+    Abstract base class for classes used to find the triangles of a\n+    Triangulation in which (x, y) points lie.\n+\n+    Rather than instantiate an object of a class derived from TriFinder, it is\n+    usually better to use the function `.Triangulation.get_trifinder`.\n+\n+    Derived classes implement __call__(x, y) where x and y are array-like point\n+    coordinates of the same shape.\n+    \"\"\"\n+\n+    def __init__(self, triangulation):\n+        _api.check_isinstance(Triangulation, triangulation=triangulation)\n+        self._triangulation = triangulation\n+\n+\n+class TrapezoidMapTriFinder(TriFinder):\n+    \"\"\"\n+    `~matplotlib.tri.TriFinder` class implemented using the trapezoid\n+    map algorithm from the book \"Computational Geometry, Algorithms and\n+    Applications\", second edition, by M. de Berg, M. van Kreveld, M. Overmars\n+    and O. Schwarzkopf.\n+\n+    The triangulation must be valid, i.e. it must not have duplicate points,\n+    triangles formed from colinear points, or overlapping triangles.  The\n+    algorithm has some tolerance to triangles formed from colinear points, but\n+    this should not be relied upon.\n+    \"\"\"\n+\n+    def __init__(self, triangulation):\n+        from matplotlib import _tri\n+        super().__init__(triangulation)\n+        self._cpp_trifinder = _tri.TrapezoidMapTriFinder(\n+            triangulation.get_cpp_triangulation())\n+        self._initialize()\n+\n+    def __call__(self, x, y):\n+        \"\"\"\n+        Return an array containing the indices of the triangles in which the\n+        specified *x*, *y* points lie, or -1 for points that do not lie within\n+        a triangle.\n+\n+        *x*, *y* are array-like x and y coordinates of the same shape and any\n+        number of dimensions.\n+\n+        Returns integer array with the same shape and *x* and *y*.\n+        \"\"\"\n+        x = np.asarray(x, dtype=np.float64)\n+        y = np.asarray(y, dtype=np.float64)\n+        if x.shape != y.shape:\n+            raise ValueError(\"x and y must be array-like with the same shape\")\n+\n+        # C++ does the heavy lifting, and expects 1D arrays.\n+        indices = (self._cpp_trifinder.find_many(x.ravel(), y.ravel())\n+                   .reshape(x.shape))\n+        return indices\n+\n+    def _get_tree_stats(self):\n+        \"\"\"\n+        Return a python list containing the statistics about the node tree:\n+            0: number of nodes (tree size)\n+            1: number of unique nodes\n+            2: number of trapezoids (tree leaf nodes)\n+            3: number of unique trapezoids\n+            4: maximum parent count (max number of times a node is repeated in\n+                   tree)\n+            5: maximum depth of tree (one more than the maximum number of\n+                   comparisons needed to search through the tree)\n+            6: mean of all trapezoid depths (one more than the average number\n+                   of comparisons needed to search through the tree)\n+        \"\"\"\n+        return self._cpp_trifinder.get_tree_stats()\n+\n+    def _initialize(self):\n+        \"\"\"\n+        Initialize the underlying C++ object.  Can be called multiple times if,\n+        for example, the triangulation is modified.\n+        \"\"\"\n+        self._cpp_trifinder.initialize()\n+\n+    def _print_tree(self):\n+        \"\"\"\n+        Print a text representation of the node tree, which is useful for\n+        debugging purposes.\n+        \"\"\"\n+        self._cpp_trifinder.print_tree()\ndiff --git a/lib/matplotlib/tri/_triinterpolate.py b/lib/matplotlib/tri/_triinterpolate.py\nnew file mode 100644\n--- /dev/null\n+++ b/lib/matplotlib/tri/_triinterpolate.py\n@@ -0,0 +1,1574 @@\n+\"\"\"\n+Interpolation inside triangular grids.\n+\"\"\"\n+\n+import numpy as np\n+\n+from matplotlib import _api\n+from matplotlib.tri import Triangulation\n+from matplotlib.tri._trifinder import TriFinder\n+from matplotlib.tri._tritools import TriAnalyzer\n+\n+__all__ = ('TriInterpolator', 'LinearTriInterpolator', 'CubicTriInterpolator')\n+\n+\n+class TriInterpolator:\n+    \"\"\"\n+    Abstract base class for classes used to interpolate on a triangular grid.\n+\n+    Derived classes implement the following methods:\n+\n+    - ``__call__(x, y)``,\n+      where x, y are array-like point coordinates of the same shape, and\n+      that returns a masked array of the same shape containing the\n+      interpolated z-values.\n+\n+    - ``gradient(x, y)``,\n+      where x, y are array-like point coordinates of the same\n+      shape, and that returns a list of 2 masked arrays of the same shape\n+      containing the 2 derivatives of the interpolator (derivatives of\n+      interpolated z values with respect to x and y).\n+    \"\"\"\n+\n+    def __init__(self, triangulation, z, trifinder=None):\n+        _api.check_isinstance(Triangulation, triangulation=triangulation)\n+        self._triangulation = triangulation\n+\n+        self._z = np.asarray(z)\n+        if self._z.shape != self._triangulation.x.shape:\n+            raise ValueError(\"z array must have same length as triangulation x\"\n+                             \" and y arrays\")\n+\n+        _api.check_isinstance((TriFinder, None), trifinder=trifinder)\n+        self._trifinder = trifinder or self._triangulation.get_trifinder()\n+\n+        # Default scaling factors : 1.0 (= no scaling)\n+        # Scaling may be used for interpolations for which the order of\n+        # magnitude of x, y has an impact on the interpolant definition.\n+        # Please refer to :meth:`_interpolate_multikeys` for details.\n+        self._unit_x = 1.0\n+        self._unit_y = 1.0\n+\n+        # Default triangle renumbering: None (= no renumbering)\n+        # Renumbering may be used to avoid unnecessary computations\n+        # if complex calculations are done inside the Interpolator.\n+        # Please refer to :meth:`_interpolate_multikeys` for details.\n+        self._tri_renum = None\n+\n+    # __call__ and gradient docstrings are shared by all subclasses\n+    # (except, if needed, relevant additions).\n+    # However these methods are only implemented in subclasses to avoid\n+    # confusion in the documentation.\n+    _docstring__call__ = \"\"\"\n+        Returns a masked array containing interpolated values at the specified\n+        (x, y) points.\n+\n+        Parameters\n+        ----------\n+        x, y : array-like\n+            x and y coordinates of the same shape and any number of\n+            dimensions.\n+\n+        Returns\n+        -------\n+        np.ma.array\n+            Masked array of the same shape as *x* and *y*; values corresponding\n+            to (*x*, *y*) points outside of the triangulation are masked out.\n+\n+        \"\"\"\n+\n+    _docstringgradient = r\"\"\"\n+        Returns a list of 2 masked arrays containing interpolated derivatives\n+        at the specified (x, y) points.\n+\n+        Parameters\n+        ----------\n+        x, y : array-like\n+            x and y coordinates of the same shape and any number of\n+            dimensions.\n+\n+        Returns\n+        -------\n+        dzdx, dzdy : np.ma.array\n+            2 masked arrays of the same shape as *x* and *y*; values\n+            corresponding to (x, y) points outside of the triangulation\n+            are masked out.\n+            The first returned array contains the values of\n+            :math:`\\frac{\\partial z}{\\partial x}` and the second those of\n+            :math:`\\frac{\\partial z}{\\partial y}`.\n+\n+        \"\"\"\n+\n+    def _interpolate_multikeys(self, x, y, tri_index=None,\n+                               return_keys=('z',)):\n+        \"\"\"\n+        Versatile (private) method defined for all TriInterpolators.\n+\n+        :meth:`_interpolate_multikeys` is a wrapper around method\n+        :meth:`_interpolate_single_key` (to be defined in the child\n+        subclasses).\n+        :meth:`_interpolate_single_key actually performs the interpolation,\n+        but only for 1-dimensional inputs and at valid locations (inside\n+        unmasked triangles of the triangulation).\n+\n+        The purpose of :meth:`_interpolate_multikeys` is to implement the\n+        following common tasks needed in all subclasses implementations:\n+\n+        - calculation of containing triangles\n+        - dealing with more than one interpolation request at the same\n+          location (e.g., if the 2 derivatives are requested, it is\n+          unnecessary to compute the containing triangles twice)\n+        - scaling according to self._unit_x, self._unit_y\n+        - dealing with points outside of the grid (with fill value np.nan)\n+        - dealing with multi-dimensional *x*, *y* arrays: flattening for\n+          :meth:`_interpolate_params` call and final reshaping.\n+\n+        (Note that np.vectorize could do most of those things very well for\n+        you, but it does it by function evaluations over successive tuples of\n+        the input arrays. Therefore, this tends to be more time consuming than\n+        using optimized numpy functions - e.g., np.dot - which can be used\n+        easily on the flattened inputs, in the child-subclass methods\n+        :meth:`_interpolate_single_key`.)\n+\n+        It is guaranteed that the calls to :meth:`_interpolate_single_key`\n+        will be done with flattened (1-d) array-like input parameters *x*, *y*\n+        and with flattened, valid `tri_index` arrays (no -1 index allowed).\n+\n+        Parameters\n+        ----------\n+        x, y : array-like\n+            x and y coordinates where interpolated values are requested.\n+        tri_index : array-like of int, optional\n+            Array of the containing triangle indices, same shape as\n+            *x* and *y*. Defaults to None. If None, these indices\n+            will be computed by a TriFinder instance.\n+            (Note: For point outside the grid, tri_index[ipt] shall be -1).\n+        return_keys : tuple of keys from {'z', 'dzdx', 'dzdy'}\n+            Defines the interpolation arrays to return, and in which order.\n+\n+        Returns\n+        -------\n+        list of arrays\n+            Each array-like contains the expected interpolated values in the\n+            order defined by *return_keys* parameter.\n+        \"\"\"\n+        # Flattening and rescaling inputs arrays x, y\n+        # (initial shape is stored for output)\n+        x = np.asarray(x, dtype=np.float64)\n+        y = np.asarray(y, dtype=np.float64)\n+        sh_ret = x.shape\n+        if x.shape != y.shape:\n+            raise ValueError(\"x and y shall have same shapes.\"\n+                             \" Given: {0} and {1}\".format(x.shape, y.shape))\n+        x = np.ravel(x)\n+        y = np.ravel(y)\n+        x_scaled = x/self._unit_x\n+        y_scaled = y/self._unit_y\n+        size_ret = np.size(x_scaled)\n+\n+        # Computes & ravels the element indexes, extract the valid ones.\n+        if tri_index is None:\n+            tri_index = self._trifinder(x, y)\n+        else:\n+            if tri_index.shape != sh_ret:\n+                raise ValueError(\n+                    \"tri_index array is provided and shall\"\n+                    \" have same shape as x and y. Given: \"\n+                    \"{0} and {1}\".format(tri_index.shape, sh_ret))\n+            tri_index = np.ravel(tri_index)\n+\n+        mask_in = (tri_index != -1)\n+        if self._tri_renum is None:\n+            valid_tri_index = tri_index[mask_in]\n+        else:\n+            valid_tri_index = self._tri_renum[tri_index[mask_in]]\n+        valid_x = x_scaled[mask_in]\n+        valid_y = y_scaled[mask_in]\n+\n+        ret = []\n+        for return_key in return_keys:\n+            # Find the return index associated with the key.\n+            try:\n+                return_index = {'z': 0, 'dzdx': 1, 'dzdy': 2}[return_key]\n+            except KeyError as err:\n+                raise ValueError(\"return_keys items shall take values in\"\n+                                 \" {'z', 'dzdx', 'dzdy'}\") from err\n+\n+            # Sets the scale factor for f & df components\n+            scale = [1., 1./self._unit_x, 1./self._unit_y][return_index]\n+\n+            # Computes the interpolation\n+            ret_loc = np.empty(size_ret, dtype=np.float64)\n+            ret_loc[~mask_in] = np.nan\n+            ret_loc[mask_in] = self._interpolate_single_key(\n+                return_key, valid_tri_index, valid_x, valid_y) * scale\n+            ret += [np.ma.masked_invalid(ret_loc.reshape(sh_ret), copy=False)]\n+\n+        return ret\n+\n+    def _interpolate_single_key(self, return_key, tri_index, x, y):\n+        \"\"\"\n+        Interpolate at points belonging to the triangulation\n+        (inside an unmasked triangles).\n+\n+        Parameters\n+        ----------\n+        return_key : {'z', 'dzdx', 'dzdy'}\n+            The requested values (z or its derivatives).\n+        tri_index : 1D int array\n+            Valid triangle index (cannot be -1).\n+        x, y : 1D arrays, same shape as `tri_index`\n+            Valid locations where interpolation is requested.\n+\n+        Returns\n+        -------\n+        1-d array\n+            Returned array of the same size as *tri_index*\n+        \"\"\"\n+        raise NotImplementedError(\"TriInterpolator subclasses\" +\n+                                  \"should implement _interpolate_single_key!\")\n+\n+\n+class LinearTriInterpolator(TriInterpolator):\n+    \"\"\"\n+    Linear interpolator on a triangular grid.\n+\n+    Each triangle is represented by a plane so that an interpolated value at\n+    point (x, y) lies on the plane of the triangle containing (x, y).\n+    Interpolated values are therefore continuous across the triangulation, but\n+    their first derivatives are discontinuous at edges between triangles.\n+\n+    Parameters\n+    ----------\n+    triangulation : `~matplotlib.tri.Triangulation`\n+        The triangulation to interpolate over.\n+    z : (npoints,) array-like\n+        Array of values, defined at grid points, to interpolate between.\n+    trifinder : `~matplotlib.tri.TriFinder`, optional\n+        If this is not specified, the Triangulation's default TriFinder will\n+        be used by calling `.Triangulation.get_trifinder`.\n+\n+    Methods\n+    -------\n+    `__call__` (x, y) : Returns interpolated values at (x, y) points.\n+    `gradient` (x, y) : Returns interpolated derivatives at (x, y) points.\n+\n+    \"\"\"\n+    def __init__(self, triangulation, z, trifinder=None):\n+        super().__init__(triangulation, z, trifinder)\n+\n+        # Store plane coefficients for fast interpolation calculations.\n+        self._plane_coefficients = \\\n+            self._triangulation.calculate_plane_coefficients(self._z)\n+\n+    def __call__(self, x, y):\n+        return self._interpolate_multikeys(x, y, tri_index=None,\n+                                           return_keys=('z',))[0]\n+    __call__.__doc__ = TriInterpolator._docstring__call__\n+\n+    def gradient(self, x, y):\n+        return self._interpolate_multikeys(x, y, tri_index=None,\n+                                           return_keys=('dzdx', 'dzdy'))\n+    gradient.__doc__ = TriInterpolator._docstringgradient\n+\n+    def _interpolate_single_key(self, return_key, tri_index, x, y):\n+        _api.check_in_list(['z', 'dzdx', 'dzdy'], return_key=return_key)\n+        if return_key == 'z':\n+            return (self._plane_coefficients[tri_index, 0]*x +\n+                    self._plane_coefficients[tri_index, 1]*y +\n+                    self._plane_coefficients[tri_index, 2])\n+        elif return_key == 'dzdx':\n+            return self._plane_coefficients[tri_index, 0]\n+        else:  # 'dzdy'\n+            return self._plane_coefficients[tri_index, 1]\n+\n+\n+class CubicTriInterpolator(TriInterpolator):\n+    r\"\"\"\n+    Cubic interpolator on a triangular grid.\n+\n+    In one-dimension - on a segment - a cubic interpolating function is\n+    defined by the values of the function and its derivative at both ends.\n+    This is almost the same in 2D inside a triangle, except that the values\n+    of the function and its 2 derivatives have to be defined at each triangle\n+    node.\n+\n+    The CubicTriInterpolator takes the value of the function at each node -\n+    provided by the user - and internally computes the value of the\n+    derivatives, resulting in a smooth interpolation.\n+    (As a special feature, the user can also impose the value of the\n+    derivatives at each node, but this is not supposed to be the common\n+    usage.)\n+\n+    Parameters\n+    ----------\n+    triangulation : `~matplotlib.tri.Triangulation`\n+        The triangulation to interpolate over.\n+    z : (npoints,) array-like\n+        Array of values, defined at grid points, to interpolate between.\n+    kind : {'min_E', 'geom', 'user'}, optional\n+        Choice of the smoothing algorithm, in order to compute\n+        the interpolant derivatives (defaults to 'min_E'):\n+\n+        - if 'min_E': (default) The derivatives at each node is computed\n+          to minimize a bending energy.\n+        - if 'geom': The derivatives at each node is computed as a\n+          weighted average of relevant triangle normals. To be used for\n+          speed optimization (large grids).\n+        - if 'user': The user provides the argument *dz*, no computation\n+          is hence needed.\n+\n+    trifinder : `~matplotlib.tri.TriFinder`, optional\n+        If not specified, the Triangulation's default TriFinder will\n+        be used by calling `.Triangulation.get_trifinder`.\n+    dz : tuple of array-likes (dzdx, dzdy), optional\n+        Used only if  *kind* ='user'. In this case *dz* must be provided as\n+        (dzdx, dzdy) where dzdx, dzdy are arrays of the same shape as *z* and\n+        are the interpolant first derivatives at the *triangulation* points.\n+\n+    Methods\n+    -------\n+    `__call__` (x, y) : Returns interpolated values at (x, y) points.\n+    `gradient` (x, y) : Returns interpolated derivatives at (x, y) points.\n+\n+    Notes\n+    -----\n+    This note is a bit technical and details how the cubic interpolation is\n+    computed.\n+\n+    The interpolation is based on a Clough-Tocher subdivision scheme of\n+    the *triangulation* mesh (to make it clearer, each triangle of the\n+    grid will be divided in 3 child-triangles, and on each child triangle\n+    the interpolated function is a cubic polynomial of the 2 coordinates).\n+    This technique originates from FEM (Finite Element Method) analysis;\n+    the element used is a reduced Hsieh-Clough-Tocher (HCT)\n+    element. Its shape functions are described in [1]_.\n+    The assembled function is guaranteed to be C1-smooth, i.e. it is\n+    continuous and its first derivatives are also continuous (this\n+    is easy to show inside the triangles but is also true when crossing the\n+    edges).\n+\n+    In the default case (*kind* ='min_E'), the interpolant minimizes a\n+    curvature energy on the functional space generated by the HCT element\n+    shape functions - with imposed values but arbitrary derivatives at each\n+    node. The minimized functional is the integral of the so-called total\n+    curvature (implementation based on an algorithm from [2]_ - PCG sparse\n+    solver):\n+\n+        .. math::\n+\n+            E(z) = \\frac{1}{2} \\int_{\\Omega} \\left(\n+                \\left( \\frac{\\partial^2{z}}{\\partial{x}^2} \\right)^2 +\n+                \\left( \\frac{\\partial^2{z}}{\\partial{y}^2} \\right)^2 +\n+                2\\left( \\frac{\\partial^2{z}}{\\partial{y}\\partial{x}} \\right)^2\n+            \\right) dx\\,dy\n+\n+    If the case *kind* ='geom' is chosen by the user, a simple geometric\n+    approximation is used (weighted average of the triangle normal\n+    vectors), which could improve speed on very large grids.\n+\n+    References\n+    ----------\n+    .. [1] Michel Bernadou, Kamal Hassan, \"Basis functions for general\n+        Hsieh-Clough-Tocher triangles, complete or reduced.\",\n+        International Journal for Numerical Methods in Engineering,\n+        17(5):784 - 789. 2.01.\n+    .. [2] C.T. Kelley, \"Iterative Methods for Optimization\".\n+\n+    \"\"\"\n+    def __init__(self, triangulation, z, kind='min_E', trifinder=None,\n+                 dz=None):\n+        super().__init__(triangulation, z, trifinder)\n+\n+        # Loads the underlying c++ _triangulation.\n+        # (During loading, reordering of triangulation._triangles may occur so\n+        # that all final triangles are now anti-clockwise)\n+        self._triangulation.get_cpp_triangulation()\n+\n+        # To build the stiffness matrix and avoid zero-energy spurious modes\n+        # we will only store internally the valid (unmasked) triangles and\n+        # the necessary (used) points coordinates.\n+        # 2 renumbering tables need to be computed and stored:\n+        #  - a triangle renum table in order to translate the result from a\n+        #    TriFinder instance into the internal stored triangle number.\n+        #  - a node renum table to overwrite the self._z values into the new\n+        #    (used) node numbering.\n+        tri_analyzer = TriAnalyzer(self._triangulation)\n+        (compressed_triangles, compressed_x, compressed_y, tri_renum,\n+         node_renum) = tri_analyzer._get_compressed_triangulation()\n+        self._triangles = compressed_triangles\n+        self._tri_renum = tri_renum\n+        # Taking into account the node renumbering in self._z:\n+        valid_node = (node_renum != -1)\n+        self._z[node_renum[valid_node]] = self._z[valid_node]\n+\n+        # Computing scale factors\n+        self._unit_x = np.ptp(compressed_x)\n+        self._unit_y = np.ptp(compressed_y)\n+        self._pts = np.column_stack([compressed_x / self._unit_x,\n+                                     compressed_y / self._unit_y])\n+        # Computing triangle points\n+        self._tris_pts = self._pts[self._triangles]\n+        # Computing eccentricities\n+        self._eccs = self._compute_tri_eccentricities(self._tris_pts)\n+        # Computing dof estimations for HCT triangle shape function\n+        _api.check_in_list(['user', 'geom', 'min_E'], kind=kind)\n+        self._dof = self._compute_dof(kind, dz=dz)\n+        # Loading HCT element\n+        self._ReferenceElement = _ReducedHCT_Element()\n+\n+    def __call__(self, x, y):\n+        return self._interpolate_multikeys(x, y, tri_index=None,\n+                                           return_keys=('z',))[0]\n+    __call__.__doc__ = TriInterpolator._docstring__call__\n+\n+    def gradient(self, x, y):\n+        return self._interpolate_multikeys(x, y, tri_index=None,\n+                                           return_keys=('dzdx', 'dzdy'))\n+    gradient.__doc__ = TriInterpolator._docstringgradient\n+\n+    def _interpolate_single_key(self, return_key, tri_index, x, y):\n+        _api.check_in_list(['z', 'dzdx', 'dzdy'], return_key=return_key)\n+        tris_pts = self._tris_pts[tri_index]\n+        alpha = self._get_alpha_vec(x, y, tris_pts)\n+        ecc = self._eccs[tri_index]\n+        dof = np.expand_dims(self._dof[tri_index], axis=1)\n+        if return_key == 'z':\n+            return self._ReferenceElement.get_function_values(\n+                alpha, ecc, dof)\n+        else:  # 'dzdx', 'dzdy'\n+            J = self._get_jacobian(tris_pts)\n+            dzdx = self._ReferenceElement.get_function_derivatives(\n+                alpha, J, ecc, dof)\n+            if return_key == 'dzdx':\n+                return dzdx[:, 0, 0]\n+            else:\n+                return dzdx[:, 1, 0]\n+\n+    def _compute_dof(self, kind, dz=None):\n+        \"\"\"\n+        Compute and return nodal dofs according to kind.\n+\n+        Parameters\n+        ----------\n+        kind : {'min_E', 'geom', 'user'}\n+            Choice of the _DOF_estimator subclass to estimate the gradient.\n+        dz : tuple of array-likes (dzdx, dzdy), optional\n+            Used only if *kind*=user; in this case passed to the\n+            :class:`_DOF_estimator_user`.\n+\n+        Returns\n+        -------\n+        array-like, shape (npts, 2)\n+            Estimation of the gradient at triangulation nodes (stored as\n+            degree of freedoms of reduced-HCT triangle elements).\n+        \"\"\"\n+        if kind == 'user':\n+            if dz is None:\n+                raise ValueError(\"For a CubicTriInterpolator with \"\n+                                 \"*kind*='user', a valid *dz* \"\n+                                 \"argument is expected.\")\n+            TE = _DOF_estimator_user(self, dz=dz)\n+        elif kind == 'geom':\n+            TE = _DOF_estimator_geom(self)\n+        else:  # 'min_E', checked in __init__\n+            TE = _DOF_estimator_min_E(self)\n+        return TE.compute_dof_from_df()\n+\n+    @staticmethod\n+    def _get_alpha_vec(x, y, tris_pts):\n+        \"\"\"\n+        Fast (vectorized) function to compute barycentric coordinates alpha.\n+\n+        Parameters\n+        ----------\n+        x, y : array-like of dim 1 (shape (nx,))\n+            Coordinates of the points whose points barycentric coordinates are\n+            requested.\n+        tris_pts : array like of dim 3 (shape: (nx, 3, 2))\n+            Coordinates of the containing triangles apexes.\n+\n+        Returns\n+        -------\n+        array of dim 2 (shape (nx, 3))\n+            Barycentric coordinates of the points inside the containing\n+            triangles.\n+        \"\"\"\n+        ndim = tris_pts.ndim-2\n+\n+        a = tris_pts[:, 1, :] - tris_pts[:, 0, :]\n+        b = tris_pts[:, 2, :] - tris_pts[:, 0, :]\n+        abT = np.stack([a, b], axis=-1)\n+        ab = _transpose_vectorized(abT)\n+        OM = np.stack([x, y], axis=1) - tris_pts[:, 0, :]\n+\n+        metric = ab @ abT\n+        # Here we try to deal with the colinear cases.\n+        # metric_inv is in this case set to the Moore-Penrose pseudo-inverse\n+        # meaning that we will still return a set of valid barycentric\n+        # coordinates.\n+        metric_inv = _pseudo_inv22sym_vectorized(metric)\n+        Covar = ab @ _transpose_vectorized(np.expand_dims(OM, ndim))\n+        ksi = metric_inv @ Covar\n+        alpha = _to_matrix_vectorized([\n+            [1-ksi[:, 0, 0]-ksi[:, 1, 0]], [ksi[:, 0, 0]], [ksi[:, 1, 0]]])\n+        return alpha\n+\n+    @staticmethod\n+    def _get_jacobian(tris_pts):\n+        \"\"\"\n+        Fast (vectorized) function to compute triangle jacobian matrix.\n+\n+        Parameters\n+        ----------\n+        tris_pts : array like of dim 3 (shape: (nx, 3, 2))\n+            Coordinates of the containing triangles apexes.\n+\n+        Returns\n+        -------\n+        array of dim 3 (shape (nx, 2, 2))\n+            Barycentric coordinates of the points inside the containing\n+            triangles.\n+            J[itri, :, :] is the jacobian matrix at apex 0 of the triangle\n+            itri, so that the following (matrix) relationship holds:\n+               [dz/dksi] = [J] x [dz/dx]\n+            with x: global coordinates\n+                 ksi: element parametric coordinates in triangle first apex\n+                 local basis.\n+        \"\"\"\n+        a = np.array(tris_pts[:, 1, :] - tris_pts[:, 0, :])\n+        b = np.array(tris_pts[:, 2, :] - tris_pts[:, 0, :])\n+        J = _to_matrix_vectorized([[a[:, 0], a[:, 1]],\n+                                   [b[:, 0], b[:, 1]]])\n+        return J\n+\n+    @staticmethod\n+    def _compute_tri_eccentricities(tris_pts):\n+        \"\"\"\n+        Compute triangle eccentricities.\n+\n+        Parameters\n+        ----------\n+        tris_pts : array like of dim 3 (shape: (nx, 3, 2))\n+            Coordinates of the triangles apexes.\n+\n+        Returns\n+        -------\n+        array like of dim 2 (shape: (nx, 3))\n+            The so-called eccentricity parameters [1] needed for HCT triangular\n+            element.\n+        \"\"\"\n+        a = np.expand_dims(tris_pts[:, 2, :] - tris_pts[:, 1, :], axis=2)\n+        b = np.expand_dims(tris_pts[:, 0, :] - tris_pts[:, 2, :], axis=2)\n+        c = np.expand_dims(tris_pts[:, 1, :] - tris_pts[:, 0, :], axis=2)\n+        # Do not use np.squeeze, this is dangerous if only one triangle\n+        # in the triangulation...\n+        dot_a = (_transpose_vectorized(a) @ a)[:, 0, 0]\n+        dot_b = (_transpose_vectorized(b) @ b)[:, 0, 0]\n+        dot_c = (_transpose_vectorized(c) @ c)[:, 0, 0]\n+        # Note that this line will raise a warning for dot_a, dot_b or dot_c\n+        # zeros, but we choose not to support triangles with duplicate points.\n+        return _to_matrix_vectorized([[(dot_c-dot_b) / dot_a],\n+                                      [(dot_a-dot_c) / dot_b],\n+                                      [(dot_b-dot_a) / dot_c]])\n+\n+\n+# FEM element used for interpolation and for solving minimisation\n+# problem (Reduced HCT element)\n+class _ReducedHCT_Element:\n+    \"\"\"\n+    Implementation of reduced HCT triangular element with explicit shape\n+    functions.\n+\n+    Computes z, dz, d2z and the element stiffness matrix for bending energy:\n+    E(f) = integral( (d2z/dx2 + d2z/dy2)**2 dA)\n+\n+    *** Reference for the shape functions: ***\n+    [1] Basis functions for general Hsieh-Clough-Tocher _triangles, complete or\n+        reduced.\n+        Michel Bernadou, Kamal Hassan\n+        International Journal for Numerical Methods in Engineering.\n+        17(5):784 - 789.  2.01\n+\n+    *** Element description: ***\n+    9 dofs: z and dz given at 3 apex\n+    C1 (conform)\n+\n+    \"\"\"\n+    # 1) Loads matrices to generate shape functions as a function of\n+    #    triangle eccentricities - based on [1] p.11 '''\n+    M = np.array([\n+        [ 0.00, 0.00, 0.00,  4.50,  4.50, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [-0.25, 0.00, 0.00,  0.50,  1.25, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [-0.25, 0.00, 0.00,  1.25,  0.50, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.50, 1.00, 0.00, -1.50,  0.00, 3.00, 3.00, 0.00, 0.00, 3.00],\n+        [ 0.00, 0.00, 0.00, -0.25,  0.25, 0.00, 1.00, 0.00, 0.00, 0.50],\n+        [ 0.25, 0.00, 0.00, -0.50, -0.25, 1.00, 0.00, 0.00, 0.00, 1.00],\n+        [ 0.50, 0.00, 1.00,  0.00, -1.50, 0.00, 0.00, 3.00, 3.00, 3.00],\n+        [ 0.25, 0.00, 0.00, -0.25, -0.50, 0.00, 0.00, 0.00, 1.00, 1.00],\n+        [ 0.00, 0.00, 0.00,  0.25, -0.25, 0.00, 0.00, 1.00, 0.00, 0.50]])\n+    M0 = np.array([\n+        [ 0.00, 0.00, 0.00,  0.00,  0.00, 0.00, 0.00, 0.00, 0.00,  0.00],\n+        [ 0.00, 0.00, 0.00,  0.00,  0.00, 0.00, 0.00, 0.00, 0.00,  0.00],\n+        [ 0.00, 0.00, 0.00,  0.00,  0.00, 0.00, 0.00, 0.00, 0.00,  0.00],\n+        [-1.00, 0.00, 0.00,  1.50,  1.50, 0.00, 0.00, 0.00, 0.00, -3.00],\n+        [-0.50, 0.00, 0.00,  0.75,  0.75, 0.00, 0.00, 0.00, 0.00, -1.50],\n+        [ 0.00, 0.00, 0.00,  0.00,  0.00, 0.00, 0.00, 0.00, 0.00,  0.00],\n+        [ 1.00, 0.00, 0.00, -1.50, -1.50, 0.00, 0.00, 0.00, 0.00,  3.00],\n+        [ 0.00, 0.00, 0.00,  0.00,  0.00, 0.00, 0.00, 0.00, 0.00,  0.00],\n+        [ 0.50, 0.00, 0.00, -0.75, -0.75, 0.00, 0.00, 0.00, 0.00,  1.50]])\n+    M1 = np.array([\n+        [-0.50, 0.00, 0.00,  1.50, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [-0.25, 0.00, 0.00,  0.75, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.50, 0.00, 0.00, -1.50, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.25, 0.00, 0.00, -0.75, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]])\n+    M2 = np.array([\n+        [ 0.50, 0.00, 0.00, 0.00, -1.50, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.25, 0.00, 0.00, 0.00, -0.75, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.00, 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [-0.50, 0.00, 0.00, 0.00,  1.50, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.00, 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [-0.25, 0.00, 0.00, 0.00,  0.75, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.00, 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.00, 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n+        [ 0.00, 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00]])\n+\n+    # 2) Loads matrices to rotate components of gradient & Hessian\n+    #    vectors in the reference basis of triangle first apex (a0)\n+    rotate_dV = np.array([[ 1.,  0.], [ 0.,  1.],\n+                          [ 0.,  1.], [-1., -1.],\n+                          [-1., -1.], [ 1.,  0.]])\n+\n+    rotate_d2V = np.array([[1., 0., 0.], [0., 1., 0.], [ 0.,  0.,  1.],\n+                           [0., 1., 0.], [1., 1., 1.], [ 0., -2., -1.],\n+                           [1., 1., 1.], [1., 0., 0.], [-2.,  0., -1.]])\n+\n+    # 3) Loads Gauss points & weights on the 3 sub-_triangles for P2\n+    #    exact integral - 3 points on each subtriangles.\n+    # NOTE: as the 2nd derivative is discontinuous , we really need those 9\n+    # points!\n+    n_gauss = 9\n+    gauss_pts = np.array([[13./18.,  4./18.,  1./18.],\n+                          [ 4./18., 13./18.,  1./18.],\n+                          [ 7./18.,  7./18.,  4./18.],\n+                          [ 1./18., 13./18.,  4./18.],\n+                          [ 1./18.,  4./18., 13./18.],\n+                          [ 4./18.,  7./18.,  7./18.],\n+                          [ 4./18.,  1./18., 13./18.],\n+                          [13./18.,  1./18.,  4./18.],\n+                          [ 7./18.,  4./18.,  7./18.]], dtype=np.float64)\n+    gauss_w = np.ones([9], dtype=np.float64) / 9.\n+\n+    #  4) Stiffness matrix for curvature energy\n+    E = np.array([[1., 0., 0.], [0., 1., 0.], [0., 0., 2.]])\n+\n+    #  5) Loads the matrix to compute DOF_rot from tri_J at apex 0\n+    J0_to_J1 = np.array([[-1.,  1.], [-1.,  0.]])\n+    J0_to_J2 = np.array([[ 0., -1.], [ 1., -1.]])\n+\n+    def get_function_values(self, alpha, ecc, dofs):\n+        \"\"\"\n+        Parameters\n+        ----------\n+        alpha : is a (N x 3 x 1) array (array of column-matrices) of\n+        barycentric coordinates,\n+        ecc : is a (N x 3 x 1) array (array of column-matrices) of triangle\n+        eccentricities,\n+        dofs : is a (N x 1 x 9) arrays (arrays of row-matrices) of computed\n+        degrees of freedom.\n+\n+        Returns\n+        -------\n+        Returns the N-array of interpolated function values.\n+        \"\"\"\n+        subtri = np.argmin(alpha, axis=1)[:, 0]\n+        ksi = _roll_vectorized(alpha, -subtri, axis=0)\n+        E = _roll_vectorized(ecc, -subtri, axis=0)\n+        x = ksi[:, 0, 0]\n+        y = ksi[:, 1, 0]\n+        z = ksi[:, 2, 0]\n+        x_sq = x*x\n+        y_sq = y*y\n+        z_sq = z*z\n+        V = _to_matrix_vectorized([\n+            [x_sq*x], [y_sq*y], [z_sq*z], [x_sq*z], [x_sq*y], [y_sq*x],\n+            [y_sq*z], [z_sq*y], [z_sq*x], [x*y*z]])\n+        prod = self.M @ V\n+        prod += _scalar_vectorized(E[:, 0, 0], self.M0 @ V)\n+        prod += _scalar_vectorized(E[:, 1, 0], self.M1 @ V)\n+        prod += _scalar_vectorized(E[:, 2, 0], self.M2 @ V)\n+        s = _roll_vectorized(prod, 3*subtri, axis=0)\n+        return (dofs @ s)[:, 0, 0]\n+\n+    def get_function_derivatives(self, alpha, J, ecc, dofs):\n+        \"\"\"\n+        Parameters\n+        ----------\n+        *alpha* is a (N x 3 x 1) array (array of column-matrices of\n+        barycentric coordinates)\n+        *J* is a (N x 2 x 2) array of jacobian matrices (jacobian matrix at\n+        triangle first apex)\n+        *ecc* is a (N x 3 x 1) array (array of column-matrices of triangle\n+        eccentricities)\n+        *dofs* is a (N x 1 x 9) arrays (arrays of row-matrices) of computed\n+        degrees of freedom.\n+\n+        Returns\n+        -------\n+        Returns the values of interpolated function derivatives [dz/dx, dz/dy]\n+        in global coordinates at locations alpha, as a column-matrices of\n+        shape (N x 2 x 1).\n+        \"\"\"\n+        subtri = np.argmin(alpha, axis=1)[:, 0]\n+        ksi = _roll_vectorized(alpha, -subtri, axis=0)\n+        E = _roll_vectorized(ecc, -subtri, axis=0)\n+        x = ksi[:, 0, 0]\n+        y = ksi[:, 1, 0]\n+        z = ksi[:, 2, 0]\n+        x_sq = x*x\n+        y_sq = y*y\n+        z_sq = z*z\n+        dV = _to_matrix_vectorized([\n+            [    -3.*x_sq,     -3.*x_sq],\n+            [     3.*y_sq,           0.],\n+            [          0.,      3.*z_sq],\n+            [     -2.*x*z, -2.*x*z+x_sq],\n+            [-2.*x*y+x_sq,      -2.*x*y],\n+            [ 2.*x*y-y_sq,        -y_sq],\n+            [      2.*y*z,         y_sq],\n+            [        z_sq,       2.*y*z],\n+            [       -z_sq,  2.*x*z-z_sq],\n+            [     x*z-y*z,      x*y-y*z]])\n+        # Puts back dV in first apex basis\n+        dV = dV @ _extract_submatrices(\n+            self.rotate_dV, subtri, block_size=2, axis=0)\n+\n+        prod = self.M @ dV\n+        prod += _scalar_vectorized(E[:, 0, 0], self.M0 @ dV)\n+        prod += _scalar_vectorized(E[:, 1, 0], self.M1 @ dV)\n+        prod += _scalar_vectorized(E[:, 2, 0], self.M2 @ dV)\n+        dsdksi = _roll_vectorized(prod, 3*subtri, axis=0)\n+        dfdksi = dofs @ dsdksi\n+        # In global coordinates:\n+        # Here we try to deal with the simplest colinear cases, returning a\n+        # null matrix.\n+        J_inv = _safe_inv22_vectorized(J)\n+        dfdx = J_inv @ _transpose_vectorized(dfdksi)\n+        return dfdx\n+\n+    def get_function_hessians(self, alpha, J, ecc, dofs):\n+        \"\"\"\n+        Parameters\n+        ----------\n+        *alpha* is a (N x 3 x 1) array (array of column-matrices) of\n+        barycentric coordinates\n+        *J* is a (N x 2 x 2) array of jacobian matrices (jacobian matrix at\n+        triangle first apex)\n+        *ecc* is a (N x 3 x 1) array (array of column-matrices) of triangle\n+        eccentricities\n+        *dofs* is a (N x 1 x 9) arrays (arrays of row-matrices) of computed\n+        degrees of freedom.\n+\n+        Returns\n+        -------\n+        Returns the values of interpolated function 2nd-derivatives\n+        [d2z/dx2, d2z/dy2, d2z/dxdy] in global coordinates at locations alpha,\n+        as a column-matrices of shape (N x 3 x 1).\n+        \"\"\"\n+        d2sdksi2 = self.get_d2Sidksij2(alpha, ecc)\n+        d2fdksi2 = dofs @ d2sdksi2\n+        H_rot = self.get_Hrot_from_J(J)\n+        d2fdx2 = d2fdksi2 @ H_rot\n+        return _transpose_vectorized(d2fdx2)\n+\n+    def get_d2Sidksij2(self, alpha, ecc):\n+        \"\"\"\n+        Parameters\n+        ----------\n+        *alpha* is a (N x 3 x 1) array (array of column-matrices) of\n+        barycentric coordinates\n+        *ecc* is a (N x 3 x 1) array (array of column-matrices) of triangle\n+        eccentricities\n+\n+        Returns\n+        -------\n+        Returns the arrays d2sdksi2 (N x 3 x 1) Hessian of shape functions\n+        expressed in covariant coordinates in first apex basis.\n+        \"\"\"\n+        subtri = np.argmin(alpha, axis=1)[:, 0]\n+        ksi = _roll_vectorized(alpha, -subtri, axis=0)\n+        E = _roll_vectorized(ecc, -subtri, axis=0)\n+        x = ksi[:, 0, 0]\n+        y = ksi[:, 1, 0]\n+        z = ksi[:, 2, 0]\n+        d2V = _to_matrix_vectorized([\n+            [     6.*x,      6.*x,      6.*x],\n+            [     6.*y,        0.,        0.],\n+            [       0.,      6.*z,        0.],\n+            [     2.*z, 2.*z-4.*x, 2.*z-2.*x],\n+            [2.*y-4.*x,      2.*y, 2.*y-2.*x],\n+            [2.*x-4.*y,        0.,     -2.*y],\n+            [     2.*z,        0.,      2.*y],\n+            [       0.,      2.*y,      2.*z],\n+            [       0., 2.*x-4.*z,     -2.*z],\n+            [    -2.*z,     -2.*y,     x-y-z]])\n+        # Puts back d2V in first apex basis\n+        d2V = d2V @ _extract_submatrices(\n+            self.rotate_d2V, subtri, block_size=3, axis=0)\n+        prod = self.M @ d2V\n+        prod += _scalar_vectorized(E[:, 0, 0], self.M0 @ d2V)\n+        prod += _scalar_vectorized(E[:, 1, 0], self.M1 @ d2V)\n+        prod += _scalar_vectorized(E[:, 2, 0], self.M2 @ d2V)\n+        d2sdksi2 = _roll_vectorized(prod, 3*subtri, axis=0)\n+        return d2sdksi2\n+\n+    def get_bending_matrices(self, J, ecc):\n+        \"\"\"\n+        Parameters\n+        ----------\n+        *J* is a (N x 2 x 2) array of jacobian matrices (jacobian matrix at\n+        triangle first apex)\n+        *ecc* is a (N x 3 x 1) array (array of column-matrices) of triangle\n+        eccentricities\n+\n+        Returns\n+        -------\n+        Returns the element K matrices for bending energy expressed in\n+        GLOBAL nodal coordinates.\n+        K_ij = integral [ (d2zi/dx2 + d2zi/dy2) * (d2zj/dx2 + d2zj/dy2) dA]\n+        tri_J is needed to rotate dofs from local basis to global basis\n+        \"\"\"\n+        n = np.size(ecc, 0)\n+\n+        # 1) matrix to rotate dofs in global coordinates\n+        J1 = self.J0_to_J1 @ J\n+        J2 = self.J0_to_J2 @ J\n+        DOF_rot = np.zeros([n, 9, 9], dtype=np.float64)\n+        DOF_rot[:, 0, 0] = 1\n+        DOF_rot[:, 3, 3] = 1\n+        DOF_rot[:, 6, 6] = 1\n+        DOF_rot[:, 1:3, 1:3] = J\n+        DOF_rot[:, 4:6, 4:6] = J1\n+        DOF_rot[:, 7:9, 7:9] = J2\n+\n+        # 2) matrix to rotate Hessian in global coordinates.\n+        H_rot, area = self.get_Hrot_from_J(J, return_area=True)\n+\n+        # 3) Computes stiffness matrix\n+        # Gauss quadrature.\n+        K = np.zeros([n, 9, 9], dtype=np.float64)\n+        weights = self.gauss_w\n+        pts = self.gauss_pts\n+        for igauss in range(self.n_gauss):\n+            alpha = np.tile(pts[igauss, :], n).reshape(n, 3)\n+            alpha = np.expand_dims(alpha, 2)\n+            weight = weights[igauss]\n+            d2Skdksi2 = self.get_d2Sidksij2(alpha, ecc)\n+            d2Skdx2 = d2Skdksi2 @ H_rot\n+            K += weight * (d2Skdx2 @ self.E @ _transpose_vectorized(d2Skdx2))\n+\n+        # 4) With nodal (not elem) dofs\n+        K = _transpose_vectorized(DOF_rot) @ K @ DOF_rot\n+\n+        # 5) Need the area to compute total element energy\n+        return _scalar_vectorized(area, K)\n+\n+    def get_Hrot_from_J(self, J, return_area=False):\n+        \"\"\"\n+        Parameters\n+        ----------\n+        *J* is a (N x 2 x 2) array of jacobian matrices (jacobian matrix at\n+        triangle first apex)\n+\n+        Returns\n+        -------\n+        Returns H_rot used to rotate Hessian from local basis of first apex,\n+        to global coordinates.\n+        if *return_area* is True, returns also the triangle area (0.5*det(J))\n+        \"\"\"\n+        # Here we try to deal with the simplest colinear cases; a null\n+        # energy and area is imposed.\n+        J_inv = _safe_inv22_vectorized(J)\n+        Ji00 = J_inv[:, 0, 0]\n+        Ji11 = J_inv[:, 1, 1]\n+        Ji10 = J_inv[:, 1, 0]\n+        Ji01 = J_inv[:, 0, 1]\n+        H_rot = _to_matrix_vectorized([\n+            [Ji00*Ji00, Ji10*Ji10, Ji00*Ji10],\n+            [Ji01*Ji01, Ji11*Ji11, Ji01*Ji11],\n+            [2*Ji00*Ji01, 2*Ji11*Ji10, Ji00*Ji11+Ji10*Ji01]])\n+        if not return_area:\n+            return H_rot\n+        else:\n+            area = 0.5 * (J[:, 0, 0]*J[:, 1, 1] - J[:, 0, 1]*J[:, 1, 0])\n+            return H_rot, area\n+\n+    def get_Kff_and_Ff(self, J, ecc, triangles, Uc):\n+        \"\"\"\n+        Build K and F for the following elliptic formulation:\n+        minimization of curvature energy with value of function at node\n+        imposed and derivatives 'free'.\n+\n+        Build the global Kff matrix in cco format.\n+        Build the full Ff vec Ff = - Kfc x Uc.\n+\n+        Parameters\n+        ----------\n+        *J* is a (N x 2 x 2) array of jacobian matrices (jacobian matrix at\n+        triangle first apex)\n+        *ecc* is a (N x 3 x 1) array (array of column-matrices) of triangle\n+        eccentricities\n+        *triangles* is a (N x 3) array of nodes indexes.\n+        *Uc* is (N x 3) array of imposed displacements at nodes\n+\n+        Returns\n+        -------\n+        (Kff_rows, Kff_cols, Kff_vals) Kff matrix in coo format - Duplicate\n+        (row, col) entries must be summed.\n+        Ff: force vector - dim npts * 3\n+        \"\"\"\n+        ntri = np.size(ecc, 0)\n+        vec_range = np.arange(ntri, dtype=np.int32)\n+        c_indices = np.full(ntri, -1, dtype=np.int32)  # for unused dofs, -1\n+        f_dof = [1, 2, 4, 5, 7, 8]\n+        c_dof = [0, 3, 6]\n+\n+        # vals, rows and cols indices in global dof numbering\n+        f_dof_indices = _to_matrix_vectorized([[\n+            c_indices, triangles[:, 0]*2, triangles[:, 0]*2+1,\n+            c_indices, triangles[:, 1]*2, triangles[:, 1]*2+1,\n+            c_indices, triangles[:, 2]*2, triangles[:, 2]*2+1]])\n+\n+        expand_indices = np.ones([ntri, 9, 1], dtype=np.int32)\n+        f_row_indices = _transpose_vectorized(expand_indices @ f_dof_indices)\n+        f_col_indices = expand_indices @ f_dof_indices\n+        K_elem = self.get_bending_matrices(J, ecc)\n+\n+        # Extracting sub-matrices\n+        # Explanation & notations:\n+        # * Subscript f denotes 'free' degrees of freedom (i.e. dz/dx, dz/dx)\n+        # * Subscript c denotes 'condensated' (imposed) degrees of freedom\n+        #    (i.e. z at all nodes)\n+        # * F = [Ff, Fc] is the force vector\n+        # * U = [Uf, Uc] is the imposed dof vector\n+        #        [ Kff Kfc ]\n+        # * K =  [         ]  is the laplacian stiffness matrix\n+        #        [ Kcf Kff ]\n+        # * As F = K x U one gets straightforwardly: Ff = - Kfc x Uc\n+\n+        # Computing Kff stiffness matrix in sparse coo format\n+        Kff_vals = np.ravel(K_elem[np.ix_(vec_range, f_dof, f_dof)])\n+        Kff_rows = np.ravel(f_row_indices[np.ix_(vec_range, f_dof, f_dof)])\n+        Kff_cols = np.ravel(f_col_indices[np.ix_(vec_range, f_dof, f_dof)])\n+\n+        # Computing Ff force vector in sparse coo format\n+        Kfc_elem = K_elem[np.ix_(vec_range, f_dof, c_dof)]\n+        Uc_elem = np.expand_dims(Uc, axis=2)\n+        Ff_elem = -(Kfc_elem @ Uc_elem)[:, :, 0]\n+        Ff_indices = f_dof_indices[np.ix_(vec_range, [0], f_dof)][:, 0, :]\n+\n+        # Extracting Ff force vector in dense format\n+        # We have to sum duplicate indices -  using bincount\n+        Ff = np.bincount(np.ravel(Ff_indices), weights=np.ravel(Ff_elem))\n+        return Kff_rows, Kff_cols, Kff_vals, Ff\n+\n+\n+# :class:_DOF_estimator, _DOF_estimator_user, _DOF_estimator_geom,\n+# _DOF_estimator_min_E\n+# Private classes used to compute the degree of freedom of each triangular\n+# element for the TriCubicInterpolator.\n+class _DOF_estimator:\n+    \"\"\"\n+    Abstract base class for classes used to estimate a function's first\n+    derivatives, and deduce the dofs for a CubicTriInterpolator using a\n+    reduced HCT element formulation.\n+\n+    Derived classes implement ``compute_df(self, **kwargs)``, returning\n+    ``np.vstack([dfx, dfy]).T`` where ``dfx, dfy`` are the estimation of the 2\n+    gradient coordinates.\n+    \"\"\"\n+    def __init__(self, interpolator, **kwargs):\n+        _api.check_isinstance(CubicTriInterpolator, interpolator=interpolator)\n+        self._pts = interpolator._pts\n+        self._tris_pts = interpolator._tris_pts\n+        self.z = interpolator._z\n+        self._triangles = interpolator._triangles\n+        (self._unit_x, self._unit_y) = (interpolator._unit_x,\n+                                        interpolator._unit_y)\n+        self.dz = self.compute_dz(**kwargs)\n+        self.compute_dof_from_df()\n+\n+    def compute_dz(self, **kwargs):\n+        raise NotImplementedError\n+\n+    def compute_dof_from_df(self):\n+        \"\"\"\n+        Compute reduced-HCT elements degrees of freedom, from the gradient.\n+        \"\"\"\n+        J = CubicTriInterpolator._get_jacobian(self._tris_pts)\n+        tri_z = self.z[self._triangles]\n+        tri_dz = self.dz[self._triangles]\n+        tri_dof = self.get_dof_vec(tri_z, tri_dz, J)\n+        return tri_dof\n+\n+    @staticmethod\n+    def get_dof_vec(tri_z, tri_dz, J):\n+        \"\"\"\n+        Compute the dof vector of a triangle, from the value of f, df and\n+        of the local Jacobian at each node.\n+\n+        Parameters\n+        ----------\n+        tri_z : shape (3,) array\n+            f nodal values.\n+        tri_dz : shape (3, 2) array\n+            df/dx, df/dy nodal values.\n+        J\n+            Jacobian matrix in local basis of apex 0.\n+\n+        Returns\n+        -------\n+        dof : shape (9,) array\n+            For each apex ``iapex``::\n+\n+                dof[iapex*3+0] = f(Ai)\n+                dof[iapex*3+1] = df(Ai).(AiAi+)\n+                dof[iapex*3+2] = df(Ai).(AiAi-)\n+        \"\"\"\n+        npt = tri_z.shape[0]\n+        dof = np.zeros([npt, 9], dtype=np.float64)\n+        J1 = _ReducedHCT_Element.J0_to_J1 @ J\n+        J2 = _ReducedHCT_Element.J0_to_J2 @ J\n+\n+        col0 = J @ np.expand_dims(tri_dz[:, 0, :], axis=2)\n+        col1 = J1 @ np.expand_dims(tri_dz[:, 1, :], axis=2)\n+        col2 = J2 @ np.expand_dims(tri_dz[:, 2, :], axis=2)\n+\n+        dfdksi = _to_matrix_vectorized([\n+            [col0[:, 0, 0], col1[:, 0, 0], col2[:, 0, 0]],\n+            [col0[:, 1, 0], col1[:, 1, 0], col2[:, 1, 0]]])\n+        dof[:, 0:7:3] = tri_z\n+        dof[:, 1:8:3] = dfdksi[:, 0]\n+        dof[:, 2:9:3] = dfdksi[:, 1]\n+        return dof\n+\n+\n+class _DOF_estimator_user(_DOF_estimator):\n+    \"\"\"dz is imposed by user; accounts for scaling if any.\"\"\"\n+\n+    def compute_dz(self, dz):\n+        (dzdx, dzdy) = dz\n+        dzdx = dzdx * self._unit_x\n+        dzdy = dzdy * self._unit_y\n+        return np.vstack([dzdx, dzdy]).T\n+\n+\n+class _DOF_estimator_geom(_DOF_estimator):\n+    \"\"\"Fast 'geometric' approximation, recommended for large arrays.\"\"\"\n+\n+    def compute_dz(self):\n+        \"\"\"\n+        self.df is computed as weighted average of _triangles sharing a common\n+        node. On each triangle itri f is first assumed linear (= ~f), which\n+        allows to compute d~f[itri]\n+        Then the following approximation of df nodal values is then proposed:\n+            f[ipt] = SUM ( w[itri] x d~f[itri] , for itri sharing apex ipt)\n+        The weighted coeff. w[itri] are proportional to the angle of the\n+        triangle itri at apex ipt\n+        \"\"\"\n+        el_geom_w = self.compute_geom_weights()\n+        el_geom_grad = self.compute_geom_grads()\n+\n+        # Sum of weights coeffs\n+        w_node_sum = np.bincount(np.ravel(self._triangles),\n+                                 weights=np.ravel(el_geom_w))\n+\n+        # Sum of weighted df = (dfx, dfy)\n+        dfx_el_w = np.empty_like(el_geom_w)\n+        dfy_el_w = np.empty_like(el_geom_w)\n+        for iapex in range(3):\n+            dfx_el_w[:, iapex] = el_geom_w[:, iapex]*el_geom_grad[:, 0]\n+            dfy_el_w[:, iapex] = el_geom_w[:, iapex]*el_geom_grad[:, 1]\n+        dfx_node_sum = np.bincount(np.ravel(self._triangles),\n+                                   weights=np.ravel(dfx_el_w))\n+        dfy_node_sum = np.bincount(np.ravel(self._triangles),\n+                                   weights=np.ravel(dfy_el_w))\n+\n+        # Estimation of df\n+        dfx_estim = dfx_node_sum/w_node_sum\n+        dfy_estim = dfy_node_sum/w_node_sum\n+        return np.vstack([dfx_estim, dfy_estim]).T\n+\n+    def compute_geom_weights(self):\n+        \"\"\"\n+        Build the (nelems, 3) weights coeffs of _triangles angles,\n+        renormalized so that np.sum(weights, axis=1) == np.ones(nelems)\n+        \"\"\"\n+        weights = np.zeros([np.size(self._triangles, 0), 3])\n+        tris_pts = self._tris_pts\n+        for ipt in range(3):\n+            p0 = tris_pts[:, ipt % 3, :]\n+            p1 = tris_pts[:, (ipt+1) % 3, :]\n+            p2 = tris_pts[:, (ipt-1) % 3, :]\n+            alpha1 = np.arctan2(p1[:, 1]-p0[:, 1], p1[:, 0]-p0[:, 0])\n+            alpha2 = np.arctan2(p2[:, 1]-p0[:, 1], p2[:, 0]-p0[:, 0])\n+            # In the below formula we could take modulo 2. but\n+            # modulo 1. is safer regarding round-off errors (flat triangles).\n+            angle = np.abs(((alpha2-alpha1) / np.pi) % 1)\n+            # Weight proportional to angle up np.pi/2; null weight for\n+            # degenerated cases 0 and np.pi (note that *angle* is normalized\n+            # by np.pi).\n+            weights[:, ipt] = 0.5 - np.abs(angle-0.5)\n+        return weights\n+\n+    def compute_geom_grads(self):\n+        \"\"\"\n+        Compute the (global) gradient component of f assumed linear (~f).\n+        returns array df of shape (nelems, 2)\n+        df[ielem].dM[ielem] = dz[ielem] i.e. df = dz x dM = dM.T^-1 x dz\n+        \"\"\"\n+        tris_pts = self._tris_pts\n+        tris_f = self.z[self._triangles]\n+\n+        dM1 = tris_pts[:, 1, :] - tris_pts[:, 0, :]\n+        dM2 = tris_pts[:, 2, :] - tris_pts[:, 0, :]\n+        dM = np.dstack([dM1, dM2])\n+        # Here we try to deal with the simplest colinear cases: a null\n+        # gradient is assumed in this case.\n+        dM_inv = _safe_inv22_vectorized(dM)\n+\n+        dZ1 = tris_f[:, 1] - tris_f[:, 0]\n+        dZ2 = tris_f[:, 2] - tris_f[:, 0]\n+        dZ = np.vstack([dZ1, dZ2]).T\n+        df = np.empty_like(dZ)\n+\n+        # With np.einsum: could be ej,eji -> ej\n+        df[:, 0] = dZ[:, 0]*dM_inv[:, 0, 0] + dZ[:, 1]*dM_inv[:, 1, 0]\n+        df[:, 1] = dZ[:, 0]*dM_inv[:, 0, 1] + dZ[:, 1]*dM_inv[:, 1, 1]\n+        return df\n+\n+\n+class _DOF_estimator_min_E(_DOF_estimator_geom):\n+    \"\"\"\n+    The 'smoothest' approximation, df is computed through global minimization\n+    of the bending energy:\n+      E(f) = integral[(d2z/dx2 + d2z/dy2 + 2 d2z/dxdy)**2 dA]\n+    \"\"\"\n+    def __init__(self, Interpolator):\n+        self._eccs = Interpolator._eccs\n+        super().__init__(Interpolator)\n+\n+    def compute_dz(self):\n+        \"\"\"\n+        Elliptic solver for bending energy minimization.\n+        Uses a dedicated 'toy' sparse Jacobi PCG solver.\n+        \"\"\"\n+        # Initial guess for iterative PCG solver.\n+        dz_init = super().compute_dz()\n+        Uf0 = np.ravel(dz_init)\n+\n+        reference_element = _ReducedHCT_Element()\n+        J = CubicTriInterpolator._get_jacobian(self._tris_pts)\n+        eccs = self._eccs\n+        triangles = self._triangles\n+        Uc = self.z[self._triangles]\n+\n+        # Building stiffness matrix and force vector in coo format\n+        Kff_rows, Kff_cols, Kff_vals, Ff = reference_element.get_Kff_and_Ff(\n+            J, eccs, triangles, Uc)\n+\n+        # Building sparse matrix and solving minimization problem\n+        # We could use scipy.sparse direct solver; however to avoid this\n+        # external dependency an implementation of a simple PCG solver with\n+        # a simple diagonal Jacobi preconditioner is implemented.\n+        tol = 1.e-10\n+        n_dof = Ff.shape[0]\n+        Kff_coo = _Sparse_Matrix_coo(Kff_vals, Kff_rows, Kff_cols,\n+                                     shape=(n_dof, n_dof))\n+        Kff_coo.compress_csc()\n+        Uf, err = _cg(A=Kff_coo, b=Ff, x0=Uf0, tol=tol)\n+        # If the PCG did not converge, we return the best guess between Uf0\n+        # and Uf.\n+        err0 = np.linalg.norm(Kff_coo.dot(Uf0) - Ff)\n+        if err0 < err:\n+            # Maybe a good occasion to raise a warning here ?\n+            _api.warn_external(\"In TriCubicInterpolator initialization, \"\n+                               \"PCG sparse solver did not converge after \"\n+                               \"1000 iterations. `geom` approximation is \"\n+                               \"used instead of `min_E`\")\n+            Uf = Uf0\n+\n+        # Building dz from Uf\n+        dz = np.empty([self._pts.shape[0], 2], dtype=np.float64)\n+        dz[:, 0] = Uf[::2]\n+        dz[:, 1] = Uf[1::2]\n+        return dz\n+\n+\n+# The following private :class:_Sparse_Matrix_coo and :func:_cg provide\n+# a PCG sparse solver for (symmetric) elliptic problems.\n+class _Sparse_Matrix_coo:\n+    def __init__(self, vals, rows, cols, shape):\n+        \"\"\"\n+        Create a sparse matrix in coo format.\n+        *vals*: arrays of values of non-null entries of the matrix\n+        *rows*: int arrays of rows of non-null entries of the matrix\n+        *cols*: int arrays of cols of non-null entries of the matrix\n+        *shape*: 2-tuple (n, m) of matrix shape\n+        \"\"\"\n+        self.n, self.m = shape\n+        self.vals = np.asarray(vals, dtype=np.float64)\n+        self.rows = np.asarray(rows, dtype=np.int32)\n+        self.cols = np.asarray(cols, dtype=np.int32)\n+\n+    def dot(self, V):\n+        \"\"\"\n+        Dot product of self by a vector *V* in sparse-dense to dense format\n+        *V* dense vector of shape (self.m,).\n+        \"\"\"\n+        assert V.shape == (self.m,)\n+        return np.bincount(self.rows,\n+                           weights=self.vals*V[self.cols],\n+                           minlength=self.m)\n+\n+    def compress_csc(self):\n+        \"\"\"\n+        Compress rows, cols, vals / summing duplicates. Sort for csc format.\n+        \"\"\"\n+        _, unique, indices = np.unique(\n+            self.rows + self.n*self.cols,\n+            return_index=True, return_inverse=True)\n+        self.rows = self.rows[unique]\n+        self.cols = self.cols[unique]\n+        self.vals = np.bincount(indices, weights=self.vals)\n+\n+    def compress_csr(self):\n+        \"\"\"\n+        Compress rows, cols, vals / summing duplicates. Sort for csr format.\n+        \"\"\"\n+        _, unique, indices = np.unique(\n+            self.m*self.rows + self.cols,\n+            return_index=True, return_inverse=True)\n+        self.rows = self.rows[unique]\n+        self.cols = self.cols[unique]\n+        self.vals = np.bincount(indices, weights=self.vals)\n+\n+    def to_dense(self):\n+        \"\"\"\n+        Return a dense matrix representing self, mainly for debugging purposes.\n+        \"\"\"\n+        ret = np.zeros([self.n, self.m], dtype=np.float64)\n+        nvals = self.vals.size\n+        for i in range(nvals):\n+            ret[self.rows[i], self.cols[i]] += self.vals[i]\n+        return ret\n+\n+    def __str__(self):\n+        return self.to_dense().__str__()\n+\n+    @property\n+    def diag(self):\n+        \"\"\"Return the (dense) vector of the diagonal elements.\"\"\"\n+        in_diag = (self.rows == self.cols)\n+        diag = np.zeros(min(self.n, self.n), dtype=np.float64)  # default 0.\n+        diag[self.rows[in_diag]] = self.vals[in_diag]\n+        return diag\n+\n+\n+def _cg(A, b, x0=None, tol=1.e-10, maxiter=1000):\n+    \"\"\"\n+    Use Preconditioned Conjugate Gradient iteration to solve A x = b\n+    A simple Jacobi (diagonal) preconditioner is used.\n+\n+    Parameters\n+    ----------\n+    A : _Sparse_Matrix_coo\n+        *A* must have been compressed before by compress_csc or\n+        compress_csr method.\n+    b : array\n+        Right hand side of the linear system.\n+    x0 : array, optional\n+        Starting guess for the solution. Defaults to the zero vector.\n+    tol : float, optional\n+        Tolerance to achieve. The algorithm terminates when the relative\n+        residual is below tol. Default is 1e-10.\n+    maxiter : int, optional\n+        Maximum number of iterations.  Iteration will stop after *maxiter*\n+        steps even if the specified tolerance has not been achieved. Defaults\n+        to 1000.\n+\n+    Returns\n+    -------\n+    x : array\n+        The converged solution.\n+    err : float\n+        The absolute error np.linalg.norm(A.dot(x) - b)\n+    \"\"\"\n+    n = b.size\n+    assert A.n == n\n+    assert A.m == n\n+    b_norm = np.linalg.norm(b)\n+\n+    # Jacobi pre-conditioner\n+    kvec = A.diag\n+    # For diag elem < 1e-6 we keep 1e-6.\n+    kvec = np.maximum(kvec, 1e-6)\n+\n+    # Initial guess\n+    if x0 is None:\n+        x = np.zeros(n)\n+    else:\n+        x = x0\n+\n+    r = b - A.dot(x)\n+    w = r/kvec\n+\n+    p = np.zeros(n)\n+    beta = 0.0\n+    rho = np.dot(r, w)\n+    k = 0\n+\n+    # Following C. T. Kelley\n+    while (np.sqrt(abs(rho)) > tol*b_norm) and (k < maxiter):\n+        p = w + beta*p\n+        z = A.dot(p)\n+        alpha = rho/np.dot(p, z)\n+        r = r - alpha*z\n+        w = r/kvec\n+        rhoold = rho\n+        rho = np.dot(r, w)\n+        x = x + alpha*p\n+        beta = rho/rhoold\n+        # err = np.linalg.norm(A.dot(x) - b)  # absolute accuracy - not used\n+        k += 1\n+    err = np.linalg.norm(A.dot(x) - b)\n+    return x, err\n+\n+\n+# The following private functions:\n+#     :func:`_safe_inv22_vectorized`\n+#     :func:`_pseudo_inv22sym_vectorized`\n+#     :func:`_scalar_vectorized`\n+#     :func:`_transpose_vectorized`\n+#     :func:`_roll_vectorized`\n+#     :func:`_to_matrix_vectorized`\n+#     :func:`_extract_submatrices`\n+# provide fast numpy implementation of some standard operations on arrays of\n+# matrices - stored as (:, n_rows, n_cols)-shaped np.arrays.\n+\n+# Development note: Dealing with pathologic 'flat' triangles in the\n+# CubicTriInterpolator code and impact on (2, 2)-matrix inversion functions\n+# :func:`_safe_inv22_vectorized` and :func:`_pseudo_inv22sym_vectorized`.\n+#\n+# Goals:\n+# 1) The CubicTriInterpolator should be able to handle flat or almost flat\n+#    triangles without raising an error,\n+# 2) These degenerated triangles should have no impact on the automatic dof\n+#    calculation (associated with null weight for the _DOF_estimator_geom and\n+#    with null energy for the _DOF_estimator_min_E),\n+# 3) Linear patch test should be passed exactly on degenerated meshes,\n+# 4) Interpolation (with :meth:`_interpolate_single_key` or\n+#    :meth:`_interpolate_multi_key`) shall be correctly handled even *inside*\n+#    the pathologic triangles, to interact correctly with a TriRefiner class.\n+#\n+# Difficulties:\n+# Flat triangles have rank-deficient *J* (so-called jacobian matrix) and\n+# *metric* (the metric tensor = J x J.T). Computation of the local\n+# tangent plane is also problematic.\n+#\n+# Implementation:\n+# Most of the time, when computing the inverse of a rank-deficient matrix it\n+# is safe to simply return the null matrix (which is the implementation in\n+# :func:`_safe_inv22_vectorized`). This is because of point 2), itself\n+# enforced by:\n+#    - null area hence null energy in :class:`_DOF_estimator_min_E`\n+#    - angles close or equal to 0 or np.pi hence null weight in\n+#      :class:`_DOF_estimator_geom`.\n+#      Note that the function angle -> weight is continuous and maximum for an\n+#      angle np.pi/2 (refer to :meth:`compute_geom_weights`)\n+# The exception is the computation of barycentric coordinates, which is done\n+# by inversion of the *metric* matrix. In this case, we need to compute a set\n+# of valid coordinates (1 among numerous possibilities), to ensure point 4).\n+# We benefit here from the symmetry of metric = J x J.T, which makes it easier\n+# to compute a pseudo-inverse in :func:`_pseudo_inv22sym_vectorized`\n+def _safe_inv22_vectorized(M):\n+    \"\"\"\n+    Inversion of arrays of (2, 2) matrices, returns 0 for rank-deficient\n+    matrices.\n+\n+    *M* : array of (2, 2) matrices to inverse, shape (n, 2, 2)\n+    \"\"\"\n+    _api.check_shape((None, 2, 2), M=M)\n+    M_inv = np.empty_like(M)\n+    prod1 = M[:, 0, 0]*M[:, 1, 1]\n+    delta = prod1 - M[:, 0, 1]*M[:, 1, 0]\n+\n+    # We set delta_inv to 0. in case of a rank deficient matrix; a\n+    # rank-deficient input matrix *M* will lead to a null matrix in output\n+    rank2 = (np.abs(delta) > 1e-8*np.abs(prod1))\n+    if np.all(rank2):\n+        # Normal 'optimized' flow.\n+        delta_inv = 1./delta\n+    else:\n+        # 'Pathologic' flow.\n+        delta_inv = np.zeros(M.shape[0])\n+        delta_inv[rank2] = 1./delta[rank2]\n+\n+    M_inv[:, 0, 0] = M[:, 1, 1]*delta_inv\n+    M_inv[:, 0, 1] = -M[:, 0, 1]*delta_inv\n+    M_inv[:, 1, 0] = -M[:, 1, 0]*delta_inv\n+    M_inv[:, 1, 1] = M[:, 0, 0]*delta_inv\n+    return M_inv\n+\n+\n+def _pseudo_inv22sym_vectorized(M):\n+    \"\"\"\n+    Inversion of arrays of (2, 2) SYMMETRIC matrices; returns the\n+    (Moore-Penrose) pseudo-inverse for rank-deficient matrices.\n+\n+    In case M is of rank 1, we have M = trace(M) x P where P is the orthogonal\n+    projection on Im(M), and we return trace(M)^-1 x P == M / trace(M)**2\n+    In case M is of rank 0, we return the null matrix.\n+\n+    *M* : array of (2, 2) matrices to inverse, shape (n, 2, 2)\n+    \"\"\"\n+    _api.check_shape((None, 2, 2), M=M)\n+    M_inv = np.empty_like(M)\n+    prod1 = M[:, 0, 0]*M[:, 1, 1]\n+    delta = prod1 - M[:, 0, 1]*M[:, 1, 0]\n+    rank2 = (np.abs(delta) > 1e-8*np.abs(prod1))\n+\n+    if np.all(rank2):\n+        # Normal 'optimized' flow.\n+        M_inv[:, 0, 0] = M[:, 1, 1] / delta\n+        M_inv[:, 0, 1] = -M[:, 0, 1] / delta\n+        M_inv[:, 1, 0] = -M[:, 1, 0] / delta\n+        M_inv[:, 1, 1] = M[:, 0, 0] / delta\n+    else:\n+        # 'Pathologic' flow.\n+        # Here we have to deal with 2 sub-cases\n+        # 1) First sub-case: matrices of rank 2:\n+        delta = delta[rank2]\n+        M_inv[rank2, 0, 0] = M[rank2, 1, 1] / delta\n+        M_inv[rank2, 0, 1] = -M[rank2, 0, 1] / delta\n+        M_inv[rank2, 1, 0] = -M[rank2, 1, 0] / delta\n+        M_inv[rank2, 1, 1] = M[rank2, 0, 0] / delta\n+        # 2) Second sub-case: rank-deficient matrices of rank 0 and 1:\n+        rank01 = ~rank2\n+        tr = M[rank01, 0, 0] + M[rank01, 1, 1]\n+        tr_zeros = (np.abs(tr) < 1.e-8)\n+        sq_tr_inv = (1.-tr_zeros) / (tr**2+tr_zeros)\n+        # sq_tr_inv = 1. / tr**2\n+        M_inv[rank01, 0, 0] = M[rank01, 0, 0] * sq_tr_inv\n+        M_inv[rank01, 0, 1] = M[rank01, 0, 1] * sq_tr_inv\n+        M_inv[rank01, 1, 0] = M[rank01, 1, 0] * sq_tr_inv\n+        M_inv[rank01, 1, 1] = M[rank01, 1, 1] * sq_tr_inv\n+\n+    return M_inv\n+\n+\n+def _scalar_vectorized(scalar, M):\n+    \"\"\"\n+    Scalar product between scalars and matrices.\n+    \"\"\"\n+    return scalar[:, np.newaxis, np.newaxis]*M\n+\n+\n+def _transpose_vectorized(M):\n+    \"\"\"\n+    Transposition of an array of matrices *M*.\n+    \"\"\"\n+    return np.transpose(M, [0, 2, 1])\n+\n+\n+def _roll_vectorized(M, roll_indices, axis):\n+    \"\"\"\n+    Roll an array of matrices along *axis* (0: rows, 1: columns) according to\n+    an array of indices *roll_indices*.\n+    \"\"\"\n+    assert axis in [0, 1]\n+    ndim = M.ndim\n+    assert ndim == 3\n+    ndim_roll = roll_indices.ndim\n+    assert ndim_roll == 1\n+    sh = M.shape\n+    r, c = sh[-2:]\n+    assert sh[0] == roll_indices.shape[0]\n+    vec_indices = np.arange(sh[0], dtype=np.int32)\n+\n+    # Builds the rolled matrix\n+    M_roll = np.empty_like(M)\n+    if axis == 0:\n+        for ir in range(r):\n+            for ic in range(c):\n+                M_roll[:, ir, ic] = M[vec_indices, (-roll_indices+ir) % r, ic]\n+    else:  # 1\n+        for ir in range(r):\n+            for ic in range(c):\n+                M_roll[:, ir, ic] = M[vec_indices, ir, (-roll_indices+ic) % c]\n+    return M_roll\n+\n+\n+def _to_matrix_vectorized(M):\n+    \"\"\"\n+    Build an array of matrices from individuals np.arrays of identical shapes.\n+\n+    Parameters\n+    ----------\n+    M\n+        ncols-list of nrows-lists of shape sh.\n+\n+    Returns\n+    -------\n+    M_res : np.array of shape (sh, nrow, ncols)\n+        *M_res* satisfies ``M_res[..., i, j] = M[i][j]``.\n+    \"\"\"\n+    assert isinstance(M, (tuple, list))\n+    assert all(isinstance(item, (tuple, list)) for item in M)\n+    c_vec = np.asarray([len(item) for item in M])\n+    assert np.all(c_vec-c_vec[0] == 0)\n+    r = len(M)\n+    c = c_vec[0]\n+    M00 = np.asarray(M[0][0])\n+    dt = M00.dtype\n+    sh = [M00.shape[0], r, c]\n+    M_ret = np.empty(sh, dtype=dt)\n+    for irow in range(r):\n+        for icol in range(c):\n+            M_ret[:, irow, icol] = np.asarray(M[irow][icol])\n+    return M_ret\n+\n+\n+def _extract_submatrices(M, block_indices, block_size, axis):\n+    \"\"\"\n+    Extract selected blocks of a matrices *M* depending on parameters\n+    *block_indices* and *block_size*.\n+\n+    Returns the array of extracted matrices *Mres* so that ::\n+\n+        M_res[..., ir, :] = M[(block_indices*block_size+ir), :]\n+    \"\"\"\n+    assert block_indices.ndim == 1\n+    assert axis in [0, 1]\n+\n+    r, c = M.shape\n+    if axis == 0:\n+        sh = [block_indices.shape[0], block_size, c]\n+    else:  # 1\n+        sh = [block_indices.shape[0], r, block_size]\n+\n+    dt = M.dtype\n+    M_res = np.empty(sh, dtype=dt)\n+    if axis == 0:\n+        for ir in range(block_size):\n+            M_res[:, ir, :] = M[(block_indices*block_size+ir), :]\n+    else:  # 1\n+        for ic in range(block_size):\n+            M_res[:, :, ic] = M[:, (block_indices*block_size+ic)]\n+\n+    return M_res\ndiff --git a/lib/matplotlib/tri/_tripcolor.py b/lib/matplotlib/tri/_tripcolor.py\nnew file mode 100644\n--- /dev/null\n+++ b/lib/matplotlib/tri/_tripcolor.py\n@@ -0,0 +1,154 @@\n+import numpy as np\n+\n+from matplotlib import _api\n+from matplotlib.collections import PolyCollection, TriMesh\n+from matplotlib.colors import Normalize\n+from matplotlib.tri._triangulation import Triangulation\n+\n+\n+def tripcolor(ax, *args, alpha=1.0, norm=None, cmap=None, vmin=None,\n+              vmax=None, shading='flat', facecolors=None, **kwargs):\n+    \"\"\"\n+    Create a pseudocolor plot of an unstructured triangular grid.\n+\n+    Call signatures::\n+\n+      tripcolor(triangulation, c, *, ...)\n+      tripcolor(x, y, c, *, [triangles=triangles], [mask=mask], ...)\n+\n+    The triangular grid can be specified either by passing a `.Triangulation`\n+    object as the first parameter, or by passing the points *x*, *y* and\n+    optionally the *triangles* and a *mask*. See `.Triangulation` for an\n+    explanation of these parameters.\n+\n+    It is possible to pass the triangles positionally, i.e.\n+    ``tripcolor(x, y, triangles, c, ...)``. However, this is discouraged.\n+    For more clarity, pass *triangles* via keyword argument.\n+\n+    If neither of *triangulation* or *triangles* are given, the triangulation\n+    is calculated on the fly. In this case, it does not make sense to provide\n+    colors at the triangle faces via *c* or *facecolors* because there are\n+    multiple possible triangulations for a group of points and you don't know\n+    which triangles will be constructed.\n+\n+    Parameters\n+    ----------\n+    triangulation : `.Triangulation`\n+        An already created triangular grid.\n+    x, y, triangles, mask\n+        Parameters defining the triangular grid. See `.Triangulation`.\n+        This is mutually exclusive with specifying *triangulation*.\n+    c : array-like\n+        The color values, either for the points or for the triangles. Which one\n+        is automatically inferred from the length of *c*, i.e. does it match\n+        the number of points or the number of triangles. If there are the same\n+        number of points and triangles in the triangulation it is assumed that\n+        color values are defined at points; to force the use of color values at\n+        triangles use the keyword argument ``facecolors=c`` instead of just\n+        ``c``.\n+        This parameter is position-only.\n+    facecolors : array-like, optional\n+        Can be used alternatively to *c* to specify colors at the triangle\n+        faces. This parameter takes precedence over *c*.\n+    shading : {'flat', 'gouraud'}, default: 'flat'\n+        If  'flat' and the color values *c* are defined at points, the color\n+        values used for each triangle are from the mean c of the triangle's\n+        three points. If *shading* is 'gouraud' then color values must be\n+        defined at points.\n+    other_parameters\n+        All other parameters are the same as for `~.Axes.pcolor`.\n+    \"\"\"\n+    _api.check_in_list(['flat', 'gouraud'], shading=shading)\n+\n+    tri, args, kwargs = Triangulation.get_from_args_and_kwargs(*args, **kwargs)\n+\n+    # Parse the color to be in one of (the other variable will be None):\n+    # - facecolors: if specified at the triangle faces\n+    # - point_colors: if specified at the points\n+    if facecolors is not None:\n+        if args:\n+            _api.warn_external(\n+                \"Positional parameter c has no effect when the keyword \"\n+                \"facecolors is given\")\n+        point_colors = None\n+        if len(facecolors) != len(tri.triangles):\n+            raise ValueError(\"The length of facecolors must match the number \"\n+                             \"of triangles\")\n+    else:\n+        # Color from positional parameter c\n+        if not args:\n+            raise TypeError(\n+                \"tripcolor() missing 1 required positional argument: 'c'; or \"\n+                \"1 required keyword-only argument: 'facecolors'\")\n+        elif len(args) > 1:\n+            _api.warn_deprecated(\n+                \"3.6\", message=f\"Additional positional parameters \"\n+                f\"{args[1:]!r} are ignored; support for them is deprecated \"\n+                f\"since %(since)s and will be removed %(removal)s\")\n+        c = np.asarray(args[0])\n+        if len(c) == len(tri.x):\n+            # having this before the len(tri.triangles) comparison gives\n+            # precedence to nodes if there are as many nodes as triangles\n+            point_colors = c\n+            facecolors = None\n+        elif len(c) == len(tri.triangles):\n+            point_colors = None\n+            facecolors = c\n+        else:\n+            raise ValueError('The length of c must match either the number '\n+                             'of points or the number of triangles')\n+\n+    # Handling of linewidths, shading, edgecolors and antialiased as\n+    # in Axes.pcolor\n+    linewidths = (0.25,)\n+    if 'linewidth' in kwargs:\n+        kwargs['linewidths'] = kwargs.pop('linewidth')\n+    kwargs.setdefault('linewidths', linewidths)\n+\n+    edgecolors = 'none'\n+    if 'edgecolor' in kwargs:\n+        kwargs['edgecolors'] = kwargs.pop('edgecolor')\n+    ec = kwargs.setdefault('edgecolors', edgecolors)\n+\n+    if 'antialiased' in kwargs:\n+        kwargs['antialiaseds'] = kwargs.pop('antialiased')\n+    if 'antialiaseds' not in kwargs and ec.lower() == \"none\":\n+        kwargs['antialiaseds'] = False\n+\n+    _api.check_isinstance((Normalize, None), norm=norm)\n+    if shading == 'gouraud':\n+        if facecolors is not None:\n+            raise ValueError(\n+                \"shading='gouraud' can only be used when the colors \"\n+                \"are specified at the points, not at the faces.\")\n+        collection = TriMesh(tri, alpha=alpha, array=point_colors,\n+                             cmap=cmap, norm=norm, **kwargs)\n+    else:  # 'flat'\n+        # Vertices of triangles.\n+        maskedTris = tri.get_masked_triangles()\n+        verts = np.stack((tri.x[maskedTris], tri.y[maskedTris]), axis=-1)\n+\n+        # Color values.\n+        if facecolors is None:\n+            # One color per triangle, the mean of the 3 vertex color values.\n+            colors = point_colors[maskedTris].mean(axis=1)\n+        elif tri.mask is not None:\n+            # Remove color values of masked triangles.\n+            colors = facecolors[~tri.mask]\n+        else:\n+            colors = facecolors\n+        collection = PolyCollection(verts, alpha=alpha, array=colors,\n+                                    cmap=cmap, norm=norm, **kwargs)\n+\n+    collection._scale_norm(norm, vmin, vmax)\n+    ax.grid(False)\n+\n+    minx = tri.x.min()\n+    maxx = tri.x.max()\n+    miny = tri.y.min()\n+    maxy = tri.y.max()\n+    corners = (minx, miny), (maxx, maxy)\n+    ax.update_datalim(corners)\n+    ax.autoscale_view()\n+    ax.add_collection(collection)\n+    return collection\ndiff --git a/lib/matplotlib/tri/_triplot.py b/lib/matplotlib/tri/_triplot.py\nnew file mode 100644\n--- /dev/null\n+++ b/lib/matplotlib/tri/_triplot.py\n@@ -0,0 +1,86 @@\n+import numpy as np\n+from matplotlib.tri._triangulation import Triangulation\n+import matplotlib.cbook as cbook\n+import matplotlib.lines as mlines\n+\n+\n+def triplot(ax, *args, **kwargs):\n+    \"\"\"\n+    Draw an unstructured triangular grid as lines and/or markers.\n+\n+    Call signatures::\n+\n+      triplot(triangulation, ...)\n+      triplot(x, y, [triangles], *, [mask=mask], ...)\n+\n+    The triangular grid can be specified either by passing a `.Triangulation`\n+    object as the first parameter, or by passing the points *x*, *y* and\n+    optionally the *triangles* and a *mask*. If neither of *triangulation* or\n+    *triangles* are given, the triangulation is calculated on the fly.\n+\n+    Parameters\n+    ----------\n+    triangulation : `.Triangulation`\n+        An already created triangular grid.\n+    x, y, triangles, mask\n+        Parameters defining the triangular grid. See `.Triangulation`.\n+        This is mutually exclusive with specifying *triangulation*.\n+    other_parameters\n+        All other args and kwargs are forwarded to `~.Axes.plot`.\n+\n+    Returns\n+    -------\n+    lines : `~matplotlib.lines.Line2D`\n+        The drawn triangles edges.\n+    markers : `~matplotlib.lines.Line2D`\n+        The drawn marker nodes.\n+    \"\"\"\n+    import matplotlib.axes\n+\n+    tri, args, kwargs = Triangulation.get_from_args_and_kwargs(*args, **kwargs)\n+    x, y, edges = (tri.x, tri.y, tri.edges)\n+\n+    # Decode plot format string, e.g., 'ro-'\n+    fmt = args[0] if args else \"\"\n+    linestyle, marker, color = matplotlib.axes._base._process_plot_format(fmt)\n+\n+    # Insert plot format string into a copy of kwargs (kwargs values prevail).\n+    kw = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n+    for key, val in zip(('linestyle', 'marker', 'color'),\n+                        (linestyle, marker, color)):\n+        if val is not None:\n+            kw.setdefault(key, val)\n+\n+    # Draw lines without markers.\n+    # Note 1: If we drew markers here, most markers would be drawn more than\n+    #         once as they belong to several edges.\n+    # Note 2: We insert nan values in the flattened edges arrays rather than\n+    #         plotting directly (triang.x[edges].T, triang.y[edges].T)\n+    #         as it considerably speeds-up code execution.\n+    linestyle = kw['linestyle']\n+    kw_lines = {\n+        **kw,\n+        'marker': 'None',  # No marker to draw.\n+        'zorder': kw.get('zorder', 1),  # Path default zorder is used.\n+    }\n+    if linestyle not in [None, 'None', '', ' ']:\n+        tri_lines_x = np.insert(x[edges], 2, np.nan, axis=1)\n+        tri_lines_y = np.insert(y[edges], 2, np.nan, axis=1)\n+        tri_lines = ax.plot(tri_lines_x.ravel(), tri_lines_y.ravel(),\n+                            **kw_lines)\n+    else:\n+        tri_lines = ax.plot([], [], **kw_lines)\n+\n+    # Draw markers separately.\n+    marker = kw['marker']\n+    kw_markers = {\n+        **kw,\n+        'linestyle': 'None',  # No line to draw.\n+    }\n+    kw_markers.pop('label', None)\n+    if marker not in [None, 'None', '', ' ']:\n+        tri_markers = ax.plot(x, y, **kw_markers)\n+    else:\n+        tri_markers = ax.plot([], [], **kw_markers)\n+\n+    return tri_lines + tri_markers\ndiff --git a/lib/matplotlib/tri/_trirefine.py b/lib/matplotlib/tri/_trirefine.py\nnew file mode 100644\n--- /dev/null\n+++ b/lib/matplotlib/tri/_trirefine.py\n@@ -0,0 +1,307 @@\n+\"\"\"\n+Mesh refinement for triangular grids.\n+\"\"\"\n+\n+import numpy as np\n+\n+from matplotlib import _api\n+from matplotlib.tri._triangulation import Triangulation\n+import matplotlib.tri._triinterpolate\n+\n+\n+class TriRefiner:\n+    \"\"\"\n+    Abstract base class for classes implementing mesh refinement.\n+\n+    A TriRefiner encapsulates a Triangulation object and provides tools for\n+    mesh refinement and interpolation.\n+\n+    Derived classes must implement:\n+\n+    - ``refine_triangulation(return_tri_index=False, **kwargs)`` , where\n+      the optional keyword arguments *kwargs* are defined in each\n+      TriRefiner concrete implementation, and which returns:\n+\n+      - a refined triangulation,\n+      - optionally (depending on *return_tri_index*), for each\n+        point of the refined triangulation: the index of\n+        the initial triangulation triangle to which it belongs.\n+\n+    - ``refine_field(z, triinterpolator=None, **kwargs)``, where:\n+\n+      - *z* array of field values (to refine) defined at the base\n+        triangulation nodes,\n+      - *triinterpolator* is an optional `~matplotlib.tri.TriInterpolator`,\n+      - the other optional keyword arguments *kwargs* are defined in\n+        each TriRefiner concrete implementation;\n+\n+      and which returns (as a tuple) a refined triangular mesh and the\n+      interpolated values of the field at the refined triangulation nodes.\n+    \"\"\"\n+\n+    def __init__(self, triangulation):\n+        _api.check_isinstance(Triangulation, triangulation=triangulation)\n+        self._triangulation = triangulation\n+\n+\n+class UniformTriRefiner(TriRefiner):\n+    \"\"\"\n+    Uniform mesh refinement by recursive subdivisions.\n+\n+    Parameters\n+    ----------\n+    triangulation : `~matplotlib.tri.Triangulation`\n+        The encapsulated triangulation (to be refined)\n+    \"\"\"\n+#    See Also\n+#    --------\n+#    :class:`~matplotlib.tri.CubicTriInterpolator` and\n+#    :class:`~matplotlib.tri.TriAnalyzer`.\n+#    \"\"\"\n+    def __init__(self, triangulation):\n+        super().__init__(triangulation)\n+\n+    def refine_triangulation(self, return_tri_index=False, subdiv=3):\n+        \"\"\"\n+        Compute an uniformly refined triangulation *refi_triangulation* of\n+        the encapsulated :attr:`triangulation`.\n+\n+        This function refines the encapsulated triangulation by splitting each\n+        father triangle into 4 child sub-triangles built on the edges midside\n+        nodes, recursing *subdiv* times.  In the end, each triangle is hence\n+        divided into ``4**subdiv`` child triangles.\n+\n+        Parameters\n+        ----------\n+        return_tri_index : bool, default: False\n+            Whether an index table indicating the father triangle index of each\n+            point is returned.\n+        subdiv : int, default: 3\n+            Recursion level for the subdivision.\n+            Each triangle is divided into ``4**subdiv`` child triangles;\n+            hence, the default results in 64 refined subtriangles for each\n+            triangle of the initial triangulation.\n+\n+        Returns\n+        -------\n+        refi_triangulation : `~matplotlib.tri.Triangulation`\n+            The refined triangulation.\n+        found_index : int array\n+            Index of the initial triangulation containing triangle, for each\n+            point of *refi_triangulation*.\n+            Returned only if *return_tri_index* is set to True.\n+        \"\"\"\n+        refi_triangulation = self._triangulation\n+        ntri = refi_triangulation.triangles.shape[0]\n+\n+        # Computes the triangulation ancestors numbers in the reference\n+        # triangulation.\n+        ancestors = np.arange(ntri, dtype=np.int32)\n+        for _ in range(subdiv):\n+            refi_triangulation, ancestors = self._refine_triangulation_once(\n+                refi_triangulation, ancestors)\n+        refi_npts = refi_triangulation.x.shape[0]\n+        refi_triangles = refi_triangulation.triangles\n+\n+        # Now we compute found_index table if needed\n+        if return_tri_index:\n+            # We have to initialize found_index with -1 because some nodes\n+            # may very well belong to no triangle at all, e.g., in case of\n+            # Delaunay Triangulation with DuplicatePointWarning.\n+            found_index = np.full(refi_npts, -1, dtype=np.int32)\n+            tri_mask = self._triangulation.mask\n+            if tri_mask is None:\n+                found_index[refi_triangles] = np.repeat(ancestors,\n+                                                        3).reshape(-1, 3)\n+            else:\n+                # There is a subtlety here: we want to avoid whenever possible\n+                # that refined points container is a masked triangle (which\n+                # would result in artifacts in plots).\n+                # So we impose the numbering from masked ancestors first,\n+                # then overwrite it with unmasked ancestor numbers.\n+                ancestor_mask = tri_mask[ancestors]\n+                found_index[refi_triangles[ancestor_mask, :]\n+                            ] = np.repeat(ancestors[ancestor_mask],\n+                                          3).reshape(-1, 3)\n+                found_index[refi_triangles[~ancestor_mask, :]\n+                            ] = np.repeat(ancestors[~ancestor_mask],\n+                                          3).reshape(-1, 3)\n+            return refi_triangulation, found_index\n+        else:\n+            return refi_triangulation\n+\n+    def refine_field(self, z, triinterpolator=None, subdiv=3):\n+        \"\"\"\n+        Refine a field defined on the encapsulated triangulation.\n+\n+        Parameters\n+        ----------\n+        z : (npoints,) array-like\n+            Values of the field to refine, defined at the nodes of the\n+            encapsulated triangulation. (``n_points`` is the number of points\n+            in the initial triangulation)\n+        triinterpolator : `~matplotlib.tri.TriInterpolator`, optional\n+            Interpolator used for field interpolation. If not specified,\n+            a `~matplotlib.tri.CubicTriInterpolator` will be used.\n+        subdiv : int, default: 3\n+            Recursion level for the subdivision.\n+            Each triangle is divided into ``4**subdiv`` child triangles.\n+\n+        Returns\n+        -------\n+        refi_tri : `~matplotlib.tri.Triangulation`\n+             The returned refined triangulation.\n+        refi_z : 1D array of length: *refi_tri* node count.\n+             The returned interpolated field (at *refi_tri* nodes).\n+        \"\"\"\n+        if triinterpolator is None:\n+            interp = matplotlib.tri.CubicTriInterpolator(\n+                self._triangulation, z)\n+        else:\n+            _api.check_isinstance(matplotlib.tri.TriInterpolator,\n+                                  triinterpolator=triinterpolator)\n+            interp = triinterpolator\n+\n+        refi_tri, found_index = self.refine_triangulation(\n+            subdiv=subdiv, return_tri_index=True)\n+        refi_z = interp._interpolate_multikeys(\n+            refi_tri.x, refi_tri.y, tri_index=found_index)[0]\n+        return refi_tri, refi_z\n+\n+    @staticmethod\n+    def _refine_triangulation_once(triangulation, ancestors=None):\n+        \"\"\"\n+        Refine a `.Triangulation` by splitting each triangle into 4\n+        child-masked_triangles built on the edges midside nodes.\n+\n+        Masked triangles, if present, are also split, but their children\n+        returned masked.\n+\n+        If *ancestors* is not provided, returns only a new triangulation:\n+        child_triangulation.\n+\n+        If the array-like key table *ancestor* is given, it shall be of shape\n+        (ntri,) where ntri is the number of *triangulation* masked_triangles.\n+        In this case, the function returns\n+        (child_triangulation, child_ancestors)\n+        child_ancestors is defined so that the 4 child masked_triangles share\n+        the same index as their father: child_ancestors.shape = (4 * ntri,).\n+        \"\"\"\n+\n+        x = triangulation.x\n+        y = triangulation.y\n+\n+        #    According to tri.triangulation doc:\n+        #         neighbors[i, j] is the triangle that is the neighbor\n+        #         to the edge from point index masked_triangles[i, j] to point\n+        #         index masked_triangles[i, (j+1)%3].\n+        neighbors = triangulation.neighbors\n+        triangles = triangulation.triangles\n+        npts = np.shape(x)[0]\n+        ntri = np.shape(triangles)[0]\n+        if ancestors is not None:\n+            ancestors = np.asarray(ancestors)\n+            if np.shape(ancestors) != (ntri,):\n+                raise ValueError(\n+                    \"Incompatible shapes provide for triangulation\"\n+                    \".masked_triangles and ancestors: {0} and {1}\".format(\n+                        np.shape(triangles), np.shape(ancestors)))\n+\n+        # Initiating tables refi_x and refi_y of the refined triangulation\n+        # points\n+        # hint: each apex is shared by 2 masked_triangles except the borders.\n+        borders = np.sum(neighbors == -1)\n+        added_pts = (3*ntri + borders) // 2\n+        refi_npts = npts + added_pts\n+        refi_x = np.zeros(refi_npts)\n+        refi_y = np.zeros(refi_npts)\n+\n+        # First part of refi_x, refi_y is just the initial points\n+        refi_x[:npts] = x\n+        refi_y[:npts] = y\n+\n+        # Second part contains the edge midside nodes.\n+        # Each edge belongs to 1 triangle (if border edge) or is shared by 2\n+        # masked_triangles (interior edge).\n+        # We first build 2 * ntri arrays of edge starting nodes (edge_elems,\n+        # edge_apexes); we then extract only the masters to avoid overlaps.\n+        # The so-called 'master' is the triangle with biggest index\n+        # The 'slave' is the triangle with lower index\n+        # (can be -1 if border edge)\n+        # For slave and master we will identify the apex pointing to the edge\n+        # start\n+        edge_elems = np.tile(np.arange(ntri, dtype=np.int32), 3)\n+        edge_apexes = np.repeat(np.arange(3, dtype=np.int32), ntri)\n+        edge_neighbors = neighbors[edge_elems, edge_apexes]\n+        mask_masters = (edge_elems > edge_neighbors)\n+\n+        # Identifying the \"masters\" and adding to refi_x, refi_y vec\n+        masters = edge_elems[mask_masters]\n+        apex_masters = edge_apexes[mask_masters]\n+        x_add = (x[triangles[masters, apex_masters]] +\n+                 x[triangles[masters, (apex_masters+1) % 3]]) * 0.5\n+        y_add = (y[triangles[masters, apex_masters]] +\n+                 y[triangles[masters, (apex_masters+1) % 3]]) * 0.5\n+        refi_x[npts:] = x_add\n+        refi_y[npts:] = y_add\n+\n+        # Building the new masked_triangles; each old masked_triangles hosts\n+        # 4 new masked_triangles\n+        # there are 6 pts to identify per 'old' triangle, 3 new_pt_corner and\n+        # 3 new_pt_midside\n+        new_pt_corner = triangles\n+\n+        # What is the index in refi_x, refi_y of point at middle of apex iapex\n+        #  of elem ielem ?\n+        # If ielem is the apex master: simple count, given the way refi_x was\n+        #  built.\n+        # If ielem is the apex slave: yet we do not know; but we will soon\n+        # using the neighbors table.\n+        new_pt_midside = np.empty([ntri, 3], dtype=np.int32)\n+        cum_sum = npts\n+        for imid in range(3):\n+            mask_st_loc = (imid == apex_masters)\n+            n_masters_loc = np.sum(mask_st_loc)\n+            elem_masters_loc = masters[mask_st_loc]\n+            new_pt_midside[:, imid][elem_masters_loc] = np.arange(\n+                n_masters_loc, dtype=np.int32) + cum_sum\n+            cum_sum += n_masters_loc\n+\n+        # Now dealing with slave elems.\n+        # for each slave element we identify the master and then the inode\n+        # once slave_masters is identified, slave_masters_apex is such that:\n+        # neighbors[slaves_masters, slave_masters_apex] == slaves\n+        mask_slaves = np.logical_not(mask_masters)\n+        slaves = edge_elems[mask_slaves]\n+        slaves_masters = edge_neighbors[mask_slaves]\n+        diff_table = np.abs(neighbors[slaves_masters, :] -\n+                            np.outer(slaves, np.ones(3, dtype=np.int32)))\n+        slave_masters_apex = np.argmin(diff_table, axis=1)\n+        slaves_apex = edge_apexes[mask_slaves]\n+        new_pt_midside[slaves, slaves_apex] = new_pt_midside[\n+            slaves_masters, slave_masters_apex]\n+\n+        # Builds the 4 child masked_triangles\n+        child_triangles = np.empty([ntri*4, 3], dtype=np.int32)\n+        child_triangles[0::4, :] = np.vstack([\n+            new_pt_corner[:, 0], new_pt_midside[:, 0],\n+            new_pt_midside[:, 2]]).T\n+        child_triangles[1::4, :] = np.vstack([\n+            new_pt_corner[:, 1], new_pt_midside[:, 1],\n+            new_pt_midside[:, 0]]).T\n+        child_triangles[2::4, :] = np.vstack([\n+            new_pt_corner[:, 2], new_pt_midside[:, 2],\n+            new_pt_midside[:, 1]]).T\n+        child_triangles[3::4, :] = np.vstack([\n+            new_pt_midside[:, 0], new_pt_midside[:, 1],\n+            new_pt_midside[:, 2]]).T\n+        child_triangulation = Triangulation(refi_x, refi_y, child_triangles)\n+\n+        # Builds the child mask\n+        if triangulation.mask is not None:\n+            child_triangulation.set_mask(np.repeat(triangulation.mask, 4))\n+\n+        if ancestors is None:\n+            return child_triangulation\n+        else:\n+            return child_triangulation, np.repeat(ancestors, 4)\ndiff --git a/lib/matplotlib/tri/_tritools.py b/lib/matplotlib/tri/_tritools.py\nnew file mode 100644\n--- /dev/null\n+++ b/lib/matplotlib/tri/_tritools.py\n@@ -0,0 +1,263 @@\n+\"\"\"\n+Tools for triangular grids.\n+\"\"\"\n+\n+import numpy as np\n+\n+from matplotlib import _api\n+from matplotlib.tri import Triangulation\n+\n+\n+class TriAnalyzer:\n+    \"\"\"\n+    Define basic tools for triangular mesh analysis and improvement.\n+\n+    A TriAnalyzer encapsulates a `.Triangulation` object and provides basic\n+    tools for mesh analysis and mesh improvement.\n+\n+    Attributes\n+    ----------\n+    scale_factors\n+\n+    Parameters\n+    ----------\n+    triangulation : `~matplotlib.tri.Triangulation`\n+        The encapsulated triangulation to analyze.\n+    \"\"\"\n+\n+    def __init__(self, triangulation):\n+        _api.check_isinstance(Triangulation, triangulation=triangulation)\n+        self._triangulation = triangulation\n+\n+    @property\n+    def scale_factors(self):\n+        \"\"\"\n+        Factors to rescale the triangulation into a unit square.\n+\n+        Returns\n+        -------\n+        (float, float)\n+            Scaling factors (kx, ky) so that the triangulation\n+            ``[triangulation.x * kx, triangulation.y * ky]``\n+            fits exactly inside a unit square.\n+        \"\"\"\n+        compressed_triangles = self._triangulation.get_masked_triangles()\n+        node_used = (np.bincount(np.ravel(compressed_triangles),\n+                                 minlength=self._triangulation.x.size) != 0)\n+        return (1 / np.ptp(self._triangulation.x[node_used]),\n+                1 / np.ptp(self._triangulation.y[node_used]))\n+\n+    def circle_ratios(self, rescale=True):\n+        \"\"\"\n+        Return a measure of the triangulation triangles flatness.\n+\n+        The ratio of the incircle radius over the circumcircle radius is a\n+        widely used indicator of a triangle flatness.\n+        It is always ``<= 0.5`` and ``== 0.5`` only for equilateral\n+        triangles. Circle ratios below 0.01 denote very flat triangles.\n+\n+        To avoid unduly low values due to a difference of scale between the 2\n+        axis, the triangular mesh can first be rescaled to fit inside a unit\n+        square with `scale_factors` (Only if *rescale* is True, which is\n+        its default value).\n+\n+        Parameters\n+        ----------\n+        rescale : bool, default: True\n+            If True, internally rescale (based on `scale_factors`), so that the\n+            (unmasked) triangles fit exactly inside a unit square mesh.\n+\n+        Returns\n+        -------\n+        masked array\n+            Ratio of the incircle radius over the circumcircle radius, for\n+            each 'rescaled' triangle of the encapsulated triangulation.\n+            Values corresponding to masked triangles are masked out.\n+\n+        \"\"\"\n+        # Coords rescaling\n+        if rescale:\n+            (kx, ky) = self.scale_factors\n+        else:\n+            (kx, ky) = (1.0, 1.0)\n+        pts = np.vstack([self._triangulation.x*kx,\n+                         self._triangulation.y*ky]).T\n+        tri_pts = pts[self._triangulation.triangles]\n+        # Computes the 3 side lengths\n+        a = tri_pts[:, 1, :] - tri_pts[:, 0, :]\n+        b = tri_pts[:, 2, :] - tri_pts[:, 1, :]\n+        c = tri_pts[:, 0, :] - tri_pts[:, 2, :]\n+        a = np.hypot(a[:, 0], a[:, 1])\n+        b = np.hypot(b[:, 0], b[:, 1])\n+        c = np.hypot(c[:, 0], c[:, 1])\n+        # circumcircle and incircle radii\n+        s = (a+b+c)*0.5\n+        prod = s*(a+b-s)*(a+c-s)*(b+c-s)\n+        # We have to deal with flat triangles with infinite circum_radius\n+        bool_flat = (prod == 0.)\n+        if np.any(bool_flat):\n+            # Pathologic flow\n+            ntri = tri_pts.shape[0]\n+            circum_radius = np.empty(ntri, dtype=np.float64)\n+            circum_radius[bool_flat] = np.inf\n+            abc = a*b*c\n+            circum_radius[~bool_flat] = abc[~bool_flat] / (\n+                4.0*np.sqrt(prod[~bool_flat]))\n+        else:\n+            # Normal optimized flow\n+            circum_radius = (a*b*c) / (4.0*np.sqrt(prod))\n+        in_radius = (a*b*c) / (4.0*circum_radius*s)\n+        circle_ratio = in_radius/circum_radius\n+        mask = self._triangulation.mask\n+        if mask is None:\n+            return circle_ratio\n+        else:\n+            return np.ma.array(circle_ratio, mask=mask)\n+\n+    def get_flat_tri_mask(self, min_circle_ratio=0.01, rescale=True):\n+        \"\"\"\n+        Eliminate excessively flat border triangles from the triangulation.\n+\n+        Returns a mask *new_mask* which allows to clean the encapsulated\n+        triangulation from its border-located flat triangles\n+        (according to their :meth:`circle_ratios`).\n+        This mask is meant to be subsequently applied to the triangulation\n+        using `.Triangulation.set_mask`.\n+        *new_mask* is an extension of the initial triangulation mask\n+        in the sense that an initially masked triangle will remain masked.\n+\n+        The *new_mask* array is computed recursively; at each step flat\n+        triangles are removed only if they share a side with the current mesh\n+        border. Thus no new holes in the triangulated domain will be created.\n+\n+        Parameters\n+        ----------\n+        min_circle_ratio : float, default: 0.01\n+            Border triangles with incircle/circumcircle radii ratio r/R will\n+            be removed if r/R < *min_circle_ratio*.\n+        rescale : bool, default: True\n+            If True, first, internally rescale (based on `scale_factors`) so\n+            that the (unmasked) triangles fit exactly inside a unit square\n+            mesh.  This rescaling accounts for the difference of scale which\n+            might exist between the 2 axis.\n+\n+        Returns\n+        -------\n+        array of bool\n+            Mask to apply to encapsulated triangulation.\n+            All the initially masked triangles remain masked in the\n+            *new_mask*.\n+\n+        Notes\n+        -----\n+        The rationale behind this function is that a Delaunay\n+        triangulation - of an unstructured set of points - sometimes contains\n+        almost flat triangles at its border, leading to artifacts in plots\n+        (especially for high-resolution contouring).\n+        Masked with computed *new_mask*, the encapsulated\n+        triangulation would contain no more unmasked border triangles\n+        with a circle ratio below *min_circle_ratio*, thus improving the\n+        mesh quality for subsequent plots or interpolation.\n+        \"\"\"\n+        # Recursively computes the mask_current_borders, true if a triangle is\n+        # at the border of the mesh OR touching the border through a chain of\n+        # invalid aspect ratio masked_triangles.\n+        ntri = self._triangulation.triangles.shape[0]\n+        mask_bad_ratio = self.circle_ratios(rescale) < min_circle_ratio\n+\n+        current_mask = self._triangulation.mask\n+        if current_mask is None:\n+            current_mask = np.zeros(ntri, dtype=bool)\n+        valid_neighbors = np.copy(self._triangulation.neighbors)\n+        renum_neighbors = np.arange(ntri, dtype=np.int32)\n+        nadd = -1\n+        while nadd != 0:\n+            # The active wavefront is the triangles from the border (unmasked\n+            # but with a least 1 neighbor equal to -1\n+            wavefront = (np.min(valid_neighbors, axis=1) == -1) & ~current_mask\n+            # The element from the active wavefront will be masked if their\n+            # circle ratio is bad.\n+            added_mask = wavefront & mask_bad_ratio\n+            current_mask = added_mask | current_mask\n+            nadd = np.sum(added_mask)\n+\n+            # now we have to update the tables valid_neighbors\n+            valid_neighbors[added_mask, :] = -1\n+            renum_neighbors[added_mask] = -1\n+            valid_neighbors = np.where(valid_neighbors == -1, -1,\n+                                       renum_neighbors[valid_neighbors])\n+\n+        return np.ma.filled(current_mask, True)\n+\n+    def _get_compressed_triangulation(self):\n+        \"\"\"\n+        Compress (if masked) the encapsulated triangulation.\n+\n+        Returns minimal-length triangles array (*compressed_triangles*) and\n+        coordinates arrays (*compressed_x*, *compressed_y*) that can still\n+        describe the unmasked triangles of the encapsulated triangulation.\n+\n+        Returns\n+        -------\n+        compressed_triangles : array-like\n+            the returned compressed triangulation triangles\n+        compressed_x : array-like\n+            the returned compressed triangulation 1st coordinate\n+        compressed_y : array-like\n+            the returned compressed triangulation 2nd coordinate\n+        tri_renum : int array\n+            renumbering table to translate the triangle numbers from the\n+            encapsulated triangulation into the new (compressed) renumbering.\n+            -1 for masked triangles (deleted from *compressed_triangles*).\n+        node_renum : int array\n+            renumbering table to translate the point numbers from the\n+            encapsulated triangulation into the new (compressed) renumbering.\n+            -1 for unused points (i.e. those deleted from *compressed_x* and\n+            *compressed_y*).\n+\n+        \"\"\"\n+        # Valid triangles and renumbering\n+        tri_mask = self._triangulation.mask\n+        compressed_triangles = self._triangulation.get_masked_triangles()\n+        ntri = self._triangulation.triangles.shape[0]\n+        if tri_mask is not None:\n+            tri_renum = self._total_to_compress_renum(~tri_mask)\n+        else:\n+            tri_renum = np.arange(ntri, dtype=np.int32)\n+\n+        # Valid nodes and renumbering\n+        valid_node = (np.bincount(np.ravel(compressed_triangles),\n+                                  minlength=self._triangulation.x.size) != 0)\n+        compressed_x = self._triangulation.x[valid_node]\n+        compressed_y = self._triangulation.y[valid_node]\n+        node_renum = self._total_to_compress_renum(valid_node)\n+\n+        # Now renumbering the valid triangles nodes\n+        compressed_triangles = node_renum[compressed_triangles]\n+\n+        return (compressed_triangles, compressed_x, compressed_y, tri_renum,\n+                node_renum)\n+\n+    @staticmethod\n+    def _total_to_compress_renum(valid):\n+        \"\"\"\n+        Parameters\n+        ----------\n+        valid : 1D bool array\n+            Validity mask.\n+\n+        Returns\n+        -------\n+        int array\n+            Array so that (`valid_array` being a compressed array\n+            based on a `masked_array` with mask ~*valid*):\n+\n+            - For all i with valid[i] = True:\n+              valid_array[renum[i]] = masked_array[i]\n+            - For all i with valid[i] = False:\n+              renum[i] = -1 (invalid value)\n+        \"\"\"\n+        renum = np.full(np.size(valid), -1, dtype=np.int32)\n+        n_valid = np.sum(valid)\n+        renum[valid] = np.arange(n_valid, dtype=np.int32)\n+        return renum\ndiff --git a/lib/matplotlib/tri/triangulation.py b/lib/matplotlib/tri/triangulation.py\n--- a/lib/matplotlib/tri/triangulation.py\n+++ b/lib/matplotlib/tri/triangulation.py\n@@ -1,240 +1,9 @@\n-import numpy as np\n-\n+from ._triangulation import *  # noqa: F401, F403\n from matplotlib import _api\n \n \n-class Triangulation:\n-    \"\"\"\n-    An unstructured triangular grid consisting of npoints points and\n-    ntri triangles.  The triangles can either be specified by the user\n-    or automatically generated using a Delaunay triangulation.\n-\n-    Parameters\n-    ----------\n-    x, y : (npoints,) array-like\n-        Coordinates of grid points.\n-    triangles : (ntri, 3) array-like of int, optional\n-        For each triangle, the indices of the three points that make\n-        up the triangle, ordered in an anticlockwise manner.  If not\n-        specified, the Delaunay triangulation is calculated.\n-    mask : (ntri,) array-like of bool, optional\n-        Which triangles are masked out.\n-\n-    Attributes\n-    ----------\n-    triangles : (ntri, 3) array of int\n-        For each triangle, the indices of the three points that make\n-        up the triangle, ordered in an anticlockwise manner. If you want to\n-        take the *mask* into account, use `get_masked_triangles` instead.\n-    mask : (ntri, 3) array of bool\n-        Masked out triangles.\n-    is_delaunay : bool\n-        Whether the Triangulation is a calculated Delaunay\n-        triangulation (where *triangles* was not specified) or not.\n-\n-    Notes\n-    -----\n-    For a Triangulation to be valid it must not have duplicate points,\n-    triangles formed from colinear points, or overlapping triangles.\n-    \"\"\"\n-    def __init__(self, x, y, triangles=None, mask=None):\n-        from matplotlib import _qhull\n-\n-        self.x = np.asarray(x, dtype=np.float64)\n-        self.y = np.asarray(y, dtype=np.float64)\n-        if self.x.shape != self.y.shape or self.x.ndim != 1:\n-            raise ValueError(\"x and y must be equal-length 1D arrays, but \"\n-                             f\"found shapes {self.x.shape!r} and \"\n-                             f\"{self.y.shape!r}\")\n-\n-        self.mask = None\n-        self._edges = None\n-        self._neighbors = None\n-        self.is_delaunay = False\n-\n-        if triangles is None:\n-            # No triangulation specified, so use matplotlib._qhull to obtain\n-            # Delaunay triangulation.\n-            self.triangles, self._neighbors = _qhull.delaunay(x, y)\n-            self.is_delaunay = True\n-        else:\n-            # Triangulation specified. Copy, since we may correct triangle\n-            # orientation.\n-            try:\n-                self.triangles = np.array(triangles, dtype=np.int32, order='C')\n-            except ValueError as e:\n-                raise ValueError('triangles must be a (N, 3) int array, not '\n-                                 f'{triangles!r}') from e\n-            if self.triangles.ndim != 2 or self.triangles.shape[1] != 3:\n-                raise ValueError(\n-                    'triangles must be a (N, 3) int array, but found shape '\n-                    f'{self.triangles.shape!r}')\n-            if self.triangles.max() >= len(self.x):\n-                raise ValueError(\n-                    'triangles are indices into the points and must be in the '\n-                    f'range 0 <= i < {len(self.x)} but found value '\n-                    f'{self.triangles.max()}')\n-            if self.triangles.min() < 0:\n-                raise ValueError(\n-                    'triangles are indices into the points and must be in the '\n-                    f'range 0 <= i < {len(self.x)} but found value '\n-                    f'{self.triangles.min()}')\n-\n-        # Underlying C++ object is not created until first needed.\n-        self._cpp_triangulation = None\n-\n-        # Default TriFinder not created until needed.\n-        self._trifinder = None\n-\n-        self.set_mask(mask)\n-\n-    def calculate_plane_coefficients(self, z):\n-        \"\"\"\n-        Calculate plane equation coefficients for all unmasked triangles from\n-        the point (x, y) coordinates and specified z-array of shape (npoints).\n-        The returned array has shape (npoints, 3) and allows z-value at (x, y)\n-        position in triangle tri to be calculated using\n-        ``z = array[tri, 0] * x  + array[tri, 1] * y + array[tri, 2]``.\n-        \"\"\"\n-        return self.get_cpp_triangulation().calculate_plane_coefficients(z)\n-\n-    @property\n-    def edges(self):\n-        \"\"\"\n-        Return integer array of shape (nedges, 2) containing all edges of\n-        non-masked triangles.\n-\n-        Each row defines an edge by its start point index and end point\n-        index.  Each edge appears only once, i.e. for an edge between points\n-        *i*  and *j*, there will only be either *(i, j)* or *(j, i)*.\n-        \"\"\"\n-        if self._edges is None:\n-            self._edges = self.get_cpp_triangulation().get_edges()\n-        return self._edges\n-\n-    def get_cpp_triangulation(self):\n-        \"\"\"\n-        Return the underlying C++ Triangulation object, creating it\n-        if necessary.\n-        \"\"\"\n-        from matplotlib import _tri\n-        if self._cpp_triangulation is None:\n-            self._cpp_triangulation = _tri.Triangulation(\n-                self.x, self.y, self.triangles, self.mask, self._edges,\n-                self._neighbors, not self.is_delaunay)\n-        return self._cpp_triangulation\n-\n-    def get_masked_triangles(self):\n-        \"\"\"\n-        Return an array of triangles taking the mask into account.\n-        \"\"\"\n-        if self.mask is not None:\n-            return self.triangles[~self.mask]\n-        else:\n-            return self.triangles\n-\n-    @staticmethod\n-    def get_from_args_and_kwargs(*args, **kwargs):\n-        \"\"\"\n-        Return a Triangulation object from the args and kwargs, and\n-        the remaining args and kwargs with the consumed values removed.\n-\n-        There are two alternatives: either the first argument is a\n-        Triangulation object, in which case it is returned, or the args\n-        and kwargs are sufficient to create a new Triangulation to\n-        return.  In the latter case, see Triangulation.__init__ for\n-        the possible args and kwargs.\n-        \"\"\"\n-        if isinstance(args[0], Triangulation):\n-            triangulation, *args = args\n-            if 'triangles' in kwargs:\n-                _api.warn_external(\n-                    \"Passing the keyword 'triangles' has no effect when also \"\n-                    \"passing a Triangulation\")\n-            if 'mask' in kwargs:\n-                _api.warn_external(\n-                    \"Passing the keyword 'mask' has no effect when also \"\n-                    \"passing a Triangulation\")\n-        else:\n-            x, y, triangles, mask, args, kwargs = \\\n-                Triangulation._extract_triangulation_params(args, kwargs)\n-            triangulation = Triangulation(x, y, triangles, mask)\n-        return triangulation, args, kwargs\n-\n-    @staticmethod\n-    def _extract_triangulation_params(args, kwargs):\n-        x, y, *args = args\n-        # Check triangles in kwargs then args.\n-        triangles = kwargs.pop('triangles', None)\n-        from_args = False\n-        if triangles is None and args:\n-            triangles = args[0]\n-            from_args = True\n-        if triangles is not None:\n-            try:\n-                triangles = np.asarray(triangles, dtype=np.int32)\n-            except ValueError:\n-                triangles = None\n-        if triangles is not None and (triangles.ndim != 2 or\n-                                      triangles.shape[1] != 3):\n-            triangles = None\n-        if triangles is not None and from_args:\n-            args = args[1:]  # Consumed first item in args.\n-        # Check for mask in kwargs.\n-        mask = kwargs.pop('mask', None)\n-        return x, y, triangles, mask, args, kwargs\n-\n-    def get_trifinder(self):\n-        \"\"\"\n-        Return the default `matplotlib.tri.TriFinder` of this\n-        triangulation, creating it if necessary.  This allows the same\n-        TriFinder object to be easily shared.\n-        \"\"\"\n-        if self._trifinder is None:\n-            # Default TriFinder class.\n-            from matplotlib.tri.trifinder import TrapezoidMapTriFinder\n-            self._trifinder = TrapezoidMapTriFinder(self)\n-        return self._trifinder\n-\n-    @property\n-    def neighbors(self):\n-        \"\"\"\n-        Return integer array of shape (ntri, 3) containing neighbor triangles.\n-\n-        For each triangle, the indices of the three triangles that\n-        share the same edges, or -1 if there is no such neighboring\n-        triangle.  ``neighbors[i, j]`` is the triangle that is the neighbor\n-        to the edge from point index ``triangles[i, j]`` to point index\n-        ``triangles[i, (j+1)%3]``.\n-        \"\"\"\n-        if self._neighbors is None:\n-            self._neighbors = self.get_cpp_triangulation().get_neighbors()\n-        return self._neighbors\n-\n-    def set_mask(self, mask):\n-        \"\"\"\n-        Set or clear the mask array.\n-\n-        Parameters\n-        ----------\n-        mask : None or bool array of length ntri\n-        \"\"\"\n-        if mask is None:\n-            self.mask = None\n-        else:\n-            self.mask = np.asarray(mask, dtype=bool)\n-            if self.mask.shape != (self.triangles.shape[0],):\n-                raise ValueError('mask array must have same length as '\n-                                 'triangles array')\n-\n-        # Set mask in C++ Triangulation.\n-        if self._cpp_triangulation is not None:\n-            self._cpp_triangulation.set_mask(self.mask)\n-\n-        # Clear derived fields so they are recalculated when needed.\n-        self._edges = None\n-        self._neighbors = None\n-\n-        # Recalculate TriFinder if it exists.\n-        if self._trifinder is not None:\n-            self._trifinder._initialize()\n+_api.warn_deprecated(\n+    \"3.7\",\n+    message=f\"Importing {__name__} was deprecated in Matplotlib 3.7 and will \"\n+            f\"be removed two minor releases later. All functionality is \"\n+            f\"available via the top-level module matplotlib.tri\")\ndiff --git a/lib/matplotlib/tri/tricontour.py b/lib/matplotlib/tri/tricontour.py\n--- a/lib/matplotlib/tri/tricontour.py\n+++ b/lib/matplotlib/tri/tricontour.py\n@@ -1,271 +1,9 @@\n-import numpy as np\n+from ._tricontour import *  # noqa: F401, F403\n+from matplotlib import _api\n \n-from matplotlib import _docstring\n-from matplotlib.contour import ContourSet\n-from matplotlib.tri.triangulation import Triangulation\n \n-\n-@_docstring.dedent_interpd\n-class TriContourSet(ContourSet):\n-    \"\"\"\n-    Create and store a set of contour lines or filled regions for\n-    a triangular grid.\n-\n-    This class is typically not instantiated directly by the user but by\n-    `~.Axes.tricontour` and `~.Axes.tricontourf`.\n-\n-    %(contour_set_attributes)s\n-    \"\"\"\n-    def __init__(self, ax, *args, **kwargs):\n-        \"\"\"\n-        Draw triangular grid contour lines or filled regions,\n-        depending on whether keyword arg *filled* is False\n-        (default) or True.\n-\n-        The first argument of the initializer must be an `~.axes.Axes`\n-        object.  The remaining arguments and keyword arguments\n-        are described in the docstring of `~.Axes.tricontour`.\n-        \"\"\"\n-        super().__init__(ax, *args, **kwargs)\n-\n-    def _process_args(self, *args, **kwargs):\n-        \"\"\"\n-        Process args and kwargs.\n-        \"\"\"\n-        if isinstance(args[0], TriContourSet):\n-            C = args[0]._contour_generator\n-            if self.levels is None:\n-                self.levels = args[0].levels\n-            self.zmin = args[0].zmin\n-            self.zmax = args[0].zmax\n-            self._mins = args[0]._mins\n-            self._maxs = args[0]._maxs\n-        else:\n-            from matplotlib import _tri\n-            tri, z = self._contour_args(args, kwargs)\n-            C = _tri.TriContourGenerator(tri.get_cpp_triangulation(), z)\n-            self._mins = [tri.x.min(), tri.y.min()]\n-            self._maxs = [tri.x.max(), tri.y.max()]\n-\n-        self._contour_generator = C\n-        return kwargs\n-\n-    def _contour_args(self, args, kwargs):\n-        tri, args, kwargs = Triangulation.get_from_args_and_kwargs(*args,\n-                                                                   **kwargs)\n-        z = np.ma.asarray(args[0])\n-        if z.shape != tri.x.shape:\n-            raise ValueError('z array must have same length as triangulation x'\n-                             ' and y arrays')\n-\n-        # z values must be finite, only need to check points that are included\n-        # in the triangulation.\n-        z_check = z[np.unique(tri.get_masked_triangles())]\n-        if np.ma.is_masked(z_check):\n-            raise ValueError('z must not contain masked points within the '\n-                             'triangulation')\n-        if not np.isfinite(z_check).all():\n-            raise ValueError('z array must not contain non-finite values '\n-                             'within the triangulation')\n-\n-        z = np.ma.masked_invalid(z, copy=False)\n-        self.zmax = float(z_check.max())\n-        self.zmin = float(z_check.min())\n-        if self.logscale and self.zmin <= 0:\n-            func = 'contourf' if self.filled else 'contour'\n-            raise ValueError(f'Cannot {func} log of negative values.')\n-        self._process_contour_level_args(args[1:])\n-        return (tri, z)\n-\n-\n-_docstring.interpd.update(_tricontour_doc=\"\"\"\n-Draw contour %%(type)s on an unstructured triangular grid.\n-\n-Call signatures::\n-\n-    %%(func)s(triangulation, z, [levels], ...)\n-    %%(func)s(x, y, z, [levels], *, [triangles=triangles], [mask=mask], ...)\n-\n-The triangular grid can be specified either by passing a `.Triangulation`\n-object as the first parameter, or by passing the points *x*, *y* and\n-optionally the *triangles* and a *mask*. See `.Triangulation` for an\n-explanation of these parameters. If neither of *triangulation* or\n-*triangles* are given, the triangulation is calculated on the fly.\n-\n-It is possible to pass *triangles* positionally, i.e.\n-``%%(func)s(x, y, triangles, z, ...)``. However, this is discouraged. For more\n-clarity, pass *triangles* via keyword argument.\n-\n-Parameters\n-----------\n-triangulation : `.Triangulation`, optional\n-    An already created triangular grid.\n-\n-x, y, triangles, mask\n-    Parameters defining the triangular grid. See `.Triangulation`.\n-    This is mutually exclusive with specifying *triangulation*.\n-\n-z : array-like\n-    The height values over which the contour is drawn.  Color-mapping is\n-    controlled by *cmap*, *norm*, *vmin*, and *vmax*.\n-\n-    .. note::\n-        All values in *z* must be finite. Hence, nan and inf values must\n-        either be removed or `~.Triangulation.set_mask` be used.\n-\n-levels : int or array-like, optional\n-    Determines the number and positions of the contour lines / regions.\n-\n-    If an int *n*, use `~matplotlib.ticker.MaxNLocator`, which tries to\n-    automatically choose no more than *n+1* \"nice\" contour levels between\n-    between minimum and maximum numeric values of *Z*.\n-\n-    If array-like, draw contour lines at the specified levels.  The values must\n-    be in increasing order.\n-\n-Returns\n--------\n-`~matplotlib.tri.TriContourSet`\n-\n-Other Parameters\n-----------------\n-colors : color string or sequence of colors, optional\n-    The colors of the levels, i.e., the contour %%(type)s.\n-\n-    The sequence is cycled for the levels in ascending order. If the sequence\n-    is shorter than the number of levels, it is repeated.\n-\n-    As a shortcut, single color strings may be used in place of one-element\n-    lists, i.e. ``'red'`` instead of ``['red']`` to color all levels with the\n-    same color. This shortcut does only work for color strings, not for other\n-    ways of specifying colors.\n-\n-    By default (value *None*), the colormap specified by *cmap* will be used.\n-\n-alpha : float, default: 1\n-    The alpha blending value, between 0 (transparent) and 1 (opaque).\n-\n-%(cmap_doc)s\n-\n-    This parameter is ignored if *colors* is set.\n-\n-%(norm_doc)s\n-\n-    This parameter is ignored if *colors* is set.\n-\n-%(vmin_vmax_doc)s\n-\n-    If *vmin* or *vmax* are not given, the default color scaling is based on\n-    *levels*.\n-\n-    This parameter is ignored if *colors* is set.\n-\n-origin : {*None*, 'upper', 'lower', 'image'}, default: None\n-    Determines the orientation and exact position of *z* by specifying the\n-    position of ``z[0, 0]``.  This is only relevant, if *X*, *Y* are not given.\n-\n-    - *None*: ``z[0, 0]`` is at X=0, Y=0 in the lower left corner.\n-    - 'lower': ``z[0, 0]`` is at X=0.5, Y=0.5 in the lower left corner.\n-    - 'upper': ``z[0, 0]`` is at X=N+0.5, Y=0.5 in the upper left corner.\n-    - 'image': Use the value from :rc:`image.origin`.\n-\n-extent : (x0, x1, y0, y1), optional\n-    If *origin* is not *None*, then *extent* is interpreted as in `.imshow`: it\n-    gives the outer pixel boundaries. In this case, the position of z[0, 0] is\n-    the center of the pixel, not a corner. If *origin* is *None*, then\n-    (*x0*, *y0*) is the position of z[0, 0], and (*x1*, *y1*) is the position\n-    of z[-1, -1].\n-\n-    This argument is ignored if *X* and *Y* are specified in the call to\n-    contour.\n-\n-locator : ticker.Locator subclass, optional\n-    The locator is used to determine the contour levels if they are not given\n-    explicitly via *levels*.\n-    Defaults to `~.ticker.MaxNLocator`.\n-\n-extend : {'neither', 'both', 'min', 'max'}, default: 'neither'\n-    Determines the ``%%(func)s``-coloring of values that are outside the\n-    *levels* range.\n-\n-    If 'neither', values outside the *levels* range are not colored.  If 'min',\n-    'max' or 'both', color the values below, above or below and above the\n-    *levels* range.\n-\n-    Values below ``min(levels)`` and above ``max(levels)`` are mapped to the\n-    under/over values of the `.Colormap`. Note that most colormaps do not have\n-    dedicated colors for these by default, so that the over and under values\n-    are the edge values of the colormap.  You may want to set these values\n-    explicitly using `.Colormap.set_under` and `.Colormap.set_over`.\n-\n-    .. note::\n-\n-        An existing `.TriContourSet` does not get notified if properties of its\n-        colormap are changed. Therefore, an explicit call to\n-        `.ContourSet.changed()` is needed after modifying the colormap. The\n-        explicit call can be left out, if a colorbar is assigned to the\n-        `.TriContourSet` because it internally calls `.ContourSet.changed()`.\n-\n-xunits, yunits : registered units, optional\n-    Override axis units by specifying an instance of a\n-    :class:`matplotlib.units.ConversionInterface`.\n-\n-antialiased : bool, optional\n-    Enable antialiasing, overriding the defaults.  For\n-    filled contours, the default is *True*.  For line contours,\n-    it is taken from :rc:`lines.antialiased`.\"\"\" % _docstring.interpd.params)\n-\n-\n-@_docstring.Substitution(func='tricontour', type='lines')\n-@_docstring.dedent_interpd\n-def tricontour(ax, *args, **kwargs):\n-    \"\"\"\n-    %(_tricontour_doc)s\n-\n-    linewidths : float or array-like, default: :rc:`contour.linewidth`\n-        The line width of the contour lines.\n-\n-        If a number, all levels will be plotted with this linewidth.\n-\n-        If a sequence, the levels in ascending order will be plotted with\n-        the linewidths in the order specified.\n-\n-        If None, this falls back to :rc:`lines.linewidth`.\n-\n-    linestyles : {*None*, 'solid', 'dashed', 'dashdot', 'dotted'}, optional\n-        If *linestyles* is *None*, the default is 'solid' unless the lines are\n-        monochrome.  In that case, negative contours will take their linestyle\n-        from :rc:`contour.negative_linestyle` setting.\n-\n-        *linestyles* can also be an iterable of the above strings specifying a\n-        set of linestyles to be used. If this iterable is shorter than the\n-        number of contour levels it will be repeated as necessary.\n-    \"\"\"\n-    kwargs['filled'] = False\n-    return TriContourSet(ax, *args, **kwargs)\n-\n-\n-@_docstring.Substitution(func='tricontourf', type='regions')\n-@_docstring.dedent_interpd\n-def tricontourf(ax, *args, **kwargs):\n-    \"\"\"\n-    %(_tricontour_doc)s\n-\n-    hatches : list[str], optional\n-        A list of cross hatch patterns to use on the filled areas.\n-        If None, no hatching will be added to the contour.\n-        Hatching is supported in the PostScript, PDF, SVG and Agg\n-        backends only.\n-\n-    Notes\n-    -----\n-    `.tricontourf` fills intervals that are closed at the top; that is, for\n-    boundaries *z1* and *z2*, the filled region is::\n-\n-        z1 < Z <= z2\n-\n-    except for the lowest interval, which is closed on both sides (i.e. it\n-    includes the lowest value).\n-    \"\"\"\n-    kwargs['filled'] = True\n-    return TriContourSet(ax, *args, **kwargs)\n+_api.warn_deprecated(\n+    \"3.7\",\n+    message=f\"Importing {__name__} was deprecated in Matplotlib 3.7 and will \"\n+            f\"be removed two minor releases later. All functionality is \"\n+            f\"available via the top-level module matplotlib.tri\")\ndiff --git a/lib/matplotlib/tri/trifinder.py b/lib/matplotlib/tri/trifinder.py\n--- a/lib/matplotlib/tri/trifinder.py\n+++ b/lib/matplotlib/tri/trifinder.py\n@@ -1,93 +1,9 @@\n-import numpy as np\n-\n+from ._trifinder import *  # noqa: F401, F403\n from matplotlib import _api\n-from matplotlib.tri import Triangulation\n-\n-\n-class TriFinder:\n-    \"\"\"\n-    Abstract base class for classes used to find the triangles of a\n-    Triangulation in which (x, y) points lie.\n-\n-    Rather than instantiate an object of a class derived from TriFinder, it is\n-    usually better to use the function `.Triangulation.get_trifinder`.\n-\n-    Derived classes implement __call__(x, y) where x and y are array-like point\n-    coordinates of the same shape.\n-    \"\"\"\n-\n-    def __init__(self, triangulation):\n-        _api.check_isinstance(Triangulation, triangulation=triangulation)\n-        self._triangulation = triangulation\n-\n-\n-class TrapezoidMapTriFinder(TriFinder):\n-    \"\"\"\n-    `~matplotlib.tri.TriFinder` class implemented using the trapezoid\n-    map algorithm from the book \"Computational Geometry, Algorithms and\n-    Applications\", second edition, by M. de Berg, M. van Kreveld, M. Overmars\n-    and O. Schwarzkopf.\n-\n-    The triangulation must be valid, i.e. it must not have duplicate points,\n-    triangles formed from colinear points, or overlapping triangles.  The\n-    algorithm has some tolerance to triangles formed from colinear points, but\n-    this should not be relied upon.\n-    \"\"\"\n-\n-    def __init__(self, triangulation):\n-        from matplotlib import _tri\n-        super().__init__(triangulation)\n-        self._cpp_trifinder = _tri.TrapezoidMapTriFinder(\n-            triangulation.get_cpp_triangulation())\n-        self._initialize()\n-\n-    def __call__(self, x, y):\n-        \"\"\"\n-        Return an array containing the indices of the triangles in which the\n-        specified *x*, *y* points lie, or -1 for points that do not lie within\n-        a triangle.\n-\n-        *x*, *y* are array-like x and y coordinates of the same shape and any\n-        number of dimensions.\n-\n-        Returns integer array with the same shape and *x* and *y*.\n-        \"\"\"\n-        x = np.asarray(x, dtype=np.float64)\n-        y = np.asarray(y, dtype=np.float64)\n-        if x.shape != y.shape:\n-            raise ValueError(\"x and y must be array-like with the same shape\")\n-\n-        # C++ does the heavy lifting, and expects 1D arrays.\n-        indices = (self._cpp_trifinder.find_many(x.ravel(), y.ravel())\n-                   .reshape(x.shape))\n-        return indices\n-\n-    def _get_tree_stats(self):\n-        \"\"\"\n-        Return a python list containing the statistics about the node tree:\n-            0: number of nodes (tree size)\n-            1: number of unique nodes\n-            2: number of trapezoids (tree leaf nodes)\n-            3: number of unique trapezoids\n-            4: maximum parent count (max number of times a node is repeated in\n-                   tree)\n-            5: maximum depth of tree (one more than the maximum number of\n-                   comparisons needed to search through the tree)\n-            6: mean of all trapezoid depths (one more than the average number\n-                   of comparisons needed to search through the tree)\n-        \"\"\"\n-        return self._cpp_trifinder.get_tree_stats()\n \n-    def _initialize(self):\n-        \"\"\"\n-        Initialize the underlying C++ object.  Can be called multiple times if,\n-        for example, the triangulation is modified.\n-        \"\"\"\n-        self._cpp_trifinder.initialize()\n \n-    def _print_tree(self):\n-        \"\"\"\n-        Print a text representation of the node tree, which is useful for\n-        debugging purposes.\n-        \"\"\"\n-        self._cpp_trifinder.print_tree()\n+_api.warn_deprecated(\n+    \"3.7\",\n+    message=f\"Importing {__name__} was deprecated in Matplotlib 3.7 and will \"\n+            f\"be removed two minor releases later. All functionality is \"\n+            f\"available via the top-level module matplotlib.tri\")\ndiff --git a/lib/matplotlib/tri/triinterpolate.py b/lib/matplotlib/tri/triinterpolate.py\n--- a/lib/matplotlib/tri/triinterpolate.py\n+++ b/lib/matplotlib/tri/triinterpolate.py\n@@ -1,1574 +1,9 @@\n-\"\"\"\n-Interpolation inside triangular grids.\n-\"\"\"\n-\n-import numpy as np\n-\n+from ._triinterpolate import *  # noqa: F401, F403\n from matplotlib import _api\n-from matplotlib.tri import Triangulation\n-from matplotlib.tri.trifinder import TriFinder\n-from matplotlib.tri.tritools import TriAnalyzer\n-\n-__all__ = ('TriInterpolator', 'LinearTriInterpolator', 'CubicTriInterpolator')\n-\n-\n-class TriInterpolator:\n-    \"\"\"\n-    Abstract base class for classes used to interpolate on a triangular grid.\n-\n-    Derived classes implement the following methods:\n-\n-    - ``__call__(x, y)``,\n-      where x, y are array-like point coordinates of the same shape, and\n-      that returns a masked array of the same shape containing the\n-      interpolated z-values.\n-\n-    - ``gradient(x, y)``,\n-      where x, y are array-like point coordinates of the same\n-      shape, and that returns a list of 2 masked arrays of the same shape\n-      containing the 2 derivatives of the interpolator (derivatives of\n-      interpolated z values with respect to x and y).\n-    \"\"\"\n-\n-    def __init__(self, triangulation, z, trifinder=None):\n-        _api.check_isinstance(Triangulation, triangulation=triangulation)\n-        self._triangulation = triangulation\n-\n-        self._z = np.asarray(z)\n-        if self._z.shape != self._triangulation.x.shape:\n-            raise ValueError(\"z array must have same length as triangulation x\"\n-                             \" and y arrays\")\n-\n-        _api.check_isinstance((TriFinder, None), trifinder=trifinder)\n-        self._trifinder = trifinder or self._triangulation.get_trifinder()\n-\n-        # Default scaling factors : 1.0 (= no scaling)\n-        # Scaling may be used for interpolations for which the order of\n-        # magnitude of x, y has an impact on the interpolant definition.\n-        # Please refer to :meth:`_interpolate_multikeys` for details.\n-        self._unit_x = 1.0\n-        self._unit_y = 1.0\n-\n-        # Default triangle renumbering: None (= no renumbering)\n-        # Renumbering may be used to avoid unnecessary computations\n-        # if complex calculations are done inside the Interpolator.\n-        # Please refer to :meth:`_interpolate_multikeys` for details.\n-        self._tri_renum = None\n-\n-    # __call__ and gradient docstrings are shared by all subclasses\n-    # (except, if needed, relevant additions).\n-    # However these methods are only implemented in subclasses to avoid\n-    # confusion in the documentation.\n-    _docstring__call__ = \"\"\"\n-        Returns a masked array containing interpolated values at the specified\n-        (x, y) points.\n-\n-        Parameters\n-        ----------\n-        x, y : array-like\n-            x and y coordinates of the same shape and any number of\n-            dimensions.\n-\n-        Returns\n-        -------\n-        np.ma.array\n-            Masked array of the same shape as *x* and *y*; values corresponding\n-            to (*x*, *y*) points outside of the triangulation are masked out.\n-\n-        \"\"\"\n-\n-    _docstringgradient = r\"\"\"\n-        Returns a list of 2 masked arrays containing interpolated derivatives\n-        at the specified (x, y) points.\n-\n-        Parameters\n-        ----------\n-        x, y : array-like\n-            x and y coordinates of the same shape and any number of\n-            dimensions.\n-\n-        Returns\n-        -------\n-        dzdx, dzdy : np.ma.array\n-            2 masked arrays of the same shape as *x* and *y*; values\n-            corresponding to (x, y) points outside of the triangulation\n-            are masked out.\n-            The first returned array contains the values of\n-            :math:`\\frac{\\partial z}{\\partial x}` and the second those of\n-            :math:`\\frac{\\partial z}{\\partial y}`.\n-\n-        \"\"\"\n-\n-    def _interpolate_multikeys(self, x, y, tri_index=None,\n-                               return_keys=('z',)):\n-        \"\"\"\n-        Versatile (private) method defined for all TriInterpolators.\n-\n-        :meth:`_interpolate_multikeys` is a wrapper around method\n-        :meth:`_interpolate_single_key` (to be defined in the child\n-        subclasses).\n-        :meth:`_interpolate_single_key actually performs the interpolation,\n-        but only for 1-dimensional inputs and at valid locations (inside\n-        unmasked triangles of the triangulation).\n-\n-        The purpose of :meth:`_interpolate_multikeys` is to implement the\n-        following common tasks needed in all subclasses implementations:\n-\n-        - calculation of containing triangles\n-        - dealing with more than one interpolation request at the same\n-          location (e.g., if the 2 derivatives are requested, it is\n-          unnecessary to compute the containing triangles twice)\n-        - scaling according to self._unit_x, self._unit_y\n-        - dealing with points outside of the grid (with fill value np.nan)\n-        - dealing with multi-dimensional *x*, *y* arrays: flattening for\n-          :meth:`_interpolate_params` call and final reshaping.\n-\n-        (Note that np.vectorize could do most of those things very well for\n-        you, but it does it by function evaluations over successive tuples of\n-        the input arrays. Therefore, this tends to be more time consuming than\n-        using optimized numpy functions - e.g., np.dot - which can be used\n-        easily on the flattened inputs, in the child-subclass methods\n-        :meth:`_interpolate_single_key`.)\n-\n-        It is guaranteed that the calls to :meth:`_interpolate_single_key`\n-        will be done with flattened (1-d) array-like input parameters *x*, *y*\n-        and with flattened, valid `tri_index` arrays (no -1 index allowed).\n-\n-        Parameters\n-        ----------\n-        x, y : array-like\n-            x and y coordinates where interpolated values are requested.\n-        tri_index : array-like of int, optional\n-            Array of the containing triangle indices, same shape as\n-            *x* and *y*. Defaults to None. If None, these indices\n-            will be computed by a TriFinder instance.\n-            (Note: For point outside the grid, tri_index[ipt] shall be -1).\n-        return_keys : tuple of keys from {'z', 'dzdx', 'dzdy'}\n-            Defines the interpolation arrays to return, and in which order.\n-\n-        Returns\n-        -------\n-        list of arrays\n-            Each array-like contains the expected interpolated values in the\n-            order defined by *return_keys* parameter.\n-        \"\"\"\n-        # Flattening and rescaling inputs arrays x, y\n-        # (initial shape is stored for output)\n-        x = np.asarray(x, dtype=np.float64)\n-        y = np.asarray(y, dtype=np.float64)\n-        sh_ret = x.shape\n-        if x.shape != y.shape:\n-            raise ValueError(\"x and y shall have same shapes.\"\n-                             \" Given: {0} and {1}\".format(x.shape, y.shape))\n-        x = np.ravel(x)\n-        y = np.ravel(y)\n-        x_scaled = x/self._unit_x\n-        y_scaled = y/self._unit_y\n-        size_ret = np.size(x_scaled)\n-\n-        # Computes & ravels the element indexes, extract the valid ones.\n-        if tri_index is None:\n-            tri_index = self._trifinder(x, y)\n-        else:\n-            if tri_index.shape != sh_ret:\n-                raise ValueError(\n-                    \"tri_index array is provided and shall\"\n-                    \" have same shape as x and y. Given: \"\n-                    \"{0} and {1}\".format(tri_index.shape, sh_ret))\n-            tri_index = np.ravel(tri_index)\n-\n-        mask_in = (tri_index != -1)\n-        if self._tri_renum is None:\n-            valid_tri_index = tri_index[mask_in]\n-        else:\n-            valid_tri_index = self._tri_renum[tri_index[mask_in]]\n-        valid_x = x_scaled[mask_in]\n-        valid_y = y_scaled[mask_in]\n-\n-        ret = []\n-        for return_key in return_keys:\n-            # Find the return index associated with the key.\n-            try:\n-                return_index = {'z': 0, 'dzdx': 1, 'dzdy': 2}[return_key]\n-            except KeyError as err:\n-                raise ValueError(\"return_keys items shall take values in\"\n-                                 \" {'z', 'dzdx', 'dzdy'}\") from err\n-\n-            # Sets the scale factor for f & df components\n-            scale = [1., 1./self._unit_x, 1./self._unit_y][return_index]\n-\n-            # Computes the interpolation\n-            ret_loc = np.empty(size_ret, dtype=np.float64)\n-            ret_loc[~mask_in] = np.nan\n-            ret_loc[mask_in] = self._interpolate_single_key(\n-                return_key, valid_tri_index, valid_x, valid_y) * scale\n-            ret += [np.ma.masked_invalid(ret_loc.reshape(sh_ret), copy=False)]\n-\n-        return ret\n-\n-    def _interpolate_single_key(self, return_key, tri_index, x, y):\n-        \"\"\"\n-        Interpolate at points belonging to the triangulation\n-        (inside an unmasked triangles).\n-\n-        Parameters\n-        ----------\n-        return_key : {'z', 'dzdx', 'dzdy'}\n-            The requested values (z or its derivatives).\n-        tri_index : 1D int array\n-            Valid triangle index (cannot be -1).\n-        x, y : 1D arrays, same shape as `tri_index`\n-            Valid locations where interpolation is requested.\n-\n-        Returns\n-        -------\n-        1-d array\n-            Returned array of the same size as *tri_index*\n-        \"\"\"\n-        raise NotImplementedError(\"TriInterpolator subclasses\" +\n-                                  \"should implement _interpolate_single_key!\")\n-\n-\n-class LinearTriInterpolator(TriInterpolator):\n-    \"\"\"\n-    Linear interpolator on a triangular grid.\n-\n-    Each triangle is represented by a plane so that an interpolated value at\n-    point (x, y) lies on the plane of the triangle containing (x, y).\n-    Interpolated values are therefore continuous across the triangulation, but\n-    their first derivatives are discontinuous at edges between triangles.\n-\n-    Parameters\n-    ----------\n-    triangulation : `~matplotlib.tri.Triangulation`\n-        The triangulation to interpolate over.\n-    z : (npoints,) array-like\n-        Array of values, defined at grid points, to interpolate between.\n-    trifinder : `~matplotlib.tri.TriFinder`, optional\n-        If this is not specified, the Triangulation's default TriFinder will\n-        be used by calling `.Triangulation.get_trifinder`.\n-\n-    Methods\n-    -------\n-    `__call__` (x, y) : Returns interpolated values at (x, y) points.\n-    `gradient` (x, y) : Returns interpolated derivatives at (x, y) points.\n-\n-    \"\"\"\n-    def __init__(self, triangulation, z, trifinder=None):\n-        super().__init__(triangulation, z, trifinder)\n-\n-        # Store plane coefficients for fast interpolation calculations.\n-        self._plane_coefficients = \\\n-            self._triangulation.calculate_plane_coefficients(self._z)\n-\n-    def __call__(self, x, y):\n-        return self._interpolate_multikeys(x, y, tri_index=None,\n-                                           return_keys=('z',))[0]\n-    __call__.__doc__ = TriInterpolator._docstring__call__\n-\n-    def gradient(self, x, y):\n-        return self._interpolate_multikeys(x, y, tri_index=None,\n-                                           return_keys=('dzdx', 'dzdy'))\n-    gradient.__doc__ = TriInterpolator._docstringgradient\n-\n-    def _interpolate_single_key(self, return_key, tri_index, x, y):\n-        _api.check_in_list(['z', 'dzdx', 'dzdy'], return_key=return_key)\n-        if return_key == 'z':\n-            return (self._plane_coefficients[tri_index, 0]*x +\n-                    self._plane_coefficients[tri_index, 1]*y +\n-                    self._plane_coefficients[tri_index, 2])\n-        elif return_key == 'dzdx':\n-            return self._plane_coefficients[tri_index, 0]\n-        else:  # 'dzdy'\n-            return self._plane_coefficients[tri_index, 1]\n-\n-\n-class CubicTriInterpolator(TriInterpolator):\n-    r\"\"\"\n-    Cubic interpolator on a triangular grid.\n-\n-    In one-dimension - on a segment - a cubic interpolating function is\n-    defined by the values of the function and its derivative at both ends.\n-    This is almost the same in 2D inside a triangle, except that the values\n-    of the function and its 2 derivatives have to be defined at each triangle\n-    node.\n-\n-    The CubicTriInterpolator takes the value of the function at each node -\n-    provided by the user - and internally computes the value of the\n-    derivatives, resulting in a smooth interpolation.\n-    (As a special feature, the user can also impose the value of the\n-    derivatives at each node, but this is not supposed to be the common\n-    usage.)\n-\n-    Parameters\n-    ----------\n-    triangulation : `~matplotlib.tri.Triangulation`\n-        The triangulation to interpolate over.\n-    z : (npoints,) array-like\n-        Array of values, defined at grid points, to interpolate between.\n-    kind : {'min_E', 'geom', 'user'}, optional\n-        Choice of the smoothing algorithm, in order to compute\n-        the interpolant derivatives (defaults to 'min_E'):\n-\n-        - if 'min_E': (default) The derivatives at each node is computed\n-          to minimize a bending energy.\n-        - if 'geom': The derivatives at each node is computed as a\n-          weighted average of relevant triangle normals. To be used for\n-          speed optimization (large grids).\n-        - if 'user': The user provides the argument *dz*, no computation\n-          is hence needed.\n-\n-    trifinder : `~matplotlib.tri.TriFinder`, optional\n-        If not specified, the Triangulation's default TriFinder will\n-        be used by calling `.Triangulation.get_trifinder`.\n-    dz : tuple of array-likes (dzdx, dzdy), optional\n-        Used only if  *kind* ='user'. In this case *dz* must be provided as\n-        (dzdx, dzdy) where dzdx, dzdy are arrays of the same shape as *z* and\n-        are the interpolant first derivatives at the *triangulation* points.\n-\n-    Methods\n-    -------\n-    `__call__` (x, y) : Returns interpolated values at (x, y) points.\n-    `gradient` (x, y) : Returns interpolated derivatives at (x, y) points.\n-\n-    Notes\n-    -----\n-    This note is a bit technical and details how the cubic interpolation is\n-    computed.\n-\n-    The interpolation is based on a Clough-Tocher subdivision scheme of\n-    the *triangulation* mesh (to make it clearer, each triangle of the\n-    grid will be divided in 3 child-triangles, and on each child triangle\n-    the interpolated function is a cubic polynomial of the 2 coordinates).\n-    This technique originates from FEM (Finite Element Method) analysis;\n-    the element used is a reduced Hsieh-Clough-Tocher (HCT)\n-    element. Its shape functions are described in [1]_.\n-    The assembled function is guaranteed to be C1-smooth, i.e. it is\n-    continuous and its first derivatives are also continuous (this\n-    is easy to show inside the triangles but is also true when crossing the\n-    edges).\n-\n-    In the default case (*kind* ='min_E'), the interpolant minimizes a\n-    curvature energy on the functional space generated by the HCT element\n-    shape functions - with imposed values but arbitrary derivatives at each\n-    node. The minimized functional is the integral of the so-called total\n-    curvature (implementation based on an algorithm from [2]_ - PCG sparse\n-    solver):\n-\n-        .. math::\n-\n-            E(z) = \\frac{1}{2} \\int_{\\Omega} \\left(\n-                \\left( \\frac{\\partial^2{z}}{\\partial{x}^2} \\right)^2 +\n-                \\left( \\frac{\\partial^2{z}}{\\partial{y}^2} \\right)^2 +\n-                2\\left( \\frac{\\partial^2{z}}{\\partial{y}\\partial{x}} \\right)^2\n-            \\right) dx\\,dy\n-\n-    If the case *kind* ='geom' is chosen by the user, a simple geometric\n-    approximation is used (weighted average of the triangle normal\n-    vectors), which could improve speed on very large grids.\n-\n-    References\n-    ----------\n-    .. [1] Michel Bernadou, Kamal Hassan, \"Basis functions for general\n-        Hsieh-Clough-Tocher triangles, complete or reduced.\",\n-        International Journal for Numerical Methods in Engineering,\n-        17(5):784 - 789. 2.01.\n-    .. [2] C.T. Kelley, \"Iterative Methods for Optimization\".\n-\n-    \"\"\"\n-    def __init__(self, triangulation, z, kind='min_E', trifinder=None,\n-                 dz=None):\n-        super().__init__(triangulation, z, trifinder)\n-\n-        # Loads the underlying c++ _triangulation.\n-        # (During loading, reordering of triangulation._triangles may occur so\n-        # that all final triangles are now anti-clockwise)\n-        self._triangulation.get_cpp_triangulation()\n-\n-        # To build the stiffness matrix and avoid zero-energy spurious modes\n-        # we will only store internally the valid (unmasked) triangles and\n-        # the necessary (used) points coordinates.\n-        # 2 renumbering tables need to be computed and stored:\n-        #  - a triangle renum table in order to translate the result from a\n-        #    TriFinder instance into the internal stored triangle number.\n-        #  - a node renum table to overwrite the self._z values into the new\n-        #    (used) node numbering.\n-        tri_analyzer = TriAnalyzer(self._triangulation)\n-        (compressed_triangles, compressed_x, compressed_y, tri_renum,\n-         node_renum) = tri_analyzer._get_compressed_triangulation()\n-        self._triangles = compressed_triangles\n-        self._tri_renum = tri_renum\n-        # Taking into account the node renumbering in self._z:\n-        valid_node = (node_renum != -1)\n-        self._z[node_renum[valid_node]] = self._z[valid_node]\n-\n-        # Computing scale factors\n-        self._unit_x = np.ptp(compressed_x)\n-        self._unit_y = np.ptp(compressed_y)\n-        self._pts = np.column_stack([compressed_x / self._unit_x,\n-                                     compressed_y / self._unit_y])\n-        # Computing triangle points\n-        self._tris_pts = self._pts[self._triangles]\n-        # Computing eccentricities\n-        self._eccs = self._compute_tri_eccentricities(self._tris_pts)\n-        # Computing dof estimations for HCT triangle shape function\n-        _api.check_in_list(['user', 'geom', 'min_E'], kind=kind)\n-        self._dof = self._compute_dof(kind, dz=dz)\n-        # Loading HCT element\n-        self._ReferenceElement = _ReducedHCT_Element()\n-\n-    def __call__(self, x, y):\n-        return self._interpolate_multikeys(x, y, tri_index=None,\n-                                           return_keys=('z',))[0]\n-    __call__.__doc__ = TriInterpolator._docstring__call__\n-\n-    def gradient(self, x, y):\n-        return self._interpolate_multikeys(x, y, tri_index=None,\n-                                           return_keys=('dzdx', 'dzdy'))\n-    gradient.__doc__ = TriInterpolator._docstringgradient\n-\n-    def _interpolate_single_key(self, return_key, tri_index, x, y):\n-        _api.check_in_list(['z', 'dzdx', 'dzdy'], return_key=return_key)\n-        tris_pts = self._tris_pts[tri_index]\n-        alpha = self._get_alpha_vec(x, y, tris_pts)\n-        ecc = self._eccs[tri_index]\n-        dof = np.expand_dims(self._dof[tri_index], axis=1)\n-        if return_key == 'z':\n-            return self._ReferenceElement.get_function_values(\n-                alpha, ecc, dof)\n-        else:  # 'dzdx', 'dzdy'\n-            J = self._get_jacobian(tris_pts)\n-            dzdx = self._ReferenceElement.get_function_derivatives(\n-                alpha, J, ecc, dof)\n-            if return_key == 'dzdx':\n-                return dzdx[:, 0, 0]\n-            else:\n-                return dzdx[:, 1, 0]\n-\n-    def _compute_dof(self, kind, dz=None):\n-        \"\"\"\n-        Compute and return nodal dofs according to kind.\n-\n-        Parameters\n-        ----------\n-        kind : {'min_E', 'geom', 'user'}\n-            Choice of the _DOF_estimator subclass to estimate the gradient.\n-        dz : tuple of array-likes (dzdx, dzdy), optional\n-            Used only if *kind*=user; in this case passed to the\n-            :class:`_DOF_estimator_user`.\n-\n-        Returns\n-        -------\n-        array-like, shape (npts, 2)\n-            Estimation of the gradient at triangulation nodes (stored as\n-            degree of freedoms of reduced-HCT triangle elements).\n-        \"\"\"\n-        if kind == 'user':\n-            if dz is None:\n-                raise ValueError(\"For a CubicTriInterpolator with \"\n-                                 \"*kind*='user', a valid *dz* \"\n-                                 \"argument is expected.\")\n-            TE = _DOF_estimator_user(self, dz=dz)\n-        elif kind == 'geom':\n-            TE = _DOF_estimator_geom(self)\n-        else:  # 'min_E', checked in __init__\n-            TE = _DOF_estimator_min_E(self)\n-        return TE.compute_dof_from_df()\n-\n-    @staticmethod\n-    def _get_alpha_vec(x, y, tris_pts):\n-        \"\"\"\n-        Fast (vectorized) function to compute barycentric coordinates alpha.\n-\n-        Parameters\n-        ----------\n-        x, y : array-like of dim 1 (shape (nx,))\n-            Coordinates of the points whose points barycentric coordinates are\n-            requested.\n-        tris_pts : array like of dim 3 (shape: (nx, 3, 2))\n-            Coordinates of the containing triangles apexes.\n-\n-        Returns\n-        -------\n-        array of dim 2 (shape (nx, 3))\n-            Barycentric coordinates of the points inside the containing\n-            triangles.\n-        \"\"\"\n-        ndim = tris_pts.ndim-2\n-\n-        a = tris_pts[:, 1, :] - tris_pts[:, 0, :]\n-        b = tris_pts[:, 2, :] - tris_pts[:, 0, :]\n-        abT = np.stack([a, b], axis=-1)\n-        ab = _transpose_vectorized(abT)\n-        OM = np.stack([x, y], axis=1) - tris_pts[:, 0, :]\n-\n-        metric = ab @ abT\n-        # Here we try to deal with the colinear cases.\n-        # metric_inv is in this case set to the Moore-Penrose pseudo-inverse\n-        # meaning that we will still return a set of valid barycentric\n-        # coordinates.\n-        metric_inv = _pseudo_inv22sym_vectorized(metric)\n-        Covar = ab @ _transpose_vectorized(np.expand_dims(OM, ndim))\n-        ksi = metric_inv @ Covar\n-        alpha = _to_matrix_vectorized([\n-            [1-ksi[:, 0, 0]-ksi[:, 1, 0]], [ksi[:, 0, 0]], [ksi[:, 1, 0]]])\n-        return alpha\n-\n-    @staticmethod\n-    def _get_jacobian(tris_pts):\n-        \"\"\"\n-        Fast (vectorized) function to compute triangle jacobian matrix.\n-\n-        Parameters\n-        ----------\n-        tris_pts : array like of dim 3 (shape: (nx, 3, 2))\n-            Coordinates of the containing triangles apexes.\n-\n-        Returns\n-        -------\n-        array of dim 3 (shape (nx, 2, 2))\n-            Barycentric coordinates of the points inside the containing\n-            triangles.\n-            J[itri, :, :] is the jacobian matrix at apex 0 of the triangle\n-            itri, so that the following (matrix) relationship holds:\n-               [dz/dksi] = [J] x [dz/dx]\n-            with x: global coordinates\n-                 ksi: element parametric coordinates in triangle first apex\n-                 local basis.\n-        \"\"\"\n-        a = np.array(tris_pts[:, 1, :] - tris_pts[:, 0, :])\n-        b = np.array(tris_pts[:, 2, :] - tris_pts[:, 0, :])\n-        J = _to_matrix_vectorized([[a[:, 0], a[:, 1]],\n-                                   [b[:, 0], b[:, 1]]])\n-        return J\n-\n-    @staticmethod\n-    def _compute_tri_eccentricities(tris_pts):\n-        \"\"\"\n-        Compute triangle eccentricities.\n-\n-        Parameters\n-        ----------\n-        tris_pts : array like of dim 3 (shape: (nx, 3, 2))\n-            Coordinates of the triangles apexes.\n-\n-        Returns\n-        -------\n-        array like of dim 2 (shape: (nx, 3))\n-            The so-called eccentricity parameters [1] needed for HCT triangular\n-            element.\n-        \"\"\"\n-        a = np.expand_dims(tris_pts[:, 2, :] - tris_pts[:, 1, :], axis=2)\n-        b = np.expand_dims(tris_pts[:, 0, :] - tris_pts[:, 2, :], axis=2)\n-        c = np.expand_dims(tris_pts[:, 1, :] - tris_pts[:, 0, :], axis=2)\n-        # Do not use np.squeeze, this is dangerous if only one triangle\n-        # in the triangulation...\n-        dot_a = (_transpose_vectorized(a) @ a)[:, 0, 0]\n-        dot_b = (_transpose_vectorized(b) @ b)[:, 0, 0]\n-        dot_c = (_transpose_vectorized(c) @ c)[:, 0, 0]\n-        # Note that this line will raise a warning for dot_a, dot_b or dot_c\n-        # zeros, but we choose not to support triangles with duplicate points.\n-        return _to_matrix_vectorized([[(dot_c-dot_b) / dot_a],\n-                                      [(dot_a-dot_c) / dot_b],\n-                                      [(dot_b-dot_a) / dot_c]])\n-\n-\n-# FEM element used for interpolation and for solving minimisation\n-# problem (Reduced HCT element)\n-class _ReducedHCT_Element:\n-    \"\"\"\n-    Implementation of reduced HCT triangular element with explicit shape\n-    functions.\n-\n-    Computes z, dz, d2z and the element stiffness matrix for bending energy:\n-    E(f) = integral( (d2z/dx2 + d2z/dy2)**2 dA)\n-\n-    *** Reference for the shape functions: ***\n-    [1] Basis functions for general Hsieh-Clough-Tocher _triangles, complete or\n-        reduced.\n-        Michel Bernadou, Kamal Hassan\n-        International Journal for Numerical Methods in Engineering.\n-        17(5):784 - 789.  2.01\n-\n-    *** Element description: ***\n-    9 dofs: z and dz given at 3 apex\n-    C1 (conform)\n-\n-    \"\"\"\n-    # 1) Loads matrices to generate shape functions as a function of\n-    #    triangle eccentricities - based on [1] p.11 '''\n-    M = np.array([\n-        [ 0.00, 0.00, 0.00,  4.50,  4.50, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [-0.25, 0.00, 0.00,  0.50,  1.25, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [-0.25, 0.00, 0.00,  1.25,  0.50, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.50, 1.00, 0.00, -1.50,  0.00, 3.00, 3.00, 0.00, 0.00, 3.00],\n-        [ 0.00, 0.00, 0.00, -0.25,  0.25, 0.00, 1.00, 0.00, 0.00, 0.50],\n-        [ 0.25, 0.00, 0.00, -0.50, -0.25, 1.00, 0.00, 0.00, 0.00, 1.00],\n-        [ 0.50, 0.00, 1.00,  0.00, -1.50, 0.00, 0.00, 3.00, 3.00, 3.00],\n-        [ 0.25, 0.00, 0.00, -0.25, -0.50, 0.00, 0.00, 0.00, 1.00, 1.00],\n-        [ 0.00, 0.00, 0.00,  0.25, -0.25, 0.00, 0.00, 1.00, 0.00, 0.50]])\n-    M0 = np.array([\n-        [ 0.00, 0.00, 0.00,  0.00,  0.00, 0.00, 0.00, 0.00, 0.00,  0.00],\n-        [ 0.00, 0.00, 0.00,  0.00,  0.00, 0.00, 0.00, 0.00, 0.00,  0.00],\n-        [ 0.00, 0.00, 0.00,  0.00,  0.00, 0.00, 0.00, 0.00, 0.00,  0.00],\n-        [-1.00, 0.00, 0.00,  1.50,  1.50, 0.00, 0.00, 0.00, 0.00, -3.00],\n-        [-0.50, 0.00, 0.00,  0.75,  0.75, 0.00, 0.00, 0.00, 0.00, -1.50],\n-        [ 0.00, 0.00, 0.00,  0.00,  0.00, 0.00, 0.00, 0.00, 0.00,  0.00],\n-        [ 1.00, 0.00, 0.00, -1.50, -1.50, 0.00, 0.00, 0.00, 0.00,  3.00],\n-        [ 0.00, 0.00, 0.00,  0.00,  0.00, 0.00, 0.00, 0.00, 0.00,  0.00],\n-        [ 0.50, 0.00, 0.00, -0.75, -0.75, 0.00, 0.00, 0.00, 0.00,  1.50]])\n-    M1 = np.array([\n-        [-0.50, 0.00, 0.00,  1.50, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [-0.25, 0.00, 0.00,  0.75, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.50, 0.00, 0.00, -1.50, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.25, 0.00, 0.00, -0.75, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]])\n-    M2 = np.array([\n-        [ 0.50, 0.00, 0.00, 0.00, -1.50, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.25, 0.00, 0.00, 0.00, -0.75, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.00, 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [-0.50, 0.00, 0.00, 0.00,  1.50, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.00, 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [-0.25, 0.00, 0.00, 0.00,  0.75, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.00, 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.00, 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n-        [ 0.00, 0.00, 0.00, 0.00,  0.00, 0.00, 0.00, 0.00, 0.00, 0.00]])\n-\n-    # 2) Loads matrices to rotate components of gradient & Hessian\n-    #    vectors in the reference basis of triangle first apex (a0)\n-    rotate_dV = np.array([[ 1.,  0.], [ 0.,  1.],\n-                          [ 0.,  1.], [-1., -1.],\n-                          [-1., -1.], [ 1.,  0.]])\n-\n-    rotate_d2V = np.array([[1., 0., 0.], [0., 1., 0.], [ 0.,  0.,  1.],\n-                           [0., 1., 0.], [1., 1., 1.], [ 0., -2., -1.],\n-                           [1., 1., 1.], [1., 0., 0.], [-2.,  0., -1.]])\n-\n-    # 3) Loads Gauss points & weights on the 3 sub-_triangles for P2\n-    #    exact integral - 3 points on each subtriangles.\n-    # NOTE: as the 2nd derivative is discontinuous , we really need those 9\n-    # points!\n-    n_gauss = 9\n-    gauss_pts = np.array([[13./18.,  4./18.,  1./18.],\n-                          [ 4./18., 13./18.,  1./18.],\n-                          [ 7./18.,  7./18.,  4./18.],\n-                          [ 1./18., 13./18.,  4./18.],\n-                          [ 1./18.,  4./18., 13./18.],\n-                          [ 4./18.,  7./18.,  7./18.],\n-                          [ 4./18.,  1./18., 13./18.],\n-                          [13./18.,  1./18.,  4./18.],\n-                          [ 7./18.,  4./18.,  7./18.]], dtype=np.float64)\n-    gauss_w = np.ones([9], dtype=np.float64) / 9.\n-\n-    #  4) Stiffness matrix for curvature energy\n-    E = np.array([[1., 0., 0.], [0., 1., 0.], [0., 0., 2.]])\n-\n-    #  5) Loads the matrix to compute DOF_rot from tri_J at apex 0\n-    J0_to_J1 = np.array([[-1.,  1.], [-1.,  0.]])\n-    J0_to_J2 = np.array([[ 0., -1.], [ 1., -1.]])\n-\n-    def get_function_values(self, alpha, ecc, dofs):\n-        \"\"\"\n-        Parameters\n-        ----------\n-        alpha : is a (N x 3 x 1) array (array of column-matrices) of\n-        barycentric coordinates,\n-        ecc : is a (N x 3 x 1) array (array of column-matrices) of triangle\n-        eccentricities,\n-        dofs : is a (N x 1 x 9) arrays (arrays of row-matrices) of computed\n-        degrees of freedom.\n-\n-        Returns\n-        -------\n-        Returns the N-array of interpolated function values.\n-        \"\"\"\n-        subtri = np.argmin(alpha, axis=1)[:, 0]\n-        ksi = _roll_vectorized(alpha, -subtri, axis=0)\n-        E = _roll_vectorized(ecc, -subtri, axis=0)\n-        x = ksi[:, 0, 0]\n-        y = ksi[:, 1, 0]\n-        z = ksi[:, 2, 0]\n-        x_sq = x*x\n-        y_sq = y*y\n-        z_sq = z*z\n-        V = _to_matrix_vectorized([\n-            [x_sq*x], [y_sq*y], [z_sq*z], [x_sq*z], [x_sq*y], [y_sq*x],\n-            [y_sq*z], [z_sq*y], [z_sq*x], [x*y*z]])\n-        prod = self.M @ V\n-        prod += _scalar_vectorized(E[:, 0, 0], self.M0 @ V)\n-        prod += _scalar_vectorized(E[:, 1, 0], self.M1 @ V)\n-        prod += _scalar_vectorized(E[:, 2, 0], self.M2 @ V)\n-        s = _roll_vectorized(prod, 3*subtri, axis=0)\n-        return (dofs @ s)[:, 0, 0]\n-\n-    def get_function_derivatives(self, alpha, J, ecc, dofs):\n-        \"\"\"\n-        Parameters\n-        ----------\n-        *alpha* is a (N x 3 x 1) array (array of column-matrices of\n-        barycentric coordinates)\n-        *J* is a (N x 2 x 2) array of jacobian matrices (jacobian matrix at\n-        triangle first apex)\n-        *ecc* is a (N x 3 x 1) array (array of column-matrices of triangle\n-        eccentricities)\n-        *dofs* is a (N x 1 x 9) arrays (arrays of row-matrices) of computed\n-        degrees of freedom.\n-\n-        Returns\n-        -------\n-        Returns the values of interpolated function derivatives [dz/dx, dz/dy]\n-        in global coordinates at locations alpha, as a column-matrices of\n-        shape (N x 2 x 1).\n-        \"\"\"\n-        subtri = np.argmin(alpha, axis=1)[:, 0]\n-        ksi = _roll_vectorized(alpha, -subtri, axis=0)\n-        E = _roll_vectorized(ecc, -subtri, axis=0)\n-        x = ksi[:, 0, 0]\n-        y = ksi[:, 1, 0]\n-        z = ksi[:, 2, 0]\n-        x_sq = x*x\n-        y_sq = y*y\n-        z_sq = z*z\n-        dV = _to_matrix_vectorized([\n-            [    -3.*x_sq,     -3.*x_sq],\n-            [     3.*y_sq,           0.],\n-            [          0.,      3.*z_sq],\n-            [     -2.*x*z, -2.*x*z+x_sq],\n-            [-2.*x*y+x_sq,      -2.*x*y],\n-            [ 2.*x*y-y_sq,        -y_sq],\n-            [      2.*y*z,         y_sq],\n-            [        z_sq,       2.*y*z],\n-            [       -z_sq,  2.*x*z-z_sq],\n-            [     x*z-y*z,      x*y-y*z]])\n-        # Puts back dV in first apex basis\n-        dV = dV @ _extract_submatrices(\n-            self.rotate_dV, subtri, block_size=2, axis=0)\n-\n-        prod = self.M @ dV\n-        prod += _scalar_vectorized(E[:, 0, 0], self.M0 @ dV)\n-        prod += _scalar_vectorized(E[:, 1, 0], self.M1 @ dV)\n-        prod += _scalar_vectorized(E[:, 2, 0], self.M2 @ dV)\n-        dsdksi = _roll_vectorized(prod, 3*subtri, axis=0)\n-        dfdksi = dofs @ dsdksi\n-        # In global coordinates:\n-        # Here we try to deal with the simplest colinear cases, returning a\n-        # null matrix.\n-        J_inv = _safe_inv22_vectorized(J)\n-        dfdx = J_inv @ _transpose_vectorized(dfdksi)\n-        return dfdx\n-\n-    def get_function_hessians(self, alpha, J, ecc, dofs):\n-        \"\"\"\n-        Parameters\n-        ----------\n-        *alpha* is a (N x 3 x 1) array (array of column-matrices) of\n-        barycentric coordinates\n-        *J* is a (N x 2 x 2) array of jacobian matrices (jacobian matrix at\n-        triangle first apex)\n-        *ecc* is a (N x 3 x 1) array (array of column-matrices) of triangle\n-        eccentricities\n-        *dofs* is a (N x 1 x 9) arrays (arrays of row-matrices) of computed\n-        degrees of freedom.\n-\n-        Returns\n-        -------\n-        Returns the values of interpolated function 2nd-derivatives\n-        [d2z/dx2, d2z/dy2, d2z/dxdy] in global coordinates at locations alpha,\n-        as a column-matrices of shape (N x 3 x 1).\n-        \"\"\"\n-        d2sdksi2 = self.get_d2Sidksij2(alpha, ecc)\n-        d2fdksi2 = dofs @ d2sdksi2\n-        H_rot = self.get_Hrot_from_J(J)\n-        d2fdx2 = d2fdksi2 @ H_rot\n-        return _transpose_vectorized(d2fdx2)\n-\n-    def get_d2Sidksij2(self, alpha, ecc):\n-        \"\"\"\n-        Parameters\n-        ----------\n-        *alpha* is a (N x 3 x 1) array (array of column-matrices) of\n-        barycentric coordinates\n-        *ecc* is a (N x 3 x 1) array (array of column-matrices) of triangle\n-        eccentricities\n-\n-        Returns\n-        -------\n-        Returns the arrays d2sdksi2 (N x 3 x 1) Hessian of shape functions\n-        expressed in covariant coordinates in first apex basis.\n-        \"\"\"\n-        subtri = np.argmin(alpha, axis=1)[:, 0]\n-        ksi = _roll_vectorized(alpha, -subtri, axis=0)\n-        E = _roll_vectorized(ecc, -subtri, axis=0)\n-        x = ksi[:, 0, 0]\n-        y = ksi[:, 1, 0]\n-        z = ksi[:, 2, 0]\n-        d2V = _to_matrix_vectorized([\n-            [     6.*x,      6.*x,      6.*x],\n-            [     6.*y,        0.,        0.],\n-            [       0.,      6.*z,        0.],\n-            [     2.*z, 2.*z-4.*x, 2.*z-2.*x],\n-            [2.*y-4.*x,      2.*y, 2.*y-2.*x],\n-            [2.*x-4.*y,        0.,     -2.*y],\n-            [     2.*z,        0.,      2.*y],\n-            [       0.,      2.*y,      2.*z],\n-            [       0., 2.*x-4.*z,     -2.*z],\n-            [    -2.*z,     -2.*y,     x-y-z]])\n-        # Puts back d2V in first apex basis\n-        d2V = d2V @ _extract_submatrices(\n-            self.rotate_d2V, subtri, block_size=3, axis=0)\n-        prod = self.M @ d2V\n-        prod += _scalar_vectorized(E[:, 0, 0], self.M0 @ d2V)\n-        prod += _scalar_vectorized(E[:, 1, 0], self.M1 @ d2V)\n-        prod += _scalar_vectorized(E[:, 2, 0], self.M2 @ d2V)\n-        d2sdksi2 = _roll_vectorized(prod, 3*subtri, axis=0)\n-        return d2sdksi2\n-\n-    def get_bending_matrices(self, J, ecc):\n-        \"\"\"\n-        Parameters\n-        ----------\n-        *J* is a (N x 2 x 2) array of jacobian matrices (jacobian matrix at\n-        triangle first apex)\n-        *ecc* is a (N x 3 x 1) array (array of column-matrices) of triangle\n-        eccentricities\n-\n-        Returns\n-        -------\n-        Returns the element K matrices for bending energy expressed in\n-        GLOBAL nodal coordinates.\n-        K_ij = integral [ (d2zi/dx2 + d2zi/dy2) * (d2zj/dx2 + d2zj/dy2) dA]\n-        tri_J is needed to rotate dofs from local basis to global basis\n-        \"\"\"\n-        n = np.size(ecc, 0)\n-\n-        # 1) matrix to rotate dofs in global coordinates\n-        J1 = self.J0_to_J1 @ J\n-        J2 = self.J0_to_J2 @ J\n-        DOF_rot = np.zeros([n, 9, 9], dtype=np.float64)\n-        DOF_rot[:, 0, 0] = 1\n-        DOF_rot[:, 3, 3] = 1\n-        DOF_rot[:, 6, 6] = 1\n-        DOF_rot[:, 1:3, 1:3] = J\n-        DOF_rot[:, 4:6, 4:6] = J1\n-        DOF_rot[:, 7:9, 7:9] = J2\n-\n-        # 2) matrix to rotate Hessian in global coordinates.\n-        H_rot, area = self.get_Hrot_from_J(J, return_area=True)\n-\n-        # 3) Computes stiffness matrix\n-        # Gauss quadrature.\n-        K = np.zeros([n, 9, 9], dtype=np.float64)\n-        weights = self.gauss_w\n-        pts = self.gauss_pts\n-        for igauss in range(self.n_gauss):\n-            alpha = np.tile(pts[igauss, :], n).reshape(n, 3)\n-            alpha = np.expand_dims(alpha, 2)\n-            weight = weights[igauss]\n-            d2Skdksi2 = self.get_d2Sidksij2(alpha, ecc)\n-            d2Skdx2 = d2Skdksi2 @ H_rot\n-            K += weight * (d2Skdx2 @ self.E @ _transpose_vectorized(d2Skdx2))\n-\n-        # 4) With nodal (not elem) dofs\n-        K = _transpose_vectorized(DOF_rot) @ K @ DOF_rot\n-\n-        # 5) Need the area to compute total element energy\n-        return _scalar_vectorized(area, K)\n-\n-    def get_Hrot_from_J(self, J, return_area=False):\n-        \"\"\"\n-        Parameters\n-        ----------\n-        *J* is a (N x 2 x 2) array of jacobian matrices (jacobian matrix at\n-        triangle first apex)\n-\n-        Returns\n-        -------\n-        Returns H_rot used to rotate Hessian from local basis of first apex,\n-        to global coordinates.\n-        if *return_area* is True, returns also the triangle area (0.5*det(J))\n-        \"\"\"\n-        # Here we try to deal with the simplest colinear cases; a null\n-        # energy and area is imposed.\n-        J_inv = _safe_inv22_vectorized(J)\n-        Ji00 = J_inv[:, 0, 0]\n-        Ji11 = J_inv[:, 1, 1]\n-        Ji10 = J_inv[:, 1, 0]\n-        Ji01 = J_inv[:, 0, 1]\n-        H_rot = _to_matrix_vectorized([\n-            [Ji00*Ji00, Ji10*Ji10, Ji00*Ji10],\n-            [Ji01*Ji01, Ji11*Ji11, Ji01*Ji11],\n-            [2*Ji00*Ji01, 2*Ji11*Ji10, Ji00*Ji11+Ji10*Ji01]])\n-        if not return_area:\n-            return H_rot\n-        else:\n-            area = 0.5 * (J[:, 0, 0]*J[:, 1, 1] - J[:, 0, 1]*J[:, 1, 0])\n-            return H_rot, area\n-\n-    def get_Kff_and_Ff(self, J, ecc, triangles, Uc):\n-        \"\"\"\n-        Build K and F for the following elliptic formulation:\n-        minimization of curvature energy with value of function at node\n-        imposed and derivatives 'free'.\n-\n-        Build the global Kff matrix in cco format.\n-        Build the full Ff vec Ff = - Kfc x Uc.\n-\n-        Parameters\n-        ----------\n-        *J* is a (N x 2 x 2) array of jacobian matrices (jacobian matrix at\n-        triangle first apex)\n-        *ecc* is a (N x 3 x 1) array (array of column-matrices) of triangle\n-        eccentricities\n-        *triangles* is a (N x 3) array of nodes indexes.\n-        *Uc* is (N x 3) array of imposed displacements at nodes\n-\n-        Returns\n-        -------\n-        (Kff_rows, Kff_cols, Kff_vals) Kff matrix in coo format - Duplicate\n-        (row, col) entries must be summed.\n-        Ff: force vector - dim npts * 3\n-        \"\"\"\n-        ntri = np.size(ecc, 0)\n-        vec_range = np.arange(ntri, dtype=np.int32)\n-        c_indices = np.full(ntri, -1, dtype=np.int32)  # for unused dofs, -1\n-        f_dof = [1, 2, 4, 5, 7, 8]\n-        c_dof = [0, 3, 6]\n-\n-        # vals, rows and cols indices in global dof numbering\n-        f_dof_indices = _to_matrix_vectorized([[\n-            c_indices, triangles[:, 0]*2, triangles[:, 0]*2+1,\n-            c_indices, triangles[:, 1]*2, triangles[:, 1]*2+1,\n-            c_indices, triangles[:, 2]*2, triangles[:, 2]*2+1]])\n-\n-        expand_indices = np.ones([ntri, 9, 1], dtype=np.int32)\n-        f_row_indices = _transpose_vectorized(expand_indices @ f_dof_indices)\n-        f_col_indices = expand_indices @ f_dof_indices\n-        K_elem = self.get_bending_matrices(J, ecc)\n-\n-        # Extracting sub-matrices\n-        # Explanation & notations:\n-        # * Subscript f denotes 'free' degrees of freedom (i.e. dz/dx, dz/dx)\n-        # * Subscript c denotes 'condensated' (imposed) degrees of freedom\n-        #    (i.e. z at all nodes)\n-        # * F = [Ff, Fc] is the force vector\n-        # * U = [Uf, Uc] is the imposed dof vector\n-        #        [ Kff Kfc ]\n-        # * K =  [         ]  is the laplacian stiffness matrix\n-        #        [ Kcf Kff ]\n-        # * As F = K x U one gets straightforwardly: Ff = - Kfc x Uc\n-\n-        # Computing Kff stiffness matrix in sparse coo format\n-        Kff_vals = np.ravel(K_elem[np.ix_(vec_range, f_dof, f_dof)])\n-        Kff_rows = np.ravel(f_row_indices[np.ix_(vec_range, f_dof, f_dof)])\n-        Kff_cols = np.ravel(f_col_indices[np.ix_(vec_range, f_dof, f_dof)])\n-\n-        # Computing Ff force vector in sparse coo format\n-        Kfc_elem = K_elem[np.ix_(vec_range, f_dof, c_dof)]\n-        Uc_elem = np.expand_dims(Uc, axis=2)\n-        Ff_elem = -(Kfc_elem @ Uc_elem)[:, :, 0]\n-        Ff_indices = f_dof_indices[np.ix_(vec_range, [0], f_dof)][:, 0, :]\n-\n-        # Extracting Ff force vector in dense format\n-        # We have to sum duplicate indices -  using bincount\n-        Ff = np.bincount(np.ravel(Ff_indices), weights=np.ravel(Ff_elem))\n-        return Kff_rows, Kff_cols, Kff_vals, Ff\n-\n-\n-# :class:_DOF_estimator, _DOF_estimator_user, _DOF_estimator_geom,\n-# _DOF_estimator_min_E\n-# Private classes used to compute the degree of freedom of each triangular\n-# element for the TriCubicInterpolator.\n-class _DOF_estimator:\n-    \"\"\"\n-    Abstract base class for classes used to estimate a function's first\n-    derivatives, and deduce the dofs for a CubicTriInterpolator using a\n-    reduced HCT element formulation.\n-\n-    Derived classes implement ``compute_df(self, **kwargs)``, returning\n-    ``np.vstack([dfx, dfy]).T`` where ``dfx, dfy`` are the estimation of the 2\n-    gradient coordinates.\n-    \"\"\"\n-    def __init__(self, interpolator, **kwargs):\n-        _api.check_isinstance(CubicTriInterpolator, interpolator=interpolator)\n-        self._pts = interpolator._pts\n-        self._tris_pts = interpolator._tris_pts\n-        self.z = interpolator._z\n-        self._triangles = interpolator._triangles\n-        (self._unit_x, self._unit_y) = (interpolator._unit_x,\n-                                        interpolator._unit_y)\n-        self.dz = self.compute_dz(**kwargs)\n-        self.compute_dof_from_df()\n-\n-    def compute_dz(self, **kwargs):\n-        raise NotImplementedError\n-\n-    def compute_dof_from_df(self):\n-        \"\"\"\n-        Compute reduced-HCT elements degrees of freedom, from the gradient.\n-        \"\"\"\n-        J = CubicTriInterpolator._get_jacobian(self._tris_pts)\n-        tri_z = self.z[self._triangles]\n-        tri_dz = self.dz[self._triangles]\n-        tri_dof = self.get_dof_vec(tri_z, tri_dz, J)\n-        return tri_dof\n-\n-    @staticmethod\n-    def get_dof_vec(tri_z, tri_dz, J):\n-        \"\"\"\n-        Compute the dof vector of a triangle, from the value of f, df and\n-        of the local Jacobian at each node.\n-\n-        Parameters\n-        ----------\n-        tri_z : shape (3,) array\n-            f nodal values.\n-        tri_dz : shape (3, 2) array\n-            df/dx, df/dy nodal values.\n-        J\n-            Jacobian matrix in local basis of apex 0.\n-\n-        Returns\n-        -------\n-        dof : shape (9,) array\n-            For each apex ``iapex``::\n-\n-                dof[iapex*3+0] = f(Ai)\n-                dof[iapex*3+1] = df(Ai).(AiAi+)\n-                dof[iapex*3+2] = df(Ai).(AiAi-)\n-        \"\"\"\n-        npt = tri_z.shape[0]\n-        dof = np.zeros([npt, 9], dtype=np.float64)\n-        J1 = _ReducedHCT_Element.J0_to_J1 @ J\n-        J2 = _ReducedHCT_Element.J0_to_J2 @ J\n-\n-        col0 = J @ np.expand_dims(tri_dz[:, 0, :], axis=2)\n-        col1 = J1 @ np.expand_dims(tri_dz[:, 1, :], axis=2)\n-        col2 = J2 @ np.expand_dims(tri_dz[:, 2, :], axis=2)\n-\n-        dfdksi = _to_matrix_vectorized([\n-            [col0[:, 0, 0], col1[:, 0, 0], col2[:, 0, 0]],\n-            [col0[:, 1, 0], col1[:, 1, 0], col2[:, 1, 0]]])\n-        dof[:, 0:7:3] = tri_z\n-        dof[:, 1:8:3] = dfdksi[:, 0]\n-        dof[:, 2:9:3] = dfdksi[:, 1]\n-        return dof\n-\n-\n-class _DOF_estimator_user(_DOF_estimator):\n-    \"\"\"dz is imposed by user; accounts for scaling if any.\"\"\"\n-\n-    def compute_dz(self, dz):\n-        (dzdx, dzdy) = dz\n-        dzdx = dzdx * self._unit_x\n-        dzdy = dzdy * self._unit_y\n-        return np.vstack([dzdx, dzdy]).T\n-\n-\n-class _DOF_estimator_geom(_DOF_estimator):\n-    \"\"\"Fast 'geometric' approximation, recommended for large arrays.\"\"\"\n-\n-    def compute_dz(self):\n-        \"\"\"\n-        self.df is computed as weighted average of _triangles sharing a common\n-        node. On each triangle itri f is first assumed linear (= ~f), which\n-        allows to compute d~f[itri]\n-        Then the following approximation of df nodal values is then proposed:\n-            f[ipt] = SUM ( w[itri] x d~f[itri] , for itri sharing apex ipt)\n-        The weighted coeff. w[itri] are proportional to the angle of the\n-        triangle itri at apex ipt\n-        \"\"\"\n-        el_geom_w = self.compute_geom_weights()\n-        el_geom_grad = self.compute_geom_grads()\n-\n-        # Sum of weights coeffs\n-        w_node_sum = np.bincount(np.ravel(self._triangles),\n-                                 weights=np.ravel(el_geom_w))\n-\n-        # Sum of weighted df = (dfx, dfy)\n-        dfx_el_w = np.empty_like(el_geom_w)\n-        dfy_el_w = np.empty_like(el_geom_w)\n-        for iapex in range(3):\n-            dfx_el_w[:, iapex] = el_geom_w[:, iapex]*el_geom_grad[:, 0]\n-            dfy_el_w[:, iapex] = el_geom_w[:, iapex]*el_geom_grad[:, 1]\n-        dfx_node_sum = np.bincount(np.ravel(self._triangles),\n-                                   weights=np.ravel(dfx_el_w))\n-        dfy_node_sum = np.bincount(np.ravel(self._triangles),\n-                                   weights=np.ravel(dfy_el_w))\n-\n-        # Estimation of df\n-        dfx_estim = dfx_node_sum/w_node_sum\n-        dfy_estim = dfy_node_sum/w_node_sum\n-        return np.vstack([dfx_estim, dfy_estim]).T\n-\n-    def compute_geom_weights(self):\n-        \"\"\"\n-        Build the (nelems, 3) weights coeffs of _triangles angles,\n-        renormalized so that np.sum(weights, axis=1) == np.ones(nelems)\n-        \"\"\"\n-        weights = np.zeros([np.size(self._triangles, 0), 3])\n-        tris_pts = self._tris_pts\n-        for ipt in range(3):\n-            p0 = tris_pts[:, ipt % 3, :]\n-            p1 = tris_pts[:, (ipt+1) % 3, :]\n-            p2 = tris_pts[:, (ipt-1) % 3, :]\n-            alpha1 = np.arctan2(p1[:, 1]-p0[:, 1], p1[:, 0]-p0[:, 0])\n-            alpha2 = np.arctan2(p2[:, 1]-p0[:, 1], p2[:, 0]-p0[:, 0])\n-            # In the below formula we could take modulo 2. but\n-            # modulo 1. is safer regarding round-off errors (flat triangles).\n-            angle = np.abs(((alpha2-alpha1) / np.pi) % 1)\n-            # Weight proportional to angle up np.pi/2; null weight for\n-            # degenerated cases 0 and np.pi (note that *angle* is normalized\n-            # by np.pi).\n-            weights[:, ipt] = 0.5 - np.abs(angle-0.5)\n-        return weights\n-\n-    def compute_geom_grads(self):\n-        \"\"\"\n-        Compute the (global) gradient component of f assumed linear (~f).\n-        returns array df of shape (nelems, 2)\n-        df[ielem].dM[ielem] = dz[ielem] i.e. df = dz x dM = dM.T^-1 x dz\n-        \"\"\"\n-        tris_pts = self._tris_pts\n-        tris_f = self.z[self._triangles]\n-\n-        dM1 = tris_pts[:, 1, :] - tris_pts[:, 0, :]\n-        dM2 = tris_pts[:, 2, :] - tris_pts[:, 0, :]\n-        dM = np.dstack([dM1, dM2])\n-        # Here we try to deal with the simplest colinear cases: a null\n-        # gradient is assumed in this case.\n-        dM_inv = _safe_inv22_vectorized(dM)\n-\n-        dZ1 = tris_f[:, 1] - tris_f[:, 0]\n-        dZ2 = tris_f[:, 2] - tris_f[:, 0]\n-        dZ = np.vstack([dZ1, dZ2]).T\n-        df = np.empty_like(dZ)\n-\n-        # With np.einsum: could be ej,eji -> ej\n-        df[:, 0] = dZ[:, 0]*dM_inv[:, 0, 0] + dZ[:, 1]*dM_inv[:, 1, 0]\n-        df[:, 1] = dZ[:, 0]*dM_inv[:, 0, 1] + dZ[:, 1]*dM_inv[:, 1, 1]\n-        return df\n-\n-\n-class _DOF_estimator_min_E(_DOF_estimator_geom):\n-    \"\"\"\n-    The 'smoothest' approximation, df is computed through global minimization\n-    of the bending energy:\n-      E(f) = integral[(d2z/dx2 + d2z/dy2 + 2 d2z/dxdy)**2 dA]\n-    \"\"\"\n-    def __init__(self, Interpolator):\n-        self._eccs = Interpolator._eccs\n-        super().__init__(Interpolator)\n-\n-    def compute_dz(self):\n-        \"\"\"\n-        Elliptic solver for bending energy minimization.\n-        Uses a dedicated 'toy' sparse Jacobi PCG solver.\n-        \"\"\"\n-        # Initial guess for iterative PCG solver.\n-        dz_init = super().compute_dz()\n-        Uf0 = np.ravel(dz_init)\n-\n-        reference_element = _ReducedHCT_Element()\n-        J = CubicTriInterpolator._get_jacobian(self._tris_pts)\n-        eccs = self._eccs\n-        triangles = self._triangles\n-        Uc = self.z[self._triangles]\n-\n-        # Building stiffness matrix and force vector in coo format\n-        Kff_rows, Kff_cols, Kff_vals, Ff = reference_element.get_Kff_and_Ff(\n-            J, eccs, triangles, Uc)\n-\n-        # Building sparse matrix and solving minimization problem\n-        # We could use scipy.sparse direct solver; however to avoid this\n-        # external dependency an implementation of a simple PCG solver with\n-        # a simple diagonal Jacobi preconditioner is implemented.\n-        tol = 1.e-10\n-        n_dof = Ff.shape[0]\n-        Kff_coo = _Sparse_Matrix_coo(Kff_vals, Kff_rows, Kff_cols,\n-                                     shape=(n_dof, n_dof))\n-        Kff_coo.compress_csc()\n-        Uf, err = _cg(A=Kff_coo, b=Ff, x0=Uf0, tol=tol)\n-        # If the PCG did not converge, we return the best guess between Uf0\n-        # and Uf.\n-        err0 = np.linalg.norm(Kff_coo.dot(Uf0) - Ff)\n-        if err0 < err:\n-            # Maybe a good occasion to raise a warning here ?\n-            _api.warn_external(\"In TriCubicInterpolator initialization, \"\n-                               \"PCG sparse solver did not converge after \"\n-                               \"1000 iterations. `geom` approximation is \"\n-                               \"used instead of `min_E`\")\n-            Uf = Uf0\n-\n-        # Building dz from Uf\n-        dz = np.empty([self._pts.shape[0], 2], dtype=np.float64)\n-        dz[:, 0] = Uf[::2]\n-        dz[:, 1] = Uf[1::2]\n-        return dz\n-\n-\n-# The following private :class:_Sparse_Matrix_coo and :func:_cg provide\n-# a PCG sparse solver for (symmetric) elliptic problems.\n-class _Sparse_Matrix_coo:\n-    def __init__(self, vals, rows, cols, shape):\n-        \"\"\"\n-        Create a sparse matrix in coo format.\n-        *vals*: arrays of values of non-null entries of the matrix\n-        *rows*: int arrays of rows of non-null entries of the matrix\n-        *cols*: int arrays of cols of non-null entries of the matrix\n-        *shape*: 2-tuple (n, m) of matrix shape\n-        \"\"\"\n-        self.n, self.m = shape\n-        self.vals = np.asarray(vals, dtype=np.float64)\n-        self.rows = np.asarray(rows, dtype=np.int32)\n-        self.cols = np.asarray(cols, dtype=np.int32)\n-\n-    def dot(self, V):\n-        \"\"\"\n-        Dot product of self by a vector *V* in sparse-dense to dense format\n-        *V* dense vector of shape (self.m,).\n-        \"\"\"\n-        assert V.shape == (self.m,)\n-        return np.bincount(self.rows,\n-                           weights=self.vals*V[self.cols],\n-                           minlength=self.m)\n-\n-    def compress_csc(self):\n-        \"\"\"\n-        Compress rows, cols, vals / summing duplicates. Sort for csc format.\n-        \"\"\"\n-        _, unique, indices = np.unique(\n-            self.rows + self.n*self.cols,\n-            return_index=True, return_inverse=True)\n-        self.rows = self.rows[unique]\n-        self.cols = self.cols[unique]\n-        self.vals = np.bincount(indices, weights=self.vals)\n-\n-    def compress_csr(self):\n-        \"\"\"\n-        Compress rows, cols, vals / summing duplicates. Sort for csr format.\n-        \"\"\"\n-        _, unique, indices = np.unique(\n-            self.m*self.rows + self.cols,\n-            return_index=True, return_inverse=True)\n-        self.rows = self.rows[unique]\n-        self.cols = self.cols[unique]\n-        self.vals = np.bincount(indices, weights=self.vals)\n-\n-    def to_dense(self):\n-        \"\"\"\n-        Return a dense matrix representing self, mainly for debugging purposes.\n-        \"\"\"\n-        ret = np.zeros([self.n, self.m], dtype=np.float64)\n-        nvals = self.vals.size\n-        for i in range(nvals):\n-            ret[self.rows[i], self.cols[i]] += self.vals[i]\n-        return ret\n-\n-    def __str__(self):\n-        return self.to_dense().__str__()\n-\n-    @property\n-    def diag(self):\n-        \"\"\"Return the (dense) vector of the diagonal elements.\"\"\"\n-        in_diag = (self.rows == self.cols)\n-        diag = np.zeros(min(self.n, self.n), dtype=np.float64)  # default 0.\n-        diag[self.rows[in_diag]] = self.vals[in_diag]\n-        return diag\n-\n-\n-def _cg(A, b, x0=None, tol=1.e-10, maxiter=1000):\n-    \"\"\"\n-    Use Preconditioned Conjugate Gradient iteration to solve A x = b\n-    A simple Jacobi (diagonal) preconditioner is used.\n-\n-    Parameters\n-    ----------\n-    A : _Sparse_Matrix_coo\n-        *A* must have been compressed before by compress_csc or\n-        compress_csr method.\n-    b : array\n-        Right hand side of the linear system.\n-    x0 : array, optional\n-        Starting guess for the solution. Defaults to the zero vector.\n-    tol : float, optional\n-        Tolerance to achieve. The algorithm terminates when the relative\n-        residual is below tol. Default is 1e-10.\n-    maxiter : int, optional\n-        Maximum number of iterations.  Iteration will stop after *maxiter*\n-        steps even if the specified tolerance has not been achieved. Defaults\n-        to 1000.\n-\n-    Returns\n-    -------\n-    x : array\n-        The converged solution.\n-    err : float\n-        The absolute error np.linalg.norm(A.dot(x) - b)\n-    \"\"\"\n-    n = b.size\n-    assert A.n == n\n-    assert A.m == n\n-    b_norm = np.linalg.norm(b)\n-\n-    # Jacobi pre-conditioner\n-    kvec = A.diag\n-    # For diag elem < 1e-6 we keep 1e-6.\n-    kvec = np.maximum(kvec, 1e-6)\n-\n-    # Initial guess\n-    if x0 is None:\n-        x = np.zeros(n)\n-    else:\n-        x = x0\n-\n-    r = b - A.dot(x)\n-    w = r/kvec\n-\n-    p = np.zeros(n)\n-    beta = 0.0\n-    rho = np.dot(r, w)\n-    k = 0\n-\n-    # Following C. T. Kelley\n-    while (np.sqrt(abs(rho)) > tol*b_norm) and (k < maxiter):\n-        p = w + beta*p\n-        z = A.dot(p)\n-        alpha = rho/np.dot(p, z)\n-        r = r - alpha*z\n-        w = r/kvec\n-        rhoold = rho\n-        rho = np.dot(r, w)\n-        x = x + alpha*p\n-        beta = rho/rhoold\n-        # err = np.linalg.norm(A.dot(x) - b)  # absolute accuracy - not used\n-        k += 1\n-    err = np.linalg.norm(A.dot(x) - b)\n-    return x, err\n-\n-\n-# The following private functions:\n-#     :func:`_safe_inv22_vectorized`\n-#     :func:`_pseudo_inv22sym_vectorized`\n-#     :func:`_scalar_vectorized`\n-#     :func:`_transpose_vectorized`\n-#     :func:`_roll_vectorized`\n-#     :func:`_to_matrix_vectorized`\n-#     :func:`_extract_submatrices`\n-# provide fast numpy implementation of some standard operations on arrays of\n-# matrices - stored as (:, n_rows, n_cols)-shaped np.arrays.\n-\n-# Development note: Dealing with pathologic 'flat' triangles in the\n-# CubicTriInterpolator code and impact on (2, 2)-matrix inversion functions\n-# :func:`_safe_inv22_vectorized` and :func:`_pseudo_inv22sym_vectorized`.\n-#\n-# Goals:\n-# 1) The CubicTriInterpolator should be able to handle flat or almost flat\n-#    triangles without raising an error,\n-# 2) These degenerated triangles should have no impact on the automatic dof\n-#    calculation (associated with null weight for the _DOF_estimator_geom and\n-#    with null energy for the _DOF_estimator_min_E),\n-# 3) Linear patch test should be passed exactly on degenerated meshes,\n-# 4) Interpolation (with :meth:`_interpolate_single_key` or\n-#    :meth:`_interpolate_multi_key`) shall be correctly handled even *inside*\n-#    the pathologic triangles, to interact correctly with a TriRefiner class.\n-#\n-# Difficulties:\n-# Flat triangles have rank-deficient *J* (so-called jacobian matrix) and\n-# *metric* (the metric tensor = J x J.T). Computation of the local\n-# tangent plane is also problematic.\n-#\n-# Implementation:\n-# Most of the time, when computing the inverse of a rank-deficient matrix it\n-# is safe to simply return the null matrix (which is the implementation in\n-# :func:`_safe_inv22_vectorized`). This is because of point 2), itself\n-# enforced by:\n-#    - null area hence null energy in :class:`_DOF_estimator_min_E`\n-#    - angles close or equal to 0 or np.pi hence null weight in\n-#      :class:`_DOF_estimator_geom`.\n-#      Note that the function angle -> weight is continuous and maximum for an\n-#      angle np.pi/2 (refer to :meth:`compute_geom_weights`)\n-# The exception is the computation of barycentric coordinates, which is done\n-# by inversion of the *metric* matrix. In this case, we need to compute a set\n-# of valid coordinates (1 among numerous possibilities), to ensure point 4).\n-# We benefit here from the symmetry of metric = J x J.T, which makes it easier\n-# to compute a pseudo-inverse in :func:`_pseudo_inv22sym_vectorized`\n-def _safe_inv22_vectorized(M):\n-    \"\"\"\n-    Inversion of arrays of (2, 2) matrices, returns 0 for rank-deficient\n-    matrices.\n-\n-    *M* : array of (2, 2) matrices to inverse, shape (n, 2, 2)\n-    \"\"\"\n-    _api.check_shape((None, 2, 2), M=M)\n-    M_inv = np.empty_like(M)\n-    prod1 = M[:, 0, 0]*M[:, 1, 1]\n-    delta = prod1 - M[:, 0, 1]*M[:, 1, 0]\n-\n-    # We set delta_inv to 0. in case of a rank deficient matrix; a\n-    # rank-deficient input matrix *M* will lead to a null matrix in output\n-    rank2 = (np.abs(delta) > 1e-8*np.abs(prod1))\n-    if np.all(rank2):\n-        # Normal 'optimized' flow.\n-        delta_inv = 1./delta\n-    else:\n-        # 'Pathologic' flow.\n-        delta_inv = np.zeros(M.shape[0])\n-        delta_inv[rank2] = 1./delta[rank2]\n-\n-    M_inv[:, 0, 0] = M[:, 1, 1]*delta_inv\n-    M_inv[:, 0, 1] = -M[:, 0, 1]*delta_inv\n-    M_inv[:, 1, 0] = -M[:, 1, 0]*delta_inv\n-    M_inv[:, 1, 1] = M[:, 0, 0]*delta_inv\n-    return M_inv\n-\n-\n-def _pseudo_inv22sym_vectorized(M):\n-    \"\"\"\n-    Inversion of arrays of (2, 2) SYMMETRIC matrices; returns the\n-    (Moore-Penrose) pseudo-inverse for rank-deficient matrices.\n-\n-    In case M is of rank 1, we have M = trace(M) x P where P is the orthogonal\n-    projection on Im(M), and we return trace(M)^-1 x P == M / trace(M)**2\n-    In case M is of rank 0, we return the null matrix.\n-\n-    *M* : array of (2, 2) matrices to inverse, shape (n, 2, 2)\n-    \"\"\"\n-    _api.check_shape((None, 2, 2), M=M)\n-    M_inv = np.empty_like(M)\n-    prod1 = M[:, 0, 0]*M[:, 1, 1]\n-    delta = prod1 - M[:, 0, 1]*M[:, 1, 0]\n-    rank2 = (np.abs(delta) > 1e-8*np.abs(prod1))\n-\n-    if np.all(rank2):\n-        # Normal 'optimized' flow.\n-        M_inv[:, 0, 0] = M[:, 1, 1] / delta\n-        M_inv[:, 0, 1] = -M[:, 0, 1] / delta\n-        M_inv[:, 1, 0] = -M[:, 1, 0] / delta\n-        M_inv[:, 1, 1] = M[:, 0, 0] / delta\n-    else:\n-        # 'Pathologic' flow.\n-        # Here we have to deal with 2 sub-cases\n-        # 1) First sub-case: matrices of rank 2:\n-        delta = delta[rank2]\n-        M_inv[rank2, 0, 0] = M[rank2, 1, 1] / delta\n-        M_inv[rank2, 0, 1] = -M[rank2, 0, 1] / delta\n-        M_inv[rank2, 1, 0] = -M[rank2, 1, 0] / delta\n-        M_inv[rank2, 1, 1] = M[rank2, 0, 0] / delta\n-        # 2) Second sub-case: rank-deficient matrices of rank 0 and 1:\n-        rank01 = ~rank2\n-        tr = M[rank01, 0, 0] + M[rank01, 1, 1]\n-        tr_zeros = (np.abs(tr) < 1.e-8)\n-        sq_tr_inv = (1.-tr_zeros) / (tr**2+tr_zeros)\n-        # sq_tr_inv = 1. / tr**2\n-        M_inv[rank01, 0, 0] = M[rank01, 0, 0] * sq_tr_inv\n-        M_inv[rank01, 0, 1] = M[rank01, 0, 1] * sq_tr_inv\n-        M_inv[rank01, 1, 0] = M[rank01, 1, 0] * sq_tr_inv\n-        M_inv[rank01, 1, 1] = M[rank01, 1, 1] * sq_tr_inv\n-\n-    return M_inv\n-\n-\n-def _scalar_vectorized(scalar, M):\n-    \"\"\"\n-    Scalar product between scalars and matrices.\n-    \"\"\"\n-    return scalar[:, np.newaxis, np.newaxis]*M\n-\n-\n-def _transpose_vectorized(M):\n-    \"\"\"\n-    Transposition of an array of matrices *M*.\n-    \"\"\"\n-    return np.transpose(M, [0, 2, 1])\n-\n-\n-def _roll_vectorized(M, roll_indices, axis):\n-    \"\"\"\n-    Roll an array of matrices along *axis* (0: rows, 1: columns) according to\n-    an array of indices *roll_indices*.\n-    \"\"\"\n-    assert axis in [0, 1]\n-    ndim = M.ndim\n-    assert ndim == 3\n-    ndim_roll = roll_indices.ndim\n-    assert ndim_roll == 1\n-    sh = M.shape\n-    r, c = sh[-2:]\n-    assert sh[0] == roll_indices.shape[0]\n-    vec_indices = np.arange(sh[0], dtype=np.int32)\n-\n-    # Builds the rolled matrix\n-    M_roll = np.empty_like(M)\n-    if axis == 0:\n-        for ir in range(r):\n-            for ic in range(c):\n-                M_roll[:, ir, ic] = M[vec_indices, (-roll_indices+ir) % r, ic]\n-    else:  # 1\n-        for ir in range(r):\n-            for ic in range(c):\n-                M_roll[:, ir, ic] = M[vec_indices, ir, (-roll_indices+ic) % c]\n-    return M_roll\n-\n-\n-def _to_matrix_vectorized(M):\n-    \"\"\"\n-    Build an array of matrices from individuals np.arrays of identical shapes.\n-\n-    Parameters\n-    ----------\n-    M\n-        ncols-list of nrows-lists of shape sh.\n-\n-    Returns\n-    -------\n-    M_res : np.array of shape (sh, nrow, ncols)\n-        *M_res* satisfies ``M_res[..., i, j] = M[i][j]``.\n-    \"\"\"\n-    assert isinstance(M, (tuple, list))\n-    assert all(isinstance(item, (tuple, list)) for item in M)\n-    c_vec = np.asarray([len(item) for item in M])\n-    assert np.all(c_vec-c_vec[0] == 0)\n-    r = len(M)\n-    c = c_vec[0]\n-    M00 = np.asarray(M[0][0])\n-    dt = M00.dtype\n-    sh = [M00.shape[0], r, c]\n-    M_ret = np.empty(sh, dtype=dt)\n-    for irow in range(r):\n-        for icol in range(c):\n-            M_ret[:, irow, icol] = np.asarray(M[irow][icol])\n-    return M_ret\n-\n-\n-def _extract_submatrices(M, block_indices, block_size, axis):\n-    \"\"\"\n-    Extract selected blocks of a matrices *M* depending on parameters\n-    *block_indices* and *block_size*.\n-\n-    Returns the array of extracted matrices *Mres* so that ::\n-\n-        M_res[..., ir, :] = M[(block_indices*block_size+ir), :]\n-    \"\"\"\n-    assert block_indices.ndim == 1\n-    assert axis in [0, 1]\n-\n-    r, c = M.shape\n-    if axis == 0:\n-        sh = [block_indices.shape[0], block_size, c]\n-    else:  # 1\n-        sh = [block_indices.shape[0], r, block_size]\n \n-    dt = M.dtype\n-    M_res = np.empty(sh, dtype=dt)\n-    if axis == 0:\n-        for ir in range(block_size):\n-            M_res[:, ir, :] = M[(block_indices*block_size+ir), :]\n-    else:  # 1\n-        for ic in range(block_size):\n-            M_res[:, :, ic] = M[:, (block_indices*block_size+ic)]\n \n-    return M_res\n+_api.warn_deprecated(\n+    \"3.7\",\n+    message=f\"Importing {__name__} was deprecated in Matplotlib 3.7 and will \"\n+            f\"be removed two minor releases later. All functionality is \"\n+            f\"available via the top-level module matplotlib.tri\")\ndiff --git a/lib/matplotlib/tri/tripcolor.py b/lib/matplotlib/tri/tripcolor.py\n--- a/lib/matplotlib/tri/tripcolor.py\n+++ b/lib/matplotlib/tri/tripcolor.py\n@@ -1,154 +1,9 @@\n-import numpy as np\n-\n+from ._tripcolor import *  # noqa: F401, F403\n from matplotlib import _api\n-from matplotlib.collections import PolyCollection, TriMesh\n-from matplotlib.colors import Normalize\n-from matplotlib.tri.triangulation import Triangulation\n-\n-\n-def tripcolor(ax, *args, alpha=1.0, norm=None, cmap=None, vmin=None,\n-              vmax=None, shading='flat', facecolors=None, **kwargs):\n-    \"\"\"\n-    Create a pseudocolor plot of an unstructured triangular grid.\n-\n-    Call signatures::\n-\n-      tripcolor(triangulation, c, *, ...)\n-      tripcolor(x, y, c, *, [triangles=triangles], [mask=mask], ...)\n-\n-    The triangular grid can be specified either by passing a `.Triangulation`\n-    object as the first parameter, or by passing the points *x*, *y* and\n-    optionally the *triangles* and a *mask*. See `.Triangulation` for an\n-    explanation of these parameters.\n-\n-    It is possible to pass the triangles positionally, i.e.\n-    ``tripcolor(x, y, triangles, c, ...)``. However, this is discouraged.\n-    For more clarity, pass *triangles* via keyword argument.\n-\n-    If neither of *triangulation* or *triangles* are given, the triangulation\n-    is calculated on the fly. In this case, it does not make sense to provide\n-    colors at the triangle faces via *c* or *facecolors* because there are\n-    multiple possible triangulations for a group of points and you don't know\n-    which triangles will be constructed.\n-\n-    Parameters\n-    ----------\n-    triangulation : `.Triangulation`\n-        An already created triangular grid.\n-    x, y, triangles, mask\n-        Parameters defining the triangular grid. See `.Triangulation`.\n-        This is mutually exclusive with specifying *triangulation*.\n-    c : array-like\n-        The color values, either for the points or for the triangles. Which one\n-        is automatically inferred from the length of *c*, i.e. does it match\n-        the number of points or the number of triangles. If there are the same\n-        number of points and triangles in the triangulation it is assumed that\n-        color values are defined at points; to force the use of color values at\n-        triangles use the keyword argument ``facecolors=c`` instead of just\n-        ``c``.\n-        This parameter is position-only.\n-    facecolors : array-like, optional\n-        Can be used alternatively to *c* to specify colors at the triangle\n-        faces. This parameter takes precedence over *c*.\n-    shading : {'flat', 'gouraud'}, default: 'flat'\n-        If  'flat' and the color values *c* are defined at points, the color\n-        values used for each triangle are from the mean c of the triangle's\n-        three points. If *shading* is 'gouraud' then color values must be\n-        defined at points.\n-    other_parameters\n-        All other parameters are the same as for `~.Axes.pcolor`.\n-    \"\"\"\n-    _api.check_in_list(['flat', 'gouraud'], shading=shading)\n-\n-    tri, args, kwargs = Triangulation.get_from_args_and_kwargs(*args, **kwargs)\n-\n-    # Parse the color to be in one of (the other variable will be None):\n-    # - facecolors: if specified at the triangle faces\n-    # - point_colors: if specified at the points\n-    if facecolors is not None:\n-        if args:\n-            _api.warn_external(\n-                \"Positional parameter c has no effect when the keyword \"\n-                \"facecolors is given\")\n-        point_colors = None\n-        if len(facecolors) != len(tri.triangles):\n-            raise ValueError(\"The length of facecolors must match the number \"\n-                             \"of triangles\")\n-    else:\n-        # Color from positional parameter c\n-        if not args:\n-            raise TypeError(\n-                \"tripcolor() missing 1 required positional argument: 'c'; or \"\n-                \"1 required keyword-only argument: 'facecolors'\")\n-        elif len(args) > 1:\n-            _api.warn_deprecated(\n-                \"3.6\", message=f\"Additional positional parameters \"\n-                f\"{args[1:]!r} are ignored; support for them is deprecated \"\n-                f\"since %(since)s and will be removed %(removal)s\")\n-        c = np.asarray(args[0])\n-        if len(c) == len(tri.x):\n-            # having this before the len(tri.triangles) comparison gives\n-            # precedence to nodes if there are as many nodes as triangles\n-            point_colors = c\n-            facecolors = None\n-        elif len(c) == len(tri.triangles):\n-            point_colors = None\n-            facecolors = c\n-        else:\n-            raise ValueError('The length of c must match either the number '\n-                             'of points or the number of triangles')\n-\n-    # Handling of linewidths, shading, edgecolors and antialiased as\n-    # in Axes.pcolor\n-    linewidths = (0.25,)\n-    if 'linewidth' in kwargs:\n-        kwargs['linewidths'] = kwargs.pop('linewidth')\n-    kwargs.setdefault('linewidths', linewidths)\n-\n-    edgecolors = 'none'\n-    if 'edgecolor' in kwargs:\n-        kwargs['edgecolors'] = kwargs.pop('edgecolor')\n-    ec = kwargs.setdefault('edgecolors', edgecolors)\n-\n-    if 'antialiased' in kwargs:\n-        kwargs['antialiaseds'] = kwargs.pop('antialiased')\n-    if 'antialiaseds' not in kwargs and ec.lower() == \"none\":\n-        kwargs['antialiaseds'] = False\n-\n-    _api.check_isinstance((Normalize, None), norm=norm)\n-    if shading == 'gouraud':\n-        if facecolors is not None:\n-            raise ValueError(\n-                \"shading='gouraud' can only be used when the colors \"\n-                \"are specified at the points, not at the faces.\")\n-        collection = TriMesh(tri, alpha=alpha, array=point_colors,\n-                             cmap=cmap, norm=norm, **kwargs)\n-    else:  # 'flat'\n-        # Vertices of triangles.\n-        maskedTris = tri.get_masked_triangles()\n-        verts = np.stack((tri.x[maskedTris], tri.y[maskedTris]), axis=-1)\n-\n-        # Color values.\n-        if facecolors is None:\n-            # One color per triangle, the mean of the 3 vertex color values.\n-            colors = point_colors[maskedTris].mean(axis=1)\n-        elif tri.mask is not None:\n-            # Remove color values of masked triangles.\n-            colors = facecolors[~tri.mask]\n-        else:\n-            colors = facecolors\n-        collection = PolyCollection(verts, alpha=alpha, array=colors,\n-                                    cmap=cmap, norm=norm, **kwargs)\n \n-    collection._scale_norm(norm, vmin, vmax)\n-    ax.grid(False)\n \n-    minx = tri.x.min()\n-    maxx = tri.x.max()\n-    miny = tri.y.min()\n-    maxy = tri.y.max()\n-    corners = (minx, miny), (maxx, maxy)\n-    ax.update_datalim(corners)\n-    ax.autoscale_view()\n-    ax.add_collection(collection)\n-    return collection\n+_api.warn_deprecated(\n+    \"3.7\",\n+    message=f\"Importing {__name__} was deprecated in Matplotlib 3.7 and will \"\n+            f\"be removed two minor releases later. All functionality is \"\n+            f\"available via the top-level module matplotlib.tri\")\ndiff --git a/lib/matplotlib/tri/triplot.py b/lib/matplotlib/tri/triplot.py\n--- a/lib/matplotlib/tri/triplot.py\n+++ b/lib/matplotlib/tri/triplot.py\n@@ -1,86 +1,9 @@\n-import numpy as np\n-from matplotlib.tri.triangulation import Triangulation\n-import matplotlib.cbook as cbook\n-import matplotlib.lines as mlines\n+from ._triplot import *  # noqa: F401, F403\n+from matplotlib import _api\n \n \n-def triplot(ax, *args, **kwargs):\n-    \"\"\"\n-    Draw an unstructured triangular grid as lines and/or markers.\n-\n-    Call signatures::\n-\n-      triplot(triangulation, ...)\n-      triplot(x, y, [triangles], *, [mask=mask], ...)\n-\n-    The triangular grid can be specified either by passing a `.Triangulation`\n-    object as the first parameter, or by passing the points *x*, *y* and\n-    optionally the *triangles* and a *mask*. If neither of *triangulation* or\n-    *triangles* are given, the triangulation is calculated on the fly.\n-\n-    Parameters\n-    ----------\n-    triangulation : `.Triangulation`\n-        An already created triangular grid.\n-    x, y, triangles, mask\n-        Parameters defining the triangular grid. See `.Triangulation`.\n-        This is mutually exclusive with specifying *triangulation*.\n-    other_parameters\n-        All other args and kwargs are forwarded to `~.Axes.plot`.\n-\n-    Returns\n-    -------\n-    lines : `~matplotlib.lines.Line2D`\n-        The drawn triangles edges.\n-    markers : `~matplotlib.lines.Line2D`\n-        The drawn marker nodes.\n-    \"\"\"\n-    import matplotlib.axes\n-\n-    tri, args, kwargs = Triangulation.get_from_args_and_kwargs(*args, **kwargs)\n-    x, y, edges = (tri.x, tri.y, tri.edges)\n-\n-    # Decode plot format string, e.g., 'ro-'\n-    fmt = args[0] if args else \"\"\n-    linestyle, marker, color = matplotlib.axes._base._process_plot_format(fmt)\n-\n-    # Insert plot format string into a copy of kwargs (kwargs values prevail).\n-    kw = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n-    for key, val in zip(('linestyle', 'marker', 'color'),\n-                        (linestyle, marker, color)):\n-        if val is not None:\n-            kw.setdefault(key, val)\n-\n-    # Draw lines without markers.\n-    # Note 1: If we drew markers here, most markers would be drawn more than\n-    #         once as they belong to several edges.\n-    # Note 2: We insert nan values in the flattened edges arrays rather than\n-    #         plotting directly (triang.x[edges].T, triang.y[edges].T)\n-    #         as it considerably speeds-up code execution.\n-    linestyle = kw['linestyle']\n-    kw_lines = {\n-        **kw,\n-        'marker': 'None',  # No marker to draw.\n-        'zorder': kw.get('zorder', 1),  # Path default zorder is used.\n-    }\n-    if linestyle not in [None, 'None', '', ' ']:\n-        tri_lines_x = np.insert(x[edges], 2, np.nan, axis=1)\n-        tri_lines_y = np.insert(y[edges], 2, np.nan, axis=1)\n-        tri_lines = ax.plot(tri_lines_x.ravel(), tri_lines_y.ravel(),\n-                            **kw_lines)\n-    else:\n-        tri_lines = ax.plot([], [], **kw_lines)\n-\n-    # Draw markers separately.\n-    marker = kw['marker']\n-    kw_markers = {\n-        **kw,\n-        'linestyle': 'None',  # No line to draw.\n-    }\n-    kw_markers.pop('label', None)\n-    if marker not in [None, 'None', '', ' ']:\n-        tri_markers = ax.plot(x, y, **kw_markers)\n-    else:\n-        tri_markers = ax.plot([], [], **kw_markers)\n-\n-    return tri_lines + tri_markers\n+_api.warn_deprecated(\n+    \"3.7\",\n+    message=f\"Importing {__name__} was deprecated in Matplotlib 3.7 and will \"\n+            f\"be removed two minor releases later. All functionality is \"\n+            f\"available via the top-level module matplotlib.tri\")\ndiff --git a/lib/matplotlib/tri/trirefine.py b/lib/matplotlib/tri/trirefine.py\n--- a/lib/matplotlib/tri/trirefine.py\n+++ b/lib/matplotlib/tri/trirefine.py\n@@ -1,307 +1,9 @@\n-\"\"\"\n-Mesh refinement for triangular grids.\n-\"\"\"\n-\n-import numpy as np\n-\n+from ._trirefine import *  # noqa: F401, F403\n from matplotlib import _api\n-from matplotlib.tri.triangulation import Triangulation\n-import matplotlib.tri.triinterpolate\n-\n-\n-class TriRefiner:\n-    \"\"\"\n-    Abstract base class for classes implementing mesh refinement.\n-\n-    A TriRefiner encapsulates a Triangulation object and provides tools for\n-    mesh refinement and interpolation.\n-\n-    Derived classes must implement:\n-\n-    - ``refine_triangulation(return_tri_index=False, **kwargs)`` , where\n-      the optional keyword arguments *kwargs* are defined in each\n-      TriRefiner concrete implementation, and which returns:\n-\n-      - a refined triangulation,\n-      - optionally (depending on *return_tri_index*), for each\n-        point of the refined triangulation: the index of\n-        the initial triangulation triangle to which it belongs.\n-\n-    - ``refine_field(z, triinterpolator=None, **kwargs)``, where:\n-\n-      - *z* array of field values (to refine) defined at the base\n-        triangulation nodes,\n-      - *triinterpolator* is an optional `~matplotlib.tri.TriInterpolator`,\n-      - the other optional keyword arguments *kwargs* are defined in\n-        each TriRefiner concrete implementation;\n-\n-      and which returns (as a tuple) a refined triangular mesh and the\n-      interpolated values of the field at the refined triangulation nodes.\n-    \"\"\"\n-\n-    def __init__(self, triangulation):\n-        _api.check_isinstance(Triangulation, triangulation=triangulation)\n-        self._triangulation = triangulation\n-\n-\n-class UniformTriRefiner(TriRefiner):\n-    \"\"\"\n-    Uniform mesh refinement by recursive subdivisions.\n-\n-    Parameters\n-    ----------\n-    triangulation : `~matplotlib.tri.Triangulation`\n-        The encapsulated triangulation (to be refined)\n-    \"\"\"\n-#    See Also\n-#    --------\n-#    :class:`~matplotlib.tri.CubicTriInterpolator` and\n-#    :class:`~matplotlib.tri.TriAnalyzer`.\n-#    \"\"\"\n-    def __init__(self, triangulation):\n-        super().__init__(triangulation)\n-\n-    def refine_triangulation(self, return_tri_index=False, subdiv=3):\n-        \"\"\"\n-        Compute an uniformly refined triangulation *refi_triangulation* of\n-        the encapsulated :attr:`triangulation`.\n-\n-        This function refines the encapsulated triangulation by splitting each\n-        father triangle into 4 child sub-triangles built on the edges midside\n-        nodes, recursing *subdiv* times.  In the end, each triangle is hence\n-        divided into ``4**subdiv`` child triangles.\n-\n-        Parameters\n-        ----------\n-        return_tri_index : bool, default: False\n-            Whether an index table indicating the father triangle index of each\n-            point is returned.\n-        subdiv : int, default: 3\n-            Recursion level for the subdivision.\n-            Each triangle is divided into ``4**subdiv`` child triangles;\n-            hence, the default results in 64 refined subtriangles for each\n-            triangle of the initial triangulation.\n-\n-        Returns\n-        -------\n-        refi_triangulation : `~matplotlib.tri.Triangulation`\n-            The refined triangulation.\n-        found_index : int array\n-            Index of the initial triangulation containing triangle, for each\n-            point of *refi_triangulation*.\n-            Returned only if *return_tri_index* is set to True.\n-        \"\"\"\n-        refi_triangulation = self._triangulation\n-        ntri = refi_triangulation.triangles.shape[0]\n-\n-        # Computes the triangulation ancestors numbers in the reference\n-        # triangulation.\n-        ancestors = np.arange(ntri, dtype=np.int32)\n-        for _ in range(subdiv):\n-            refi_triangulation, ancestors = self._refine_triangulation_once(\n-                refi_triangulation, ancestors)\n-        refi_npts = refi_triangulation.x.shape[0]\n-        refi_triangles = refi_triangulation.triangles\n-\n-        # Now we compute found_index table if needed\n-        if return_tri_index:\n-            # We have to initialize found_index with -1 because some nodes\n-            # may very well belong to no triangle at all, e.g., in case of\n-            # Delaunay Triangulation with DuplicatePointWarning.\n-            found_index = np.full(refi_npts, -1, dtype=np.int32)\n-            tri_mask = self._triangulation.mask\n-            if tri_mask is None:\n-                found_index[refi_triangles] = np.repeat(ancestors,\n-                                                        3).reshape(-1, 3)\n-            else:\n-                # There is a subtlety here: we want to avoid whenever possible\n-                # that refined points container is a masked triangle (which\n-                # would result in artifacts in plots).\n-                # So we impose the numbering from masked ancestors first,\n-                # then overwrite it with unmasked ancestor numbers.\n-                ancestor_mask = tri_mask[ancestors]\n-                found_index[refi_triangles[ancestor_mask, :]\n-                            ] = np.repeat(ancestors[ancestor_mask],\n-                                          3).reshape(-1, 3)\n-                found_index[refi_triangles[~ancestor_mask, :]\n-                            ] = np.repeat(ancestors[~ancestor_mask],\n-                                          3).reshape(-1, 3)\n-            return refi_triangulation, found_index\n-        else:\n-            return refi_triangulation\n-\n-    def refine_field(self, z, triinterpolator=None, subdiv=3):\n-        \"\"\"\n-        Refine a field defined on the encapsulated triangulation.\n-\n-        Parameters\n-        ----------\n-        z : (npoints,) array-like\n-            Values of the field to refine, defined at the nodes of the\n-            encapsulated triangulation. (``n_points`` is the number of points\n-            in the initial triangulation)\n-        triinterpolator : `~matplotlib.tri.TriInterpolator`, optional\n-            Interpolator used for field interpolation. If not specified,\n-            a `~matplotlib.tri.CubicTriInterpolator` will be used.\n-        subdiv : int, default: 3\n-            Recursion level for the subdivision.\n-            Each triangle is divided into ``4**subdiv`` child triangles.\n-\n-        Returns\n-        -------\n-        refi_tri : `~matplotlib.tri.Triangulation`\n-             The returned refined triangulation.\n-        refi_z : 1D array of length: *refi_tri* node count.\n-             The returned interpolated field (at *refi_tri* nodes).\n-        \"\"\"\n-        if triinterpolator is None:\n-            interp = matplotlib.tri.CubicTriInterpolator(\n-                self._triangulation, z)\n-        else:\n-            _api.check_isinstance(matplotlib.tri.TriInterpolator,\n-                                  triinterpolator=triinterpolator)\n-            interp = triinterpolator\n-\n-        refi_tri, found_index = self.refine_triangulation(\n-            subdiv=subdiv, return_tri_index=True)\n-        refi_z = interp._interpolate_multikeys(\n-            refi_tri.x, refi_tri.y, tri_index=found_index)[0]\n-        return refi_tri, refi_z\n-\n-    @staticmethod\n-    def _refine_triangulation_once(triangulation, ancestors=None):\n-        \"\"\"\n-        Refine a `.Triangulation` by splitting each triangle into 4\n-        child-masked_triangles built on the edges midside nodes.\n-\n-        Masked triangles, if present, are also split, but their children\n-        returned masked.\n-\n-        If *ancestors* is not provided, returns only a new triangulation:\n-        child_triangulation.\n-\n-        If the array-like key table *ancestor* is given, it shall be of shape\n-        (ntri,) where ntri is the number of *triangulation* masked_triangles.\n-        In this case, the function returns\n-        (child_triangulation, child_ancestors)\n-        child_ancestors is defined so that the 4 child masked_triangles share\n-        the same index as their father: child_ancestors.shape = (4 * ntri,).\n-        \"\"\"\n-\n-        x = triangulation.x\n-        y = triangulation.y\n-\n-        #    According to tri.triangulation doc:\n-        #         neighbors[i, j] is the triangle that is the neighbor\n-        #         to the edge from point index masked_triangles[i, j] to point\n-        #         index masked_triangles[i, (j+1)%3].\n-        neighbors = triangulation.neighbors\n-        triangles = triangulation.triangles\n-        npts = np.shape(x)[0]\n-        ntri = np.shape(triangles)[0]\n-        if ancestors is not None:\n-            ancestors = np.asarray(ancestors)\n-            if np.shape(ancestors) != (ntri,):\n-                raise ValueError(\n-                    \"Incompatible shapes provide for triangulation\"\n-                    \".masked_triangles and ancestors: {0} and {1}\".format(\n-                        np.shape(triangles), np.shape(ancestors)))\n-\n-        # Initiating tables refi_x and refi_y of the refined triangulation\n-        # points\n-        # hint: each apex is shared by 2 masked_triangles except the borders.\n-        borders = np.sum(neighbors == -1)\n-        added_pts = (3*ntri + borders) // 2\n-        refi_npts = npts + added_pts\n-        refi_x = np.zeros(refi_npts)\n-        refi_y = np.zeros(refi_npts)\n-\n-        # First part of refi_x, refi_y is just the initial points\n-        refi_x[:npts] = x\n-        refi_y[:npts] = y\n-\n-        # Second part contains the edge midside nodes.\n-        # Each edge belongs to 1 triangle (if border edge) or is shared by 2\n-        # masked_triangles (interior edge).\n-        # We first build 2 * ntri arrays of edge starting nodes (edge_elems,\n-        # edge_apexes); we then extract only the masters to avoid overlaps.\n-        # The so-called 'master' is the triangle with biggest index\n-        # The 'slave' is the triangle with lower index\n-        # (can be -1 if border edge)\n-        # For slave and master we will identify the apex pointing to the edge\n-        # start\n-        edge_elems = np.tile(np.arange(ntri, dtype=np.int32), 3)\n-        edge_apexes = np.repeat(np.arange(3, dtype=np.int32), ntri)\n-        edge_neighbors = neighbors[edge_elems, edge_apexes]\n-        mask_masters = (edge_elems > edge_neighbors)\n-\n-        # Identifying the \"masters\" and adding to refi_x, refi_y vec\n-        masters = edge_elems[mask_masters]\n-        apex_masters = edge_apexes[mask_masters]\n-        x_add = (x[triangles[masters, apex_masters]] +\n-                 x[triangles[masters, (apex_masters+1) % 3]]) * 0.5\n-        y_add = (y[triangles[masters, apex_masters]] +\n-                 y[triangles[masters, (apex_masters+1) % 3]]) * 0.5\n-        refi_x[npts:] = x_add\n-        refi_y[npts:] = y_add\n-\n-        # Building the new masked_triangles; each old masked_triangles hosts\n-        # 4 new masked_triangles\n-        # there are 6 pts to identify per 'old' triangle, 3 new_pt_corner and\n-        # 3 new_pt_midside\n-        new_pt_corner = triangles\n-\n-        # What is the index in refi_x, refi_y of point at middle of apex iapex\n-        #  of elem ielem ?\n-        # If ielem is the apex master: simple count, given the way refi_x was\n-        #  built.\n-        # If ielem is the apex slave: yet we do not know; but we will soon\n-        # using the neighbors table.\n-        new_pt_midside = np.empty([ntri, 3], dtype=np.int32)\n-        cum_sum = npts\n-        for imid in range(3):\n-            mask_st_loc = (imid == apex_masters)\n-            n_masters_loc = np.sum(mask_st_loc)\n-            elem_masters_loc = masters[mask_st_loc]\n-            new_pt_midside[:, imid][elem_masters_loc] = np.arange(\n-                n_masters_loc, dtype=np.int32) + cum_sum\n-            cum_sum += n_masters_loc\n-\n-        # Now dealing with slave elems.\n-        # for each slave element we identify the master and then the inode\n-        # once slave_masters is identified, slave_masters_apex is such that:\n-        # neighbors[slaves_masters, slave_masters_apex] == slaves\n-        mask_slaves = np.logical_not(mask_masters)\n-        slaves = edge_elems[mask_slaves]\n-        slaves_masters = edge_neighbors[mask_slaves]\n-        diff_table = np.abs(neighbors[slaves_masters, :] -\n-                            np.outer(slaves, np.ones(3, dtype=np.int32)))\n-        slave_masters_apex = np.argmin(diff_table, axis=1)\n-        slaves_apex = edge_apexes[mask_slaves]\n-        new_pt_midside[slaves, slaves_apex] = new_pt_midside[\n-            slaves_masters, slave_masters_apex]\n-\n-        # Builds the 4 child masked_triangles\n-        child_triangles = np.empty([ntri*4, 3], dtype=np.int32)\n-        child_triangles[0::4, :] = np.vstack([\n-            new_pt_corner[:, 0], new_pt_midside[:, 0],\n-            new_pt_midside[:, 2]]).T\n-        child_triangles[1::4, :] = np.vstack([\n-            new_pt_corner[:, 1], new_pt_midside[:, 1],\n-            new_pt_midside[:, 0]]).T\n-        child_triangles[2::4, :] = np.vstack([\n-            new_pt_corner[:, 2], new_pt_midside[:, 2],\n-            new_pt_midside[:, 1]]).T\n-        child_triangles[3::4, :] = np.vstack([\n-            new_pt_midside[:, 0], new_pt_midside[:, 1],\n-            new_pt_midside[:, 2]]).T\n-        child_triangulation = Triangulation(refi_x, refi_y, child_triangles)\n \n-        # Builds the child mask\n-        if triangulation.mask is not None:\n-            child_triangulation.set_mask(np.repeat(triangulation.mask, 4))\n \n-        if ancestors is None:\n-            return child_triangulation\n-        else:\n-            return child_triangulation, np.repeat(ancestors, 4)\n+_api.warn_deprecated(\n+    \"3.7\",\n+    message=f\"Importing {__name__} was deprecated in Matplotlib 3.7 and will \"\n+            f\"be removed two minor releases later. All functionality is \"\n+            f\"available via the top-level module matplotlib.tri\")\ndiff --git a/lib/matplotlib/tri/tritools.py b/lib/matplotlib/tri/tritools.py\n--- a/lib/matplotlib/tri/tritools.py\n+++ b/lib/matplotlib/tri/tritools.py\n@@ -1,263 +1,9 @@\n-\"\"\"\n-Tools for triangular grids.\n-\"\"\"\n-\n-import numpy as np\n-\n+from ._tritools import *  # noqa: F401, F403\n from matplotlib import _api\n-from matplotlib.tri import Triangulation\n-\n-\n-class TriAnalyzer:\n-    \"\"\"\n-    Define basic tools for triangular mesh analysis and improvement.\n-\n-    A TriAnalyzer encapsulates a `.Triangulation` object and provides basic\n-    tools for mesh analysis and mesh improvement.\n-\n-    Attributes\n-    ----------\n-    scale_factors\n-\n-    Parameters\n-    ----------\n-    triangulation : `~matplotlib.tri.Triangulation`\n-        The encapsulated triangulation to analyze.\n-    \"\"\"\n-\n-    def __init__(self, triangulation):\n-        _api.check_isinstance(Triangulation, triangulation=triangulation)\n-        self._triangulation = triangulation\n-\n-    @property\n-    def scale_factors(self):\n-        \"\"\"\n-        Factors to rescale the triangulation into a unit square.\n-\n-        Returns\n-        -------\n-        (float, float)\n-            Scaling factors (kx, ky) so that the triangulation\n-            ``[triangulation.x * kx, triangulation.y * ky]``\n-            fits exactly inside a unit square.\n-        \"\"\"\n-        compressed_triangles = self._triangulation.get_masked_triangles()\n-        node_used = (np.bincount(np.ravel(compressed_triangles),\n-                                 minlength=self._triangulation.x.size) != 0)\n-        return (1 / np.ptp(self._triangulation.x[node_used]),\n-                1 / np.ptp(self._triangulation.y[node_used]))\n-\n-    def circle_ratios(self, rescale=True):\n-        \"\"\"\n-        Return a measure of the triangulation triangles flatness.\n-\n-        The ratio of the incircle radius over the circumcircle radius is a\n-        widely used indicator of a triangle flatness.\n-        It is always ``<= 0.5`` and ``== 0.5`` only for equilateral\n-        triangles. Circle ratios below 0.01 denote very flat triangles.\n-\n-        To avoid unduly low values due to a difference of scale between the 2\n-        axis, the triangular mesh can first be rescaled to fit inside a unit\n-        square with `scale_factors` (Only if *rescale* is True, which is\n-        its default value).\n-\n-        Parameters\n-        ----------\n-        rescale : bool, default: True\n-            If True, internally rescale (based on `scale_factors`), so that the\n-            (unmasked) triangles fit exactly inside a unit square mesh.\n-\n-        Returns\n-        -------\n-        masked array\n-            Ratio of the incircle radius over the circumcircle radius, for\n-            each 'rescaled' triangle of the encapsulated triangulation.\n-            Values corresponding to masked triangles are masked out.\n-\n-        \"\"\"\n-        # Coords rescaling\n-        if rescale:\n-            (kx, ky) = self.scale_factors\n-        else:\n-            (kx, ky) = (1.0, 1.0)\n-        pts = np.vstack([self._triangulation.x*kx,\n-                         self._triangulation.y*ky]).T\n-        tri_pts = pts[self._triangulation.triangles]\n-        # Computes the 3 side lengths\n-        a = tri_pts[:, 1, :] - tri_pts[:, 0, :]\n-        b = tri_pts[:, 2, :] - tri_pts[:, 1, :]\n-        c = tri_pts[:, 0, :] - tri_pts[:, 2, :]\n-        a = np.hypot(a[:, 0], a[:, 1])\n-        b = np.hypot(b[:, 0], b[:, 1])\n-        c = np.hypot(c[:, 0], c[:, 1])\n-        # circumcircle and incircle radii\n-        s = (a+b+c)*0.5\n-        prod = s*(a+b-s)*(a+c-s)*(b+c-s)\n-        # We have to deal with flat triangles with infinite circum_radius\n-        bool_flat = (prod == 0.)\n-        if np.any(bool_flat):\n-            # Pathologic flow\n-            ntri = tri_pts.shape[0]\n-            circum_radius = np.empty(ntri, dtype=np.float64)\n-            circum_radius[bool_flat] = np.inf\n-            abc = a*b*c\n-            circum_radius[~bool_flat] = abc[~bool_flat] / (\n-                4.0*np.sqrt(prod[~bool_flat]))\n-        else:\n-            # Normal optimized flow\n-            circum_radius = (a*b*c) / (4.0*np.sqrt(prod))\n-        in_radius = (a*b*c) / (4.0*circum_radius*s)\n-        circle_ratio = in_radius/circum_radius\n-        mask = self._triangulation.mask\n-        if mask is None:\n-            return circle_ratio\n-        else:\n-            return np.ma.array(circle_ratio, mask=mask)\n-\n-    def get_flat_tri_mask(self, min_circle_ratio=0.01, rescale=True):\n-        \"\"\"\n-        Eliminate excessively flat border triangles from the triangulation.\n-\n-        Returns a mask *new_mask* which allows to clean the encapsulated\n-        triangulation from its border-located flat triangles\n-        (according to their :meth:`circle_ratios`).\n-        This mask is meant to be subsequently applied to the triangulation\n-        using `.Triangulation.set_mask`.\n-        *new_mask* is an extension of the initial triangulation mask\n-        in the sense that an initially masked triangle will remain masked.\n-\n-        The *new_mask* array is computed recursively; at each step flat\n-        triangles are removed only if they share a side with the current mesh\n-        border. Thus no new holes in the triangulated domain will be created.\n-\n-        Parameters\n-        ----------\n-        min_circle_ratio : float, default: 0.01\n-            Border triangles with incircle/circumcircle radii ratio r/R will\n-            be removed if r/R < *min_circle_ratio*.\n-        rescale : bool, default: True\n-            If True, first, internally rescale (based on `scale_factors`) so\n-            that the (unmasked) triangles fit exactly inside a unit square\n-            mesh.  This rescaling accounts for the difference of scale which\n-            might exist between the 2 axis.\n-\n-        Returns\n-        -------\n-        array of bool\n-            Mask to apply to encapsulated triangulation.\n-            All the initially masked triangles remain masked in the\n-            *new_mask*.\n-\n-        Notes\n-        -----\n-        The rationale behind this function is that a Delaunay\n-        triangulation - of an unstructured set of points - sometimes contains\n-        almost flat triangles at its border, leading to artifacts in plots\n-        (especially for high-resolution contouring).\n-        Masked with computed *new_mask*, the encapsulated\n-        triangulation would contain no more unmasked border triangles\n-        with a circle ratio below *min_circle_ratio*, thus improving the\n-        mesh quality for subsequent plots or interpolation.\n-        \"\"\"\n-        # Recursively computes the mask_current_borders, true if a triangle is\n-        # at the border of the mesh OR touching the border through a chain of\n-        # invalid aspect ratio masked_triangles.\n-        ntri = self._triangulation.triangles.shape[0]\n-        mask_bad_ratio = self.circle_ratios(rescale) < min_circle_ratio\n-\n-        current_mask = self._triangulation.mask\n-        if current_mask is None:\n-            current_mask = np.zeros(ntri, dtype=bool)\n-        valid_neighbors = np.copy(self._triangulation.neighbors)\n-        renum_neighbors = np.arange(ntri, dtype=np.int32)\n-        nadd = -1\n-        while nadd != 0:\n-            # The active wavefront is the triangles from the border (unmasked\n-            # but with a least 1 neighbor equal to -1\n-            wavefront = (np.min(valid_neighbors, axis=1) == -1) & ~current_mask\n-            # The element from the active wavefront will be masked if their\n-            # circle ratio is bad.\n-            added_mask = wavefront & mask_bad_ratio\n-            current_mask = added_mask | current_mask\n-            nadd = np.sum(added_mask)\n-\n-            # now we have to update the tables valid_neighbors\n-            valid_neighbors[added_mask, :] = -1\n-            renum_neighbors[added_mask] = -1\n-            valid_neighbors = np.where(valid_neighbors == -1, -1,\n-                                       renum_neighbors[valid_neighbors])\n-\n-        return np.ma.filled(current_mask, True)\n-\n-    def _get_compressed_triangulation(self):\n-        \"\"\"\n-        Compress (if masked) the encapsulated triangulation.\n-\n-        Returns minimal-length triangles array (*compressed_triangles*) and\n-        coordinates arrays (*compressed_x*, *compressed_y*) that can still\n-        describe the unmasked triangles of the encapsulated triangulation.\n-\n-        Returns\n-        -------\n-        compressed_triangles : array-like\n-            the returned compressed triangulation triangles\n-        compressed_x : array-like\n-            the returned compressed triangulation 1st coordinate\n-        compressed_y : array-like\n-            the returned compressed triangulation 2nd coordinate\n-        tri_renum : int array\n-            renumbering table to translate the triangle numbers from the\n-            encapsulated triangulation into the new (compressed) renumbering.\n-            -1 for masked triangles (deleted from *compressed_triangles*).\n-        node_renum : int array\n-            renumbering table to translate the point numbers from the\n-            encapsulated triangulation into the new (compressed) renumbering.\n-            -1 for unused points (i.e. those deleted from *compressed_x* and\n-            *compressed_y*).\n-\n-        \"\"\"\n-        # Valid triangles and renumbering\n-        tri_mask = self._triangulation.mask\n-        compressed_triangles = self._triangulation.get_masked_triangles()\n-        ntri = self._triangulation.triangles.shape[0]\n-        if tri_mask is not None:\n-            tri_renum = self._total_to_compress_renum(~tri_mask)\n-        else:\n-            tri_renum = np.arange(ntri, dtype=np.int32)\n-\n-        # Valid nodes and renumbering\n-        valid_node = (np.bincount(np.ravel(compressed_triangles),\n-                                  minlength=self._triangulation.x.size) != 0)\n-        compressed_x = self._triangulation.x[valid_node]\n-        compressed_y = self._triangulation.y[valid_node]\n-        node_renum = self._total_to_compress_renum(valid_node)\n-\n-        # Now renumbering the valid triangles nodes\n-        compressed_triangles = node_renum[compressed_triangles]\n-\n-        return (compressed_triangles, compressed_x, compressed_y, tri_renum,\n-                node_renum)\n-\n-    @staticmethod\n-    def _total_to_compress_renum(valid):\n-        \"\"\"\n-        Parameters\n-        ----------\n-        valid : 1D bool array\n-            Validity mask.\n \n-        Returns\n-        -------\n-        int array\n-            Array so that (`valid_array` being a compressed array\n-            based on a `masked_array` with mask ~*valid*):\n \n-            - For all i with valid[i] = True:\n-              valid_array[renum[i]] = masked_array[i]\n-            - For all i with valid[i] = False:\n-              renum[i] = -1 (invalid value)\n-        \"\"\"\n-        renum = np.full(np.size(valid), -1, dtype=np.int32)\n-        n_valid = np.sum(valid)\n-        renum[valid] = np.arange(n_valid, dtype=np.int32)\n-        return renum\n+_api.warn_deprecated(\n+    \"3.7\",\n+    message=f\"Importing {__name__} was deprecated in Matplotlib 3.7 and will \"\n+            f\"be removed two minor releases later. All functionality is \"\n+            f\"available via the top-level module matplotlib.tri\")\ndiff --git a/lib/mpl_toolkits/mplot3d/axes3d.py b/lib/mpl_toolkits/mplot3d/axes3d.py\n--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -32,7 +32,7 @@\n from matplotlib.axes import Axes\n from matplotlib.axes._base import _axis_method_wrapper, _process_plot_format\n from matplotlib.transforms import Bbox\n-from matplotlib.tri.triangulation import Triangulation\n+from matplotlib.tri._triangulation import Triangulation\n \n from . import art3d\n from . import proj3d\n@@ -2153,7 +2153,7 @@ def tricontour(self, *args,\n \n         Returns\n         -------\n-        matplotlib.tri.tricontour.TriContourSet\n+        matplotlib.tri._tricontour.TriContourSet\n         \"\"\"\n         had_data = self.has_data()\n \n@@ -2246,7 +2246,7 @@ def tricontourf(self, *args, zdir='z', offset=None, **kwargs):\n \n         Returns\n         -------\n-        matplotlib.tri.tricontour.TriContourSet\n+        matplotlib.tri._tricontour.TriContourSet\n         \"\"\"\n         had_data = self.has_data()\n \n",
  "test_patch": "diff --git a/lib/matplotlib/tests/test_triangulation.py b/lib/matplotlib/tests/test_triangulation.py\n--- a/lib/matplotlib/tests/test_triangulation.py\n+++ b/lib/matplotlib/tests/test_triangulation.py\n@@ -614,15 +614,15 @@ def poisson_sparse_matrix(n, m):\n \n     # Instantiating a sparse Poisson matrix of size 48 x 48:\n     (n, m) = (12, 4)\n-    mat = mtri.triinterpolate._Sparse_Matrix_coo(*poisson_sparse_matrix(n, m))\n+    mat = mtri._triinterpolate._Sparse_Matrix_coo(*poisson_sparse_matrix(n, m))\n     mat.compress_csc()\n     mat_dense = mat.to_dense()\n     # Testing a sparse solve for all 48 basis vector\n     for itest in range(n*m):\n         b = np.zeros(n*m, dtype=np.float64)\n         b[itest] = 1.\n-        x, _ = mtri.triinterpolate._cg(A=mat, b=b, x0=np.zeros(n*m),\n-                                       tol=1.e-10)\n+        x, _ = mtri._triinterpolate._cg(A=mat, b=b, x0=np.zeros(n*m),\n+                                        tol=1.e-10)\n         assert_array_almost_equal(np.dot(mat_dense, x), b)\n \n     # 2) Same matrix with inserting 2 rows - cols with null diag terms\n@@ -635,16 +635,16 @@ def poisson_sparse_matrix(n, m):\n     rows = np.concatenate([rows, [i_zero, i_zero-1, j_zero, j_zero-1]])\n     cols = np.concatenate([cols, [i_zero-1, i_zero, j_zero-1, j_zero]])\n     vals = np.concatenate([vals, [1., 1., 1., 1.]])\n-    mat = mtri.triinterpolate._Sparse_Matrix_coo(vals, rows, cols,\n-                                                 (n*m + 2, n*m + 2))\n+    mat = mtri._triinterpolate._Sparse_Matrix_coo(vals, rows, cols,\n+                                                  (n*m + 2, n*m + 2))\n     mat.compress_csc()\n     mat_dense = mat.to_dense()\n     # Testing a sparse solve for all 50 basis vec\n     for itest in range(n*m + 2):\n         b = np.zeros(n*m + 2, dtype=np.float64)\n         b[itest] = 1.\n-        x, _ = mtri.triinterpolate._cg(A=mat, b=b, x0=np.ones(n*m + 2),\n-                                       tol=1.e-10)\n+        x, _ = mtri._triinterpolate._cg(A=mat, b=b, x0=np.ones(n * m + 2),\n+                                        tol=1.e-10)\n         assert_array_almost_equal(np.dot(mat_dense, x), b)\n \n     # 3) Now a simple test that summation of duplicate (i.e. with same rows,\n@@ -655,7 +655,7 @@ def poisson_sparse_matrix(n, m):\n     cols = np.array([0, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2],\n                     dtype=np.int32)\n     dim = (3, 3)\n-    mat = mtri.triinterpolate._Sparse_Matrix_coo(vals, rows, cols, dim)\n+    mat = mtri._triinterpolate._Sparse_Matrix_coo(vals, rows, cols, dim)\n     mat.compress_csc()\n     mat_dense = mat.to_dense()\n     assert_array_almost_equal(mat_dense, np.array([\n@@ -678,7 +678,7 @@ def test_triinterpcubic_geom_weights():\n         y_rot = -np.sin(theta)*x + np.cos(theta)*y\n         triang = mtri.Triangulation(x_rot, y_rot, triangles)\n         cubic_geom = mtri.CubicTriInterpolator(triang, z, kind='geom')\n-        dof_estimator = mtri.triinterpolate._DOF_estimator_geom(cubic_geom)\n+        dof_estimator = mtri._triinterpolate._DOF_estimator_geom(cubic_geom)\n         weights = dof_estimator.compute_geom_weights()\n         # Testing for the 4 possibilities...\n         sum_w[0, :] = np.sum(weights, 1) - 1\n",
  "problem_statement": "function shadowing their own definition modules\nI'm not sure if this is really a \"bug\" report but more of an unexpected interaction. The short reason for this is that I'm working on improving the documentation in IPython and need a bijection object <-> fully qualified name which is made difficult by the following. I take the example of tripcolor, but this is not the only object that shadow it's module definition.\r\n\r\n### Bug report\r\n\r\n`matplotlib.tri.tripcolor` refer either as a module or function depending on context:\r\n\r\n```\r\n>>> from matplotlib.tri.tripcolor import tripcolor\r\n>>> tripcolor.__module__\r\n'matplotlib.tri.tripcolor'\r\n```\r\nTherefore those two lines confort us that `matplotlib.tri.tripcolor` is a module.\r\n\r\nThough\r\n\r\n```\r\n>>> matplotlib.tri.tripcolor is tripcolor\r\nTrue\r\n```\r\n\r\nThis is not too shocking for the advanced pythonista, as `tri/__init__.py:` contains\r\n```\r\n...\r\nfrom .tripcolor import * \r\n```\r\n\r\nThough it makes it hard to get access to the tripcolor module, though still possible via `importlib.import_module`, but make getting the object from it's fully qualified name difficult:\r\n\r\n```\r\nIn [6]: qualname = tripcolor.__module__+ '.' + tripcolor.__name__\r\n   ...: obj = matplotlib\r\n   ...: for k in qualname.split('.')[1:]:\r\n   ...:     obj = getattr(obj, k)\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-25-8f431e6ed783> in <module>\r\n      2 obj = matplotlib\r\n      3 for k in qualname.split('.')[1:]:\r\n----> 4     obj = getattr(obj, k)\r\n\r\nAttributeError: 'function' object has no attribute 'tripcolor'\r\n```\r\n\r\nI'd like to suggest to rename the tripcolor submodule to _tripcolor, or anything else which is different than the name of the function so that the function and module where it is defined have non-clashing fully-qualified names. \r\n\r\nNote that this is not completely API-compatible, as the shown above `from matplotlib.tri.tripcolor import tripcolor` would not work \u2013 though the correct import form is `from matplotlib.tri import tripcolor` that should still work.\r\n\r\nIs that a general concern in the matplotlib codebase and is there a desire that `obj.__module__+'.'+obj.__name__` should allow to get the fully qualified name of the object and should allow recursive call to getattr/import in order to access the object?\n",
  "hints_text": "I agree with renaming all the `tri/foo.py` modules to `tri/_foo.py` (`tri/__init__.py` already reexports everything anyways).  I'm not sure it's possible to have a proper deprecation for `from matplotlib.tri.tripcolor import tripcolor` (without ridiculous hacks)?",
  "created_at": "2022-09-26T18:56:52Z",
  "version": "3.6",
  "FAIL_TO_PASS": "[\"lib/matplotlib/tests/test_triangulation.py::test_triinterpcubic_cg_solver\", \"lib/matplotlib/tests/test_triangulation.py::test_triinterpcubic_geom_weights\"]",
  "PASS_TO_PASS": "[\"lib/matplotlib/tests/test_triangulation.py::TestTriangulationParams::test_extract_triangulation_params[args0-kwargs0-expected0]\", \"lib/matplotlib/tests/test_triangulation.py::TestTriangulationParams::test_extract_triangulation_params[args1-kwargs1-expected1]\", \"lib/matplotlib/tests/test_triangulation.py::TestTriangulationParams::test_extract_triangulation_params[args2-kwargs2-expected2]\", \"lib/matplotlib/tests/test_triangulation.py::TestTriangulationParams::test_extract_triangulation_params[args3-kwargs3-expected3]\", \"lib/matplotlib/tests/test_triangulation.py::TestTriangulationParams::test_extract_triangulation_params[args4-kwargs4-expected4]\", \"lib/matplotlib/tests/test_triangulation.py::TestTriangulationParams::test_extract_triangulation_params[args5-kwargs5-expected5]\", \"lib/matplotlib/tests/test_triangulation.py::test_delaunay\", \"lib/matplotlib/tests/test_triangulation.py::test_delaunay_duplicate_points\", \"lib/matplotlib/tests/test_triangulation.py::test_delaunay_insufficient_points[x0-y0]\", \"lib/matplotlib/tests/test_triangulation.py::test_delaunay_insufficient_points[x1-y1]\", \"lib/matplotlib/tests/test_triangulation.py::test_delaunay_insufficient_points[x2-y2]\", \"lib/matplotlib/tests/test_triangulation.py::test_delaunay_insufficient_points[x3-y3]\", \"lib/matplotlib/tests/test_triangulation.py::test_delaunay_insufficient_points[x4-y4]\", \"lib/matplotlib/tests/test_triangulation.py::test_delaunay_insufficient_points[x5-y5]\", \"lib/matplotlib/tests/test_triangulation.py::test_delaunay_points_in_line\", \"lib/matplotlib/tests/test_triangulation.py::test_delaunay_robust\", \"lib/matplotlib/tests/test_triangulation.py::test_extract_triangulation_positional_mask\", \"lib/matplotlib/tests/test_triangulation.py::test_internal_cpp_api\", \"lib/matplotlib/tests/test_triangulation.py::test_no_modify\", \"lib/matplotlib/tests/test_triangulation.py::test_qhull_large_offset\", \"lib/matplotlib/tests/test_triangulation.py::test_qhull_triangle_orientation\", \"lib/matplotlib/tests/test_triangulation.py::test_tri_smooth_contouring[png]\", \"lib/matplotlib/tests/test_triangulation.py::test_tri_smooth_gradient[png]\", \"lib/matplotlib/tests/test_triangulation.py::test_trianalyzer_mismatched_indices\", \"lib/matplotlib/tests/test_triangulation.py::test_triangulation_init\", \"lib/matplotlib/tests/test_triangulation.py::test_tricontour_non_finite_z\", \"lib/matplotlib/tests/test_triangulation.py::test_tricontourf_decreasing_levels\", \"lib/matplotlib/tests/test_triangulation.py::test_tricontourset_reuse\", \"lib/matplotlib/tests/test_triangulation.py::test_trifinder\", \"lib/matplotlib/tests/test_triangulation.py::test_triinterp\", \"lib/matplotlib/tests/test_triangulation.py::test_triinterp_colinear\", \"lib/matplotlib/tests/test_triangulation.py::test_triinterp_transformations\", \"lib/matplotlib/tests/test_triangulation.py::test_triinterpcubic_C1_continuity\", \"lib/matplotlib/tests/test_triangulation.py::test_tripcolor[png]\", \"lib/matplotlib/tests/test_triangulation.py::test_tripcolor_clim\", \"lib/matplotlib/tests/test_triangulation.py::test_tripcolor_color\", \"lib/matplotlib/tests/test_triangulation.py::test_tripcolor_warnings\", \"lib/matplotlib/tests/test_triangulation.py::test_triplot_label\", \"lib/matplotlib/tests/test_triangulation.py::test_triplot_return\", \"lib/matplotlib/tests/test_triangulation.py::test_triplot_with_ls[pdf]\", \"lib/matplotlib/tests/test_triangulation.py::test_triplot_with_ls[png]\", \"lib/matplotlib/tests/test_triangulation.py::test_trirefine\", \"lib/matplotlib/tests/test_triangulation.py::test_trirefine_masked[cubic]\", \"lib/matplotlib/tests/test_triangulation.py::test_trirefine_masked[linear]\", \"lib/matplotlib/tests/test_triangulation.py::test_trirefiner_fortran_contiguous_triangles\", \"lib/matplotlib/tests/test_triangulation.py::test_tritools\"]",
  "environment_setup_commit": "73909bcb408886a22e2b84581d6b9e6d9907c813",
  "patch_files": [
    "lib/matplotlib/tri/__init__.py",
    "lib/matplotlib/tri/_triangulation.py",
    "lib/matplotlib/tri/_tricontour.py",
    "lib/matplotlib/tri/_trifinder.py",
    "lib/matplotlib/tri/_triinterpolate.py",
    "lib/matplotlib/tri/_tripcolor.py",
    "lib/matplotlib/tri/_triplot.py",
    "lib/matplotlib/tri/_trirefine.py",
    "lib/matplotlib/tri/_tritools.py",
    "lib/matplotlib/tri/triangulation.py",
    "lib/matplotlib/tri/tricontour.py",
    "lib/matplotlib/tri/trifinder.py",
    "lib/matplotlib/tri/triinterpolate.py",
    "lib/matplotlib/tri/tripcolor.py",
    "lib/matplotlib/tri/triplot.py",
    "lib/matplotlib/tri/trirefine.py",
    "lib/matplotlib/tri/tritools.py",
    "lib/mpl_toolkits/mplot3d/axes3d.py"
  ],
  "test_patch_files": [
    "lib/matplotlib/tests/test_triangulation.py"
  ],
  "patch_diff_details": {
    "lib/matplotlib/tri/__init__.py": {
      "diffs": [
        {
          "start_line_old": 5,
          "end_line_old": 13
        }
      ]
    },
    "lib/matplotlib/tri/_triangulation.py": {
      "diffs": [
        {
          "start_line_old": 0,
          "end_line_old": 0
        }
      ]
    },
    "lib/matplotlib/tri/_tricontour.py": {
      "diffs": [
        {
          "start_line_old": 0,
          "end_line_old": 0
        }
      ]
    },
    "lib/matplotlib/tri/_trifinder.py": {
      "diffs": [
        {
          "start_line_old": 0,
          "end_line_old": 0
        }
      ]
    },
    "lib/matplotlib/tri/_triinterpolate.py": {
      "diffs": [
        {
          "start_line_old": 0,
          "end_line_old": 0
        }
      ]
    },
    "lib/matplotlib/tri/_tripcolor.py": {
      "diffs": [
        {
          "start_line_old": 0,
          "end_line_old": 0
        }
      ]
    },
    "lib/matplotlib/tri/_triplot.py": {
      "diffs": [
        {
          "start_line_old": 0,
          "end_line_old": 0
        }
      ]
    },
    "lib/matplotlib/tri/_trirefine.py": {
      "diffs": [
        {
          "start_line_old": 0,
          "end_line_old": 0
        }
      ]
    },
    "lib/matplotlib/tri/_tritools.py": {
      "diffs": [
        {
          "start_line_old": 0,
          "end_line_old": 0
        }
      ]
    },
    "lib/matplotlib/tri/triangulation.py": {
      "diffs": [
        {
          "start_line_old": 1,
          "end_line_old": 240,
          "file_pos": 26,
          "file_context_length": 190444,
          "closest_snippet_id": "/tmp/repos/matplotlib/lib/matplotlib/tri/triangulation.py_Triangulation._extract_triangulation_params_Triangulation._extract_triangulation_params.11.1",
          "closest_snippet_line_distance": 55
        }
      ]
    },
    "lib/matplotlib/tri/tricontour.py": {
      "diffs": [
        {
          "start_line_old": 1,
          "end_line_old": 271
        }
      ]
    },
    "lib/matplotlib/tri/trifinder.py": {
      "diffs": [
        {
          "start_line_old": 1,
          "end_line_old": 93
        }
      ]
    },
    "lib/matplotlib/tri/triinterpolate.py": {
      "diffs": [
        {
          "start_line_old": 1,
          "end_line_old": 1574
        }
      ]
    },
    "lib/matplotlib/tri/tripcolor.py": {
      "diffs": [
        {
          "start_line_old": 1,
          "end_line_old": 154,
          "file_pos": 5,
          "file_context_length": 66588,
          "closest_snippet_id": "/tmp/repos/matplotlib/lib/matplotlib/tri/tripcolor.py_tripcolor.7_",
          "closest_snippet_line_distance": 1
        }
      ]
    },
    "lib/matplotlib/tri/triplot.py": {
      "diffs": [
        {
          "start_line_old": 1,
          "end_line_old": 86
        }
      ]
    },
    "lib/matplotlib/tri/trirefine.py": {
      "diffs": [
        {
          "start_line_old": 1,
          "end_line_old": 307
        }
      ]
    },
    "lib/matplotlib/tri/tritools.py": {
      "diffs": [
        {
          "start_line_old": 1,
          "end_line_old": 263
        }
      ]
    },
    "lib/mpl_toolkits/mplot3d/axes3d.py": {
      "diffs": [
        {
          "start_line_old": 35,
          "end_line_old": 35
        },
        {
          "start_line_old": 2156,
          "end_line_old": 2156
        },
        {
          "start_line_old": 2249,
          "end_line_old": 2249
        }
      ]
    }
  },
  "vectors": 3948,
  "snippets": [
    {
      "position": 1,
      "id": "/tmp/repos/matplotlib/doc/conf.py_50_intersphinx_mapping.1",
      "distance": 1.01636803150177,
      "file_path": "doc/conf.py",
      "start_line": 111,
      "end_line": 158,
      "tokens": 481,
      "context_length": 481
    },
    {
      "position": 2,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/pyplot.py_286_triplot.1.1",
      "distance": 1.0181622505187988,
      "file_path": "lib/matplotlib/pyplot.py",
      "start_line": 2956,
      "end_line": 2971,
      "tokens": 184,
      "context_length": 665
    },
    {
      "position": 3,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/__init__.py_3__VersionInfo.1",
      "distance": 1.0467442274093628,
      "file_path": "lib/matplotlib/__init__.py",
      "start_line": 107,
      "end_line": 156,
      "tokens": 328,
      "context_length": 993
    },
    {
      "position": 4,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/__init__.py_1_atexit",
      "distance": 1.057220220565796,
      "file_path": "lib/matplotlib/__init__.py",
      "start_line": 1,
      "end_line": 106,
      "tokens": 767,
      "context_length": 1760
    },
    {
      "position": 5,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/pyplot.py__copy_docstring_and_deprecators__draw_all_if_interactive.1.1",
      "distance": 1.0701372623443604,
      "file_path": "lib/matplotlib/pyplot.py",
      "start_line": 92,
      "end_line": 119,
      "tokens": 223,
      "context_length": 1983
    },
    {
      "position": 6,
      "id": "/tmp/repos/matplotlib/doc/conf.py_244_",
      "distance": 1.0823308229446411,
      "file_path": "doc/conf.py",
      "start_line": 635,
      "end_line": 708,
      "tokens": 477,
      "context_length": 2460
    },
    {
      "position": 7,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/cbook/__init__.py___getattr_____getattr__.MatplotlibDeprecationWarning.mplDeprecation.1",
      "distance": 1.0827186107635498,
      "file_path": "lib/matplotlib/cbook/__init__.py",
      "start_line": 33,
      "end_line": 43,
      "tokens": 126,
      "context_length": 2586
    },
    {
      "position": 8,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/__init__.py___getattr____check_versions.ft2font",
      "distance": 1.0831266641616821,
      "file_path": "lib/matplotlib/__init__.py",
      "start_line": 203,
      "end_line": 229,
      "tokens": 253,
      "context_length": 2839
    },
    {
      "position": 9,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/tri/tripcolor.py_tripcolor.7_",
      "distance": 1.084036111831665,
      "file_path": "lib/matplotlib/tri/tripcolor.py",
      "start_line": 68,
      "end_line": 155,
      "tokens": 851,
      "context_length": 3690,
      "file_pos": 5
    },
    {
      "position": 10,
      "id": "/tmp/repos/matplotlib/plot_types/unstructured/tripcolor.py_1_",
      "distance": 1.092216968536377,
      "file_path": "plot_types/unstructured/tripcolor.py",
      "start_line": 1,
      "end_line": 28,
      "tokens": 170,
      "context_length": 3860
    },
    {
      "position": 11,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/pyplot.py_rc_setp.1.1",
      "distance": 1.0924437046051025,
      "file_path": "lib/matplotlib/pyplot.py",
      "start_line": 569,
      "end_line": 601,
      "tokens": 231,
      "context_length": 4091
    },
    {
      "position": 12,
      "id": "/tmp/repos/matplotlib/doc/sphinxext/skip_deprecated.py_1_",
      "distance": 1.0932272672653198,
      "file_path": "doc/sphinxext/skip_deprecated.py",
      "start_line": 1,
      "end_line": 18,
      "tokens": 128,
      "context_length": 4219
    },
    {
      "position": 13,
      "id": "/tmp/repos/matplotlib/doc/conf.py_sphinx_gallery_conf_project.1",
      "distance": 1.097040057182312,
      "file_path": "doc/conf.py",
      "start_line": 178,
      "end_line": 273,
      "tokens": 760,
      "context_length": 4979
    },
    {
      "position": 14,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/pyplot.py_1__log.1",
      "distance": 1.100290060043335,
      "file_path": "lib/matplotlib/pyplot.py",
      "start_line": 1,
      "end_line": 89,
      "tokens": 669,
      "context_length": 5648
    },
    {
      "position": 15,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/_docstring.py__ArtistPropertiesSubstitution_",
      "distance": 1.1030566692352295,
      "file_path": "lib/matplotlib/_docstring.py",
      "start_line": 64,
      "end_line": 98,
      "tokens": 265,
      "context_length": 5913
    },
    {
      "position": 16,
      "id": "/tmp/repos/matplotlib/examples/images_contours_and_fields/tripcolor_demo.py_1_41",
      "distance": 1.1051366329193115,
      "file_path": "examples/images_contours_and_fields/tripcolor_demo.py",
      "start_line": 1,
      "end_line": 61,
      "tokens": 475,
      "context_length": 6388
    },
    {
      "position": 17,
      "id": "/tmp/repos/matplotlib/tutorials/advanced/patheffects_guide.py_1_fig_64.1",
      "distance": 1.1142361164093018,
      "file_path": "tutorials/advanced/patheffects_guide.py",
      "start_line": 1,
      "end_line": 101,
      "tokens": 918,
      "context_length": 7306
    },
    {
      "position": 18,
      "id": "/tmp/repos/matplotlib/examples/images_contours_and_fields/tripcolor_demo.py_xmid_",
      "distance": 1.1188983917236328,
      "file_path": "examples/images_contours_and_fields/tripcolor_demo.py",
      "start_line": 103,
      "end_line": 138,
      "tokens": 319,
      "context_length": 7625
    },
    {
      "position": 19,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/__init__.py__preprocess_data.inner_",
      "distance": 1.1220746040344238,
      "file_path": "lib/matplotlib/__init__.py",
      "start_line": 1444,
      "end_line": 1488,
      "tokens": 404,
      "context_length": 8029
    },
    {
      "position": 20,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/pylab.py_1_",
      "distance": 1.1222902536392212,
      "file_path": "lib/matplotlib/pylab.py",
      "start_line": 1,
      "end_line": 51,
      "tokens": 387,
      "context_length": 8416
    },
    {
      "position": 21,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/axes/_base.py_1__log.1",
      "distance": 1.1315433979034424,
      "file_path": "lib/matplotlib/axes/_base.py",
      "start_line": 1,
      "end_line": 32,
      "tokens": 212,
      "context_length": 8628
    },
    {
      "position": 22,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/testing/decorators.py_contextlib_CleanupTestCase.tearDownClass.1",
      "distance": 1.1377201080322266,
      "file_path": "lib/matplotlib/testing/decorators.py",
      "start_line": 1,
      "end_line": 45,
      "tokens": 256,
      "context_length": 8884
    },
    {
      "position": 23,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/axes/_base.py__process_plot_var_args._plot_args.7__AxesBase",
      "distance": 1.1398035287857056,
      "file_path": "lib/matplotlib/axes/_base.py",
      "start_line": 469,
      "end_line": 4640,
      "tokens": 813,
      "context_length": 9697
    },
    {
      "position": 24,
      "id": "/tmp/repos/matplotlib/tutorials/colors/colormaps.py_78_114",
      "distance": 1.1438640356063843,
      "file_path": "tutorials/colors/colormaps.py",
      "start_line": 202,
      "end_line": 259,
      "tokens": 653,
      "context_length": 10350
    },
    {
      "position": 25,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/_api/__init__.py_1_MatplotlibDeprecationWarning",
      "distance": 1.1441649198532104,
      "file_path": "lib/matplotlib/_api/__init__.py",
      "start_line": 1,
      "end_line": 24,
      "tokens": 136,
      "context_length": 10486
    },
    {
      "position": 26,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/artist.py_ArtistInspector._NOT_LINKABLE_ArtistInspector._NOT_LINKABLE.1",
      "distance": 1.1446166038513184,
      "file_path": "lib/matplotlib/artist.py",
      "start_line": 1533,
      "end_line": 1547,
      "tokens": 162,
      "context_length": 10648
    },
    {
      "position": 27,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/backends/backend_gtk3.py_functools__mpl_to_gtk_cursor.1.1",
      "distance": 1.1465284824371338,
      "file_path": "lib/matplotlib/backends/backend_gtk3.py",
      "start_line": 1,
      "end_line": 52,
      "tokens": 377,
      "context_length": 11025
    },
    {
      "position": 28,
      "id": "/tmp/repos/matplotlib/doc/conf.py_214_243",
      "distance": 1.1471635103225708,
      "file_path": "doc/conf.py",
      "start_line": 561,
      "end_line": 633,
      "tokens": 639,
      "context_length": 11664
    },
    {
      "position": 29,
      "id": "/tmp/repos/matplotlib/doc/conf.py_1_exclude_patterns.1",
      "distance": 1.1477770805358887,
      "file_path": "doc/conf.py",
      "start_line": 1,
      "end_line": 84,
      "tokens": 646,
      "context_length": 12310
    },
    {
      "position": 30,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/testing/decorators.py__ImageComparisonBase__ImageComparisonBase.copy_baseline.6.1",
      "distance": 1.1504559516906738,
      "file_path": "lib/matplotlib/testing/decorators.py",
      "start_line": 175,
      "end_line": 210,
      "tokens": 309,
      "context_length": 12619
    },
    {
      "position": 31,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/animation.py_1_subprocess_creation_flags.1",
      "distance": 1.151214838027954,
      "file_path": "lib/matplotlib/animation.py",
      "start_line": 1,
      "end_line": 49,
      "tokens": 356,
      "context_length": 12975
    },
    {
      "position": 32,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/_api/__init__.py_caching_module_getattr_caching_module_getattr.7.1",
      "distance": 1.151889443397522,
      "file_path": "lib/matplotlib/_api/__init__.py",
      "start_line": 195,
      "end_line": 227,
      "tokens": 292,
      "context_length": 13267
    },
    {
      "position": 33,
      "id": "/tmp/repos/matplotlib/doc/conf.py__check_dependencies__check_dependencies.5.1",
      "distance": 1.1531860828399658,
      "file_path": "doc/conf.py",
      "start_line": 87,
      "end_line": 109,
      "tokens": 195,
      "context_length": 13462
    },
    {
      "position": 34,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/colorbar.py_14_14",
      "distance": 1.1533992290496826,
      "file_path": "lib/matplotlib/colorbar.py",
      "start_line": 30,
      "end_line": 115,
      "tokens": 961,
      "context_length": 14423
    },
    {
      "position": 35,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/patheffects.py_SimplePatchShadow.draw_path_withSimplePatchShadow.1",
      "distance": 1.1566574573516846,
      "file_path": "lib/matplotlib/patheffects.py",
      "start_line": 259,
      "end_line": 285,
      "tokens": 251,
      "context_length": 14674
    },
    {
      "position": 36,
      "id": "/tmp/repos/matplotlib/tutorials/toolkits/axisartist.py_1_",
      "distance": 1.1588811874389648,
      "file_path": "tutorials/toolkits/axisartist.py",
      "start_line": 1,
      "end_line": 563,
      "tokens": 4711,
      "context_length": 19385
    },
    {
      "position": 37,
      "id": "/tmp/repos/matplotlib/doc/conf.py_copyright_github_project_url.1",
      "distance": 1.1607606410980225,
      "file_path": "doc/conf.py",
      "start_line": 274,
      "end_line": 331,
      "tokens": 412,
      "context_length": 19797
    },
    {
      "position": 38,
      "id": "/tmp/repos/matplotlib/examples/shapes_and_collections/artist_reference.py_line_",
      "distance": 1.161258578300476,
      "file_path": "examples/shapes_and_collections/artist_reference.py",
      "start_line": 90,
      "end_line": 130,
      "tokens": 319,
      "context_length": 20116
    },
    {
      "position": 39,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/testing/decorators.py__ImageComparisonBase.compare__ImageComparisonBase.compare.7.3",
      "distance": 1.1617684364318848,
      "file_path": "lib/matplotlib/testing/decorators.py",
      "start_line": 212,
      "end_line": 235,
      "tokens": 202,
      "context_length": 20318
    },
    {
      "position": 40,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/pyplot.py_121_colorbar.3.1",
      "distance": 1.1622776985168457,
      "file_path": "lib/matplotlib/pyplot.py",
      "start_line": 2060,
      "end_line": 2073,
      "tokens": 138,
      "context_length": 20456
    },
    {
      "position": 41,
      "id": "/tmp/repos/matplotlib/tests.py_1_",
      "distance": 1.1642781496047974,
      "file_path": "tests.py",
      "start_line": 1,
      "end_line": 35,
      "tokens": 238,
      "context_length": 20694
    },
    {
      "position": 42,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/patheffects.py_SimpleLineShadow.draw_path_SimpleLineShadow.draw_path.10",
      "distance": 1.1652319431304932,
      "file_path": "lib/matplotlib/patheffects.py",
      "start_line": 321,
      "end_line": 342,
      "tokens": 225,
      "context_length": 20919
    },
    {
      "position": 43,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/artist.py_1__log.1",
      "distance": 1.1657886505126953,
      "file_path": "lib/matplotlib/artist.py",
      "start_line": 1,
      "end_line": 21,
      "tokens": 117,
      "context_length": 21036
    },
    {
      "position": 44,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/cbook/__init__.py__strip_comment_file_requires_unicode.2.3.1.1",
      "distance": 1.1687994003295898,
      "file_path": "lib/matplotlib/cbook/__init__.py",
      "start_line": 414,
      "end_line": 449,
      "tokens": 274,
      "context_length": 21310
    },
    {
      "position": 45,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/pyplot.py__warn_if_gui_out_of_main_thread__warn_if_gui_out_of_main_thread.3.1",
      "distance": 1.170959711074829,
      "file_path": "lib/matplotlib/pyplot.py",
      "start_line": 341,
      "end_line": 359,
      "tokens": 175,
      "context_length": 21485
    },
    {
      "position": 46,
      "id": "/tmp/repos/matplotlib/tutorials/advanced/patheffects_guide.py_t_",
      "distance": 1.1725614070892334,
      "file_path": "tutorials/advanced/patheffects_guide.py",
      "start_line": 102,
      "end_line": 119,
      "tokens": 127,
      "context_length": 21612
    },
    {
      "position": 47,
      "id": "/tmp/repos/matplotlib/examples/misc/pythonic_matplotlib.py_1_",
      "distance": 1.1725693941116333,
      "file_path": "examples/misc/pythonic_matplotlib.py",
      "start_line": 1,
      "end_line": 81,
      "tokens": 610,
      "context_length": 22222
    },
    {
      "position": 48,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/testing/decorators.py_check_freetype_version__checked_on_freetype_version.2.1",
      "distance": 1.173095703125,
      "file_path": "lib/matplotlib/testing/decorators.py",
      "start_line": 91,
      "end_line": 116,
      "tokens": 214,
      "context_length": 22436
    },
    {
      "position": 49,
      "id": "/tmp/repos/matplotlib/tutorials/intermediate/artists.py_plt_lines",
      "distance": 1.1751574277877808,
      "file_path": "tutorials/intermediate/artists.py",
      "start_line": 118,
      "end_line": 333,
      "tokens": 2328,
      "context_length": 24764
    },
    {
      "position": 50,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/pyplot.py_296_318",
      "distance": 1.1756302118301392,
      "file_path": "lib/matplotlib/pyplot.py",
      "start_line": 3010,
      "end_line": 3106,
      "tokens": 792,
      "context_length": 25556
    },
    {
      "position": 51,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/tri/triangulation.py_Triangulation._extract_triangulation_params_Triangulation._extract_triangulation_params.11.1",
      "distance": 1.1763689517974854,
      "file_path": "lib/matplotlib/tri/triangulation.py",
      "start_line": 164,
      "end_line": 185,
      "tokens": 199,
      "context_length": 25755,
      "file_pos": 26
    },
    {
      "position": 52,
      "id": "/tmp/repos/matplotlib/examples/shapes_and_collections/path_patch.py_1_",
      "distance": 1.1769897937774658,
      "file_path": "examples/shapes_and_collections/path_patch.py",
      "start_line": 1,
      "end_line": 53,
      "tokens": 399,
      "context_length": 26154
    },
    {
      "position": 53,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/_api/deprecation.py_deprecate_privatize_attribute_DECORATORS.1",
      "distance": 1.1786390542984009,
      "file_path": "lib/matplotlib/_api/deprecation.py",
      "start_line": 223,
      "end_line": 254,
      "tokens": 311,
      "context_length": 26465
    },
    {
      "position": 54,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/_api/deprecation.py__generate_deprecation_warning__generate_deprecation_warning.4.1",
      "distance": 1.179074764251709,
      "file_path": "lib/matplotlib/_api/deprecation.py",
      "start_line": 24,
      "end_line": 47,
      "tokens": 238,
      "context_length": 26703
    },
    {
      "position": 55,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/axes/_base.py__process_plot_var_args._makefill__process_plot_var_args._makefill.x.37.1",
      "distance": 1.181359887123108,
      "file_path": "lib/matplotlib/axes/_base.py",
      "start_line": 355,
      "end_line": 405,
      "tokens": 512,
      "context_length": 27215
    },
    {
      "position": 56,
      "id": "/tmp/repos/matplotlib/lib/matplotlib/__init__.py_95_default_test_modules.1",
      "distance": 1.1817538738250732,
      "file_path": "lib/matplotlib/__init__.py",
      "start_line": 1194,
      "end_line": 1231,
      "tokens": 170,
      "context_length": 27385
    },
    {
      "position": 57,
      "id": "/tmp/repos/matplotlib/tutorials/introductory/quick_start.py_428_503",
      "distance": 1.1821961402893066,
      "file_path": "tutorials/introductory/quick_start.py",
      "start_line": 475,
      "end_line": 561,
      "tokens": 1039,
      "context_length": 28424
    }
  ],
  "files": [
    {
      "file_path": "doc/conf.py",
      "position": 1,
      "tokens": 5611,
      "context_length": 5611
    },
    {
      "file_path": "lib/matplotlib/pyplot.py",
      "position": 2,
      "tokens": 28080,
      "context_length": 33691
    },
    {
      "file_path": "lib/matplotlib/__init__.py",
      "position": 3,
      "tokens": 12051,
      "context_length": 45742
    },
    {
      "file_path": "lib/matplotlib/cbook/__init__.py",
      "position": 4,
      "tokens": 19318,
      "context_length": 65060
    },
    {
      "file_path": "lib/matplotlib/tri/tripcolor.py",
      "position": 5,
      "tokens": 1528,
      "context_length": 66588
    },
    {
      "file_path": "plot_types/unstructured/tripcolor.py",
      "position": 6,
      "tokens": 170,
      "context_length": 66758
    },
    {
      "file_path": "doc/sphinxext/skip_deprecated.py",
      "position": 7,
      "tokens": 129,
      "context_length": 66887
    },
    {
      "file_path": "lib/matplotlib/_docstring.py",
      "position": 8,
      "tokens": 688,
      "context_length": 67575
    },
    {
      "file_path": "examples/images_contours_and_fields/tripcolor_demo.py",
      "position": 9,
      "tokens": 2343,
      "context_length": 69918
    },
    {
      "file_path": "tutorials/advanced/patheffects_guide.py",
      "position": 10,
      "tokens": 1046,
      "context_length": 70964
    },
    {
      "file_path": "lib/matplotlib/pylab.py",
      "position": 11,
      "tokens": 388,
      "context_length": 71352
    },
    {
      "file_path": "lib/matplotlib/axes/_base.py",
      "position": 12,
      "tokens": 39362,
      "context_length": 110714
    },
    {
      "file_path": "lib/matplotlib/testing/decorators.py",
      "position": 13,
      "tokens": 4155,
      "context_length": 114869
    },
    {
      "file_path": "tutorials/colors/colormaps.py",
      "position": 14,
      "tokens": 4773,
      "context_length": 119642
    },
    {
      "file_path": "lib/matplotlib/_api/__init__.py",
      "position": 15,
      "tokens": 2946,
      "context_length": 122588
    },
    {
      "file_path": "lib/matplotlib/artist.py",
      "position": 16,
      "tokens": 13375,
      "context_length": 135963
    },
    {
      "file_path": "lib/matplotlib/backends/backend_gtk3.py",
      "position": 17,
      "tokens": 4842,
      "context_length": 140805
    },
    {
      "file_path": "lib/matplotlib/animation.py",
      "position": 18,
      "tokens": 14813,
      "context_length": 155618
    },
    {
      "file_path": "lib/matplotlib/colorbar.py",
      "position": 19,
      "tokens": 14049,
      "context_length": 169667
    },
    {
      "file_path": "lib/matplotlib/patheffects.py",
      "position": 20,
      "tokens": 4294,
      "context_length": 173961
    },
    {
      "file_path": "tutorials/toolkits/axisartist.py",
      "position": 21,
      "tokens": 4711,
      "context_length": 178672
    },
    {
      "file_path": "examples/shapes_and_collections/artist_reference.py",
      "position": 22,
      "tokens": 1160,
      "context_length": 179832
    },
    {
      "file_path": "tests.py",
      "position": 23,
      "tokens": 238,
      "context_length": 180070
    },
    {
      "file_path": "examples/misc/pythonic_matplotlib.py",
      "position": 24,
      "tokens": 610,
      "context_length": 180680
    },
    {
      "file_path": "tutorials/intermediate/artists.py",
      "position": 25,
      "tokens": 7611,
      "context_length": 188291
    },
    {
      "file_path": "lib/matplotlib/tri/triangulation.py",
      "position": 26,
      "tokens": 2153,
      "context_length": 190444
    },
    {
      "file_path": "examples/shapes_and_collections/path_patch.py",
      "position": 27,
      "tokens": 399,
      "context_length": 190843
    },
    {
      "file_path": "lib/matplotlib/_api/deprecation.py",
      "position": 28,
      "tokens": 4317,
      "context_length": 195160
    },
    {
      "file_path": "tutorials/introductory/quick_start.py",
      "position": 29,
      "tokens": 5940,
      "context_length": 201100
    }
  ]
}